---
title: "Personality Tests"
linktitle: "Week 3: Personality Tests"
output:
  blogdown::html_page:
    toc: true
menu:
  walkthroughs:
    parent: Walkthroughs
    weight: 2
type: docs
weight: 1
editor_options: 
  chunk_output_type: console
---
<style>
  .hvr-sweep-to-left {
    display: inline-block;
    vertical-align: middle;
    -webkit-transform: perspective(1px) translateZ(0);
    transform: perspective(1px) translateZ(0);
    box-shadow: 0 0 1px rgba(0, 0, 0, 0);
    position: relative;
    -webkit-transition-property: color;
    transition-property: color;
    -webkit-transition-duration: 0.25s;
    transition-duration: 0.25s;
  }

.hvr-sweep-to-left:before {
  content: "";
  position: absolute;
  z-index: -1;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background: #761756;
    -webkit-transform: scaleX(0);
  transform: scaleX(0);
  -webkit-transform-origin: 100% 50%;
  transform-origin: 100% 50%;
  -webkit-transition-property: transform;
  transition-property: transform;
  -webkit-transition-duration: 0.3s;
  transition-duration: 0.3s;
  -webkit-transition-timing-function: ease-out;
  transition-timing-function: ease-out;
}

.hvr-sweep-to-left:hover, .hvr-sweep-to-left:focus, .hvr-sweep-to-left:active {
  color: white;
}

.hvr-sweep-to-left:hover:before, .hvr-sweep-to-left:focus:before, .hvr-sweep-to-left:active:before {
  -webkit-transform: scaleX(1);
  transform: scaleX(1);
}
</style>

```{r setup, include=FALSE,purl=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(widgetframe_self_contained = TRUE) 
knitr::opts_knit$set(root.dir = getwd())

library(tidyverse)
library(fivethirtyeight)
library(psych)
library(knitr)
library(kableExtra)
```

<script src="//yihui.org/js/math-code.js"></script>
<script async
  src="//mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

## Take This

First things first, please go and take the [Big Five Personality Test](https://openpsychometrics.org/tests/IPIP-BFFM/){target="_blank"}. 

## Read Up

Now go and read this short synopsis on the test from [FiveThirtyEight](https://projects.fivethirtyeight.com/personality-quiz/){target="_blank"}.

## Data Files

Please download the files we'll need. 

```{r echo=FALSE,eval=TRUE,message=FALSE,purl=FALSE}
loc <- here::here("static", "data", "EDP611Week3Data&Script.zip")

downloadthis::download_file(
  path = loc,
  output_name = "Week 3 Data and Script",
  button_label = "Download Data and Script",
  button_type = "default",
  has_icon = TRUE,
  icon = "fa fa-save",
  class = "hvr-sweep-to-left"
  )
```

## Prerequisites {-}

Open up R and create a new script by going to **File > New File > R Script**. Save this in an easily accessible folder. Now unzip this week's data set and take the files - `Big5data.csv`, `Big5codebook.csv`, `Big5measures.csv`, and `03-walkthrough` - and drop them all in a folder of their own. If you aren't familiar with how directories and file paths work on a computer, consider keeping both your R script and data sets in the same folder. It just makes life easier.

Before we load the libraries, we're going to grab a package called `surveytools2` that is not on CRAN - the main R repository of packages. In any case, there is a command within the `surveytools2` package that will make our lives easier moving forward. To install it, please run the following commands

```{r eval = FALSE}
install.packages("remotes")

remotes::install_github("peterhurford/surveytools2")
```

If you are asked to update any packages, please select `1: All`. 

Now please go ahead and load up the following libraries or download and load if needed

```{r}
library("tidyverse")
library("psych")
library("corrr")
library("surveytools2")
```

Then set the working directory to the location of the script by running

```{r eval=FALSE}
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
```

in your console or by selecting **Session > Set Working Directory > To Source File Location**.

## Data Files

We'll be looking at a very truncated data set from the 2018 BigFive Personality Test. The full data set is a huge file with 1 million answers to the 50 personality items! You can access it [here](
https://openpsychometrics.org/_rawdata/IPIP-FFM-data-8Nov2018.zip) but be warned that opening a file that size can take a long time or may even crash some computers depending on their processing power and RAM. It is a tab separated csv file. 

### Side Note: Loading the Entire Data Set

If you want to give the entire data set a go, I am not certain how to load it in Excel but in R you can use

```{r eval=FALSE}
toobig_five_data <- read_delim("data-final.csv", delim="\t") 
```

to save it to the `big_five_data` variable which you can access by running

```{r eval=FALSE}
toobig_five_data
```

At this point you probably want to just open up the csv files in Excel and if that is what works, then by all means. While I try to run everything in R, sometimes its just easier to double click it. The problem really lies in the size of a data set. The larger the data set, the more power and time it takes for excel to load it up. With R you avoid this whole idea and the set loads up within seconds, rather than minutes. If you try loading the original data set in both R and Excel, the difference is very apparent. 

In any case, we will be working with data strictly in R, but never feel bad about opening and wrangling a data set using another application like Excel. For all of my snarkiness towards anything Microsoft, Excel has some nice qualities but don't tell anyone I ever wrote that.

## Loading a Local Data Set

Let's turn back to the data set we'll be using. To load the data set, codebook, and measures, run the following

```{r eval=FALSE}
big_five_data <- read_csv("Big5data.csv")
```

```{r echo=FALSE, purl=FALSE}
big_five_data <- read_csv(here::here("static", "data", "Big5data.csv"))
```

```{r eval=FALSE}
big_five_codebook <- read_csv("Big5codebook.csv")
```

```{r echo=FALSE, purl=FALSE}
big_five_codebook <-
  read_csv(here::here("static", "data", "Big5codebook.csv"))
```

```{r eval=FALSE}
big_five_measures <- read_csv("Big5measures.csv")
```

```{r echo=FALSE, purl=FALSE}
big_five_measures <-
  read_csv(here::here("static", "data", "Big5measures.csv"))
```

and take a look at each

```{r}
big_five_data %>%
  head()
```

with respondents self-report under the five factors Extroversion (`EXT`), Agreeableness (`AGR`), Conscientiousness (`CSN`), Emotional Stability (`EST`), and Intellect/Imagination (`OPN`).

```{r}
big_five_codebook
```

```{r}
big_five_measures
```

For this walkthrough, let's just concentrate on the Extroversion items which are given by `EXT.` That means we should probably pair down both the data set and codebook. For data sets with multiple columns, we can use the `select()` syntax. Moreover since we are looking at all of the columns that have `EXT`, we can pull only those using the `starts_with()` command. For more examples of options that can be used with `select()`, take a look [here](https://dplyr.tidyverse.org/reference/select.html){target="_blank"}. 

```{r}
big_five_data_EXT <- big_five_data %>%
                     select(starts_with("EXT"))
```

and then we'll do something similar to the codebook. While we can't simply select columns because all of the variables are in a single column. Much like in Excel, we can filter rows. To do this in R, we use the `filter()` command.

```{r}
big_five_codebook_EXT <- big_five_codebook %>%
                         filter(str_detect(ID, "EXT"))
```

```{r}
big_five_data_EXT

big_five_codebook_EXT
```

## Reverse Coding

Sometimes items can be worded ‘backwards’. In these situation, scales need to be reversed to point in the same direction. 

### Example

For example both these questions might be used to measure the same underlying construct or idea.

1. I really like being alone
2. I really *don't* enjoy large gatherings

In this situation, if we used the same response scale for each participants’ responses they would simply cancel out. 

When aligning the direction, we typically reverse code the one that has a negative, aka the negatively-keyed item. In this case is the second example since it includes the word *don't*. There are exceptions to this rule, but they are narrowly defined. For example, someone who states that they "really *don't* enjoy large gatherings" doesn't automatically imply they like being alone. In fact, there are arguably an infinite number of possibilities of things they do like! The only time you can be code all items in either direction are in circumstances where there is a binary choice (e.g. Yes/No questions).

But wait...there's more! You also have to consider the intent of the questions and the participants. This second and final check is crucial to reporting reliable and consistent results.<br />
:::

Getting back to the main data set, let's again look at the codebook.  

```{r}
big_five_codebook_EXT
```

Well it certainly looks like `EXT2`, `EXT4`, `EXT6`, `EXT8` and `EXT10` are all negative in the context of of assessing extroversion. Furthermore while `EXT9` includes the term *don't*, it doesn't orient the statement in a negative way so it stays the way it is. 

Remember that command we needed from the `surveytools2` package? Well it was to reverse code in a tidy way

```{r}
big_five_data_EXT_rev <- big_five_data_EXT %>%
                         mutate(EXT2 = reverse_code(EXT2),
                                EXT4 = reverse_code(EXT4),
                                EXT6 = reverse_code(EXT6),
                                EXT8 = reverse_code(EXT8),
                                EXT10 = reverse_code(EXT10))

big_five_data_EXT_rev
```

Let's take a look at a sample of the first six rows between the two tables to see if the columns were indeed reverse coded.


<div align="center">

```{r, echo = FALSE, purl=FALSE}
kable(big_five_data_EXT 
        %>% head(),
      align = "c") %>%
  kable_styling(full_width = FALSE, 
                font_size = 13.0,
                position = "center",
                bootstrap_options = c("striped", "hover", "condensed", "responsive")) %>%          
                column_spec(2, color='white', background='#52bf90')  %>%        
                column_spec(4, color='white', background='#49ab81')  %>%
                column_spec(6, color='white', background='#419873')  %>%        
                column_spec(8, color='white', background='#398564') %>%         
                column_spec(10, color='white', background='#317256') %>%                        add_header_above(c("Original Data Set" = 10))
```

```{r, echo = FALSE, purl=FALSE}
kable(big_five_data_EXT_rev 
        %>% head(),
      align = "c") %>%
  kable_styling(full_width = FALSE, 
                font_size = 13.0,
                position = "center",
                bootstrap_options = c("striped", "hover", "condensed", "responsive")) %>%          
                column_spec(2, color='white', background='#52bf90')  %>%        
                column_spec(4, color='white', background='#49ab81')  %>%
                column_spec(6, color='white', background='#419873')  %>%        
                column_spec(8, color='white', background='#398564') %>%         
                column_spec(10, color='white', background='#317256') %>%
                add_header_above(c("Data Set with Reverse Coded Columns" = 10))
```

</div>

That looks correct! Notice that in the <a style="color:	#FFFFFF; background-color: #419873">green</a> columns, the numbers flip along the neutral measure (3), or maybe a better observation is that the numerical complement is correct if adding two corresponding cells equals 5. If you have had any upper level mathematics courses, you may notice these as a modulo or mod 5 system.

## Computing the Internal Consistency 

There are many approaches when assessing reliability, namely those associated with interviews, experiments, surveys, trials, etc. Internal consistency is foremost one of many existing methods used to measure reliability, and it is typically useful in assessing items (e.g from a protocol, questionnaire, test, etc). It essentially **estimates to what degree total scores on an instrument would change or vary if different items were used**. Here are four but really three approaches used by a majority of practitioners:

### Composite Reliability

Getting a bit ahead of ourselves, composite reliability is based on the factor lodgings in a confirmatory factor analysis (CFA). We'll cover this when we address CFAs soon!

### Cronbach’s alpha

By far the most utilized approach, it is also very procedural which is typically viewed as beneficial by many evaluators. There are many ways to tell R to compute alpha $\left(\alpha\right)$ but by far the simplest may be to use the `psych` package

```{r}
psych::alpha(big_five_data_EXT_rev)
```

There is a lot there and most of those outcomes are useful, but for reliability we really care about the `raw_alpha`, or the *the standardized alpha based upon the correlations*. For a raw $\alpha$ score, the following breakdown is widely accepted but not without controversy. 

<div align="center">

| Cronbach's Alpha       | Measure of Internal Consistency |
|------------------------|---------------------------------|
| $\alpha \geq 0.90$     | Excellent                       |
| $0.70 >\alpha\geq0.90$ | Good                            |
| $0.80 >\alpha\geq0.70$ | Acceptable                      |
| $0.70 >\alpha\geq0.60$ | Poor                            |
| $\alpha < 0.50$        | Unacceptable                    |
|                        |                                 |

</div>

Note that the thresholds themselves do not have any logical grounding, rather what is an acceptable threshold may be situation dependent. 

If you’d like to access the alpha value easily, implement this

```{r}
psych::alpha(big_five_data_EXT_rev)$total$raw_alpha
```

which for a **quick and dirty** measure of reliability seems to be pretty Good!


### Inter-item Correlation

This is foremost an **average** which uses correlations. 

```{r}
big_five_data_EXT_rev %>%
  correlate()
```

The package gives an `NA` for variables that try to correlate with themselves. By default each variable should be perfectly correlated with itself but who cares?  With the diagonal owned by `NA`s, we can obtain the average correlation of each item with all others by computing the means for each column `EXT1` - `EXT10`.

```{r}
inter_measure  <- big_five_data_EXT_rev %>% 
                  correlate() %>% 
                  select(-term) %>% 
                  colMeans(na.rm = TRUE)

inter_measure 
```

We can check the variables that are more strongly correlated with the other items in the `EXT` group. The same information is presented by arranging categories and descending internal consistency measures, respectively.

```{r}
big_five_correlations_cat <- data.frame(inter_measure) %>%
                             rownames_to_column() %>%
                             as_tibble() %>%
                             arrange(desc(inter_measure)) 

big_five_correlations_num <- big_five_correlations_cat %>%
                             left_join(big_five_codebook, c("rowname" = "ID"))

big_five_correlations_cat

big_five_correlations_num 
```

### Side Note: Getting a Jump on Joins

We'll talk about a `left_join()` and other types of `joins` next week but for now if you can't wrap your head around what happened in that step, that's fine! If you want to get a head start on `joins`, take a look at [STAT545](https://stat545.com/join-cheatsheet.html). 

In any case, it looks like `EXT4`, `EXT5`, `EXT10`, and `EXT7` have the strongest correlation. The list below has been arranged to represent the data in descending order of measure.

<div align="center">
```{r, echo = FALSE, purl=FALSE}
big_five_correlations_num %>%
  rename("Variable" = "rowname") %>%
  rename("Internal Consistency Measure" = "inter_measure") %>%
kable(align = "c") %>%
  kable_styling(full_width = FALSE, 
                font_size = 13.0,
                position = "center",
                bootstrap_options = c("striped", "hover", "condensed", "responsive")) %>%          
                row_spec(1, color='white', background='#5AA85C')  %>%        
                row_spec(2, color='white', background='#599D68')  %>% 
                row_spec(3, color='white', background='#56916F')  %>% 
                row_spec(4, color='white', background='#538572')  %>%
                row_spec(5, color='white', background='#4F7972')  %>%
                row_spec(6, color='white', background='#4B6C6D')  %>%
                row_spec(7, color='white', background='#465B61')  %>%
                row_spec(8, color='white', background='#404C55')  %>%
                row_spec(9, color='white', background='#393F49')  %>%
                row_spec(10, color='white', background='#32333E')
```
</div>

and the overall average inter-item correlation can be found by

```{r}
mean(inter_measure)
```


### Item-total Correlation

The item-total correlation is similar to the correlation described previously. We are calculating the average but this time, we're doing it by row rather than by column. To do that we sum 

```{r}
agg_scores <- big_five_data_EXT_rev %>% 
              mutate(score = rowMeans(select(.,1:10))) %>% 
              correlate() %>% 
              focus(score) %>%
              arrange(desc(score))

agg_scores
```

Well that is quite enough for now. There are other ways to assess reliability. As you move along in the course, keep in mind that none of these could yield good measures for internal consistency. You may have to look around the internet for other R commands and packages that may be a better fit. As usual, you always have your peers and me if you get stuck!
