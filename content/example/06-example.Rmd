---
title: "I'm the Map"
linktitle: "Week 6: I'm the Map"
output:
  blogdown::html_page:
    toc: true
menu:
  example:
    parent: Examples
    weight: 6
type: docs
weight: 1
editor_options: 
  chunk_output_type: console
---

```{r echo=FALSE, message=FALSE, purl=FALSE}
library(knitr)
library(kableExtra)
library(tidyverse)
library(downloadthis)
library(here)
```

```{r setup, include=FALSE, purl=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Introduction

In a nutshell, choropleth comes from the Greek *choros* (area) and *pleth* (value). They distribute colors the map regions based on the measure which then allows for comparisons using the relative value associated with each color of one region to another.

# Preliminary Items

## First Things First! Set your Working Directory

Your *working directory* is simply where your script will look for anything it needs like external data sets. There are a few ways to go about doing this which we will cover. However for now, just do the following:

1.  Open up a new script by going to `File > New File > R Script`.
2.  Save it in a preferably empty folder as whatever you want.
3.  Go to the menu bar and select `Session > Set Working Directory > To Source File Location`.

## Download the script

Copying and pasting syntax from a browser can cause problems. To avoid this issue, please download a script with all of the needed code presented in this walkthrough.

```{r echo=FALSE,eval=TRUE,purl=FALSE}
downloadthis::download_file(
  path = here::here("content", "example", "06-example.R"),
  output_name = "Week 6 Example Script Outline",
  button_label = "Download the Script",
  button_type = "default",
  has_icon = TRUE,
  icon = "fa fa-save",
  class = "hvr-sweep-to-left"
  )
```

## Loading libraries

Go ahead and load these or install and then load them.
```{r message=FALSE}
library(tidyverse)
library(tidycensus)
library(viridis)
library(tools)
```

## Setting up your API

As before, you will utilize the Census API. You'll likely receive a prompt to save it using

`To install your API key for use in future sessions, run this function with install = TRUE.`

I suggest rerunning the command and do just that!

```{r message = FALSE, eval = TRUE, echo=FALSE, purl=FALSE}
census_api_key("1dea0fbe280aeab3e04993bee543979a4dc36790")
readRenviron("~/.Renviron")
```

```{r eval = FALSE, echo=TRUE}
# Input your Census key
census_api_key("YOUR CENSUS API KEY")

# Reload the .Renviron marker
readRenviron("~/.Renviron")
```

# Walkthrough 
There are two major functions implemented in `tidycensus::get_decennial()`, which grants access to the 1990, 2000, and 2010 decennial US Census APIs, and `get_acs`, which grants access to the 5-year American Community Survey APIs. While limited in comparison to the other method we used, what it lacks in breadth, it soon makes up in depth which we will see soon!<br>

Getting variables from the Census or ACS requires knowing the variable ID - and there are thousands of these IDs across the different Census files. To search for variables without pulling your hair out, use the `load_variables` function. The function takes two required arguments: 

1. the year of the Census or endyear of the ACS sample, and

2. the dataset - one of `sf1`, `sf3`, or `acs5`.

For ideal functionality, it is recommended that you assign the result of this function to a variable, setting `cache = TRUE` to store the result on your computer for future access, and using the `View` function in RStudio to interactively browse for variables. However, this is not required. However, as an example, we will take the 2016 American Community Survey data set and save it.

```{r}
acs16 <- load_variables(2016, "acs5", cache = TRUE) 
```

```{r}
head(acs16) # or View(acs16) if you prefer
```

In this basic example, let's look at US income by county using the data set `B19013_001` (such a clear and obvious name)
```{r}
title <- acs16 %>% # use the acs_16 data set we created
  filter(name == "B19013_001") %>% # filter everything else out except where we find B19013_001
  select(concept) # select the column concept that provides a very brief description

# Convert to title case. We have to go in a funny way simply due to the encoding of text within the Census API
title <- tolower(title) %>%
          toTitleCase()

title
```

Then let's get some income level data from that set...
```{r}
us_county_income <-  get_acs(geography = "county", 
          variables = "B19013_001", 
          shift_geo = TRUE, 
          geometry = TRUE)
```

...and plot!
```{r}
ggplot(us_county_income) + 
  geom_sf(aes(fill = estimate), color = NA) + 
  # Removes the graticule lines from the plot
  coord_sf(datum = NA) + 
  theme_minimal() + 
  scale_fill_viridis()
```

Looks good. ow let's get some West Virginia population data like we did earlier in the term.
```{r}
wv_pop <- get_acs(geography = "county", 
                     variables = "B01003_001", 
                     state = "WV",
                     geometry = TRUE)
```

```{r}
head(wv_pop) # or View(wv_pop) if you prefer
```

So far we haven't done anything out of left field, in that it the process and results are pretty similar to what came before. It is at this point you should note that there is something much more interesting coming. Let's redo the plot above using a very cool package called `leaflet`. Let's lod (or install and load) some new libraries:
```{r}
library(leaflet) # a JavaScript library for interactive maps
library(stringr) # Well I lied...this isn't new!
library(sf) # A very nice package that allows us to us a standardized way to encode spatial vector data, aka spatial objects.
```

I cheated a little and know how many colors we'll need (10). Below is one of many ways to construct a continuous scale.
```{r}
pal <- colorQuantile(palette = "viridis", domain = wv_pop$estimate, n = 10)
```

Now it gets interesting (well for me anyways...yes I find maps fun). Below we're going to construct an interactive plot. You can click on the individual counties to see their names:
```{r}
wv_pop %>%
  st_transform(crs = "+init=epsg:4326") %>% 
  leaflet(width = "100%") %>%
  addProviderTiles(provider = "CartoDB.Positron") %>%
  addPolygons(popup = ~ str_extract(NAME, "^([^,]*)"),
              stroke = FALSE,
              smoothFactor = 0,
              fillOpacity = 0.7,
              color = ~ pal(estimate)) %>%
  addLegend("bottomright", 
            pal = pal, 
            values = ~ estimate,
            title = "Population percentiles",
            opacity = 1)
```

Want an explanation of the code? If so, keep reading. If you have fallen asleep, maybe move on to the next batch of codes.<br>

### Note about geographic information system (GIS)

What the heck is `st_transform(crs = "+init=epsg:4326")`? Well without getting too into GIS because that is an entire semesters worth of material in itself, the `epsg` part specifically refers to an optimal coordinate system first developed by the European Petroleum Survey Group, an organization involved in best practices for surveying and applied geodesy. The EPSG was absorbed into the International Association of Oil & Gas Producers in 2005 but the code `epsg` has become a standard.<br>

If you want to know more about GIS in general, let me know as I am considering teaching a section. Again, maps are fun! Inn the meantime, to know more about GIS in general, consider checking out the ersi homepage: [https://www.esri.com/en-us/what-is-gis/overview]("https://www.esri.com/en-us/what-is-gis/overview"). They make the most popular software package for GIS called ArcGIS and thought it is expensive (and I mean expensive) in the outside world, much like Tableau, it is free for students and educators alike. Moreover, companies and organizations that use ArcGIS use it heavily and are more likely than not well aware of the investment. Moreover, mapping geometries (and by this I mean anything from GPS to LiDAR to measuring distances on your phone and more) is a lucrative area to be in. Take a look at this recent report by National Geographic on how wrong we were about the size and population of the Mayan people which absolutely blew my mind: [https://news.nationalgeographic.com/2018/02/maya-laser-lidar-guatemala-pacunam/]("https://news.nationalgeographic.com/2018/02/maya-laser-lidar-guatemala-pacunam/"). That is simply one amazing facet of GIS!<br>

OK what were we doing? Oh yeah. OK back to our maps.<br>

Let's now look at one of our border states - Pennsylvania. In this case, we are going to use data regarding Pennsylvania's population by county and proportional estimates by pulling from the ACS data set `B01003_001`.

```{r}
# Use the acs_16 data set we created
acs16 %>% 
  # filter everything else out except where we find B01003_001
  filter(name == "B01003_001") %>% 
  # select the column concept that provides a very brief description
  select(concept) 
```

```{r}
# Pretty much the exact same pull we did above...
pa_pop <- get_acs(geography = "county", 
                    variables = "B01003_001", 
                    state = "PA",
                    geometry = TRUE)
```

```{r}
# ... but this time we'll color it differently.
pal <- colorNumeric(palette = "plasma", 
                    domain = pa_pop$estimate)
```

```{r}
# GIS things. Look at the code. Most of it is repetitive and for the most part, I think you should be able to figure out what's generally going on. 
pa_pop %>%
  st_transform(crs = "+init=epsg:4326") %>%
  leaflet(width = "100%") %>%
  addProviderTiles(provider = "CartoDB.Positron") %>%
  addPolygons(popup = ~ str_extract(NAME, "^([^,]*)"),
              stroke = FALSE,
              smoothFactor = 0,
              fillOpacity = 0.7,
              color = ~ pal(estimate)) %>%
  addLegend("bottomright", 
            pal = pal, 
            values = ~ estimate,
            title = "County Populations",
            opacity = 1)
```

Well the output makes sense. PA is a pretty rural state barring areas close to Washington DC and just Pittsburgh. Let's compare it to an a state like Florida that is overtly populated:

```{r}
# Again, use the acs_16 data set we created
fl_pop <- get_acs(geography = "county", 
                  variables = "B01003_001", 
                  state = "FL",
                  geometry = TRUE)
```

```{r}
# Assign out color palette for comparison
pal <- colorNumeric(palette = "plasma", 
                    domain = fl_pop$estimate)
```

```{r}
# GIS things again. Notice that the base code is consistent.
fl_pop %>%
  st_transform(crs = "+init=epsg:4326") %>%
  leaflet(width = "100%") %>%
  addProviderTiles(provider = "CartoDB.Positron") %>%
  addPolygons(popup = ~ str_extract(NAME, "^([^,]*)"),
              stroke = FALSE,
              smoothFactor = 0,
              fillOpacity = 0.7,
              color = ~ pal(estimate)) %>%
  addLegend("bottomright", 
            pal = pal, 
            values = ~ estimate,
            title = "County Populations",
            opacity = 1)
```

