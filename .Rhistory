region_tract_data <- tidycensus::get_acs(geography = "region",
variables = vars_of_interest,
year = 2016,
survey = "acs5",
geometry = TRUE) %>%
rename(`Median Income` = estimate) %>%
filter(GEOID == 1) %>%
as_tibble() %>%
do.call(what = sf:::rbind.sf, args)
#  We get acs data and geographies for our variable at only the
# ~ tract level
region_tract_data <- tidycensus::get_acs(geography = "region",
variables = vars_of_interest,
year = 2016,
survey = "acs5",
geometry = TRUE) %>%
rename(`Median Income` = estimate) %>%
filter(GEOID == 1) %>%
as_tibble() %>%
do.call(what = sf:::rbind.sf, args = list_of_sf)
#  We get acs data and geographies for our variable at only the
# ~ tract level
region_tract_data <- tidycensus::get_acs(geography = "region",
variables = vars_of_interest,
year = 2016,
survey = "acs5",
geometry = TRUE) %>%
rename(`Median Income` = estimate) %>%
filter(GEOID == 1) %>%
as_tibble()
do.call(what = sf:::rbind.sf, args =   region_tract_data)
do.call(what = sf:::rbind.sf, args = region_tract_data)
purrr::reduce(region_tract_data, sf:::rbind.sf)
mapedit:::combine_list_of_sf(region_tract_data )
install.packages("mapedit")
mapedit:::combine_list_of_sf(region_tract_data)
purrr::reduce(region_tract_data$geometry, sf:::rbind.sf)
mapedit:::combine_list_of_sf(region_tract_data$geometry)
do.call(what = sf:::rbind.sf, args = region_tract_data$geometry)
purrr::reduce(region_tract_data$geometry, sf:::rbind.sf) %>%
as_tibble()
View(purrr::reduce(region_tract_data$geometry, sf:::rbind.sf) )
#  We get acs data and geographies for our variable at only the
# ~ tract level
region_tract_data <- tidycensus::get_acs(geography = "region",
variables = vars_of_interest,
year = 2016,
survey = "acs5",
geometry = TRUE) %>%
rename(`Median Income` = estimate) %>%
filter(GEOID == 1) %>%
tidyr::unnest_auto()
#  We get acs data and geographies for our variable at only the
# ~ tract level
region_tract_data <- tidycensus::get_acs(geography = "region",
variables = vars_of_interest,
year = 2016,
survey = "acs5",
geometry = TRUE) %>%
rename(`Median Income` = estimate) %>%
filter(GEOID == 1) %>%
tidyr::unnest_auto(col = c("geometry"))
#  We get acs data and geographies for our variable at only the
# ~ tract level
region_tract_data <- tidycensus::get_acs(geography = "region",
variables = vars_of_interest,
year = 2016,
survey = "acs5",
geometry = TRUE) %>%
rename(`Median Income` = estimate) %>%
filter(GEOID == 1) %>%
tidyr::unnest_legacy(col = c("geometry"))
unnest.sf = function(data, ..., .preserve = NULL) {
# nocov start
sf_column_name = attr(data, "sf_column", exact = TRUE)
if (!requireNamespace("tidyr", quietly = TRUE))
stop("unnest requires tidyr; install that first")
class(data) = setdiff(class(data), "sf")
st_sf(NextMethod(), sf_column_name = sf_column_name)
# nocov end
}
#  We get acs data and geographies for our variable at only the
# ~ tract level
region_tract_data <- tidycensus::get_acs(geography = "region",
variables = vars_of_interest,
year = 2016,
survey = "acs5",
geometry = TRUE) %>%
rename(`Median Income` = estimate) %>%
filter(GEOID == 1) %>%
tidyr::unnest_legacy(col = c("geometry"))
#  We get acs data and geographies for our variable at only the
# ~ tract level
region_tract_data <- tidycensus::get_acs(geography = "region",
variables = vars_of_interest,
year = 2016,
survey = "acs5",
geometry = TRUE) %>%
rename(`Median Income` = estimate) %>%
filter(GEOID == 1) %>%
unnest.sf()
#  We get acs data and geographies for our variable at only the
# ~ tract level
region_tract_data <- tidycensus::get_acs(geography = "region",
variables = vars_of_interest,
year = 2016,
survey = "acs5",
geometry = TRUE) %>%
rename(`Median Income` = estimate) %>%
filter(GEOID == 1) %>%
unnest.sf("geometry")
#  We get acs data and geographies for our variable at only the
# ~ tract level
region_tract_data <- tidycensus::get_acs(geography = "region",
variables = vars_of_interest,
year = 2016,
survey = "acs5",
geometry = TRUE) %>%
rename(`Median Income` = estimate) %>%
filter(GEOID == 1) %>%
as_tibble() %>%
st_as_sfc()
#  We get acs data and geographies for our variable at only the
# ~ tract level
region_tract_data <- tidycensus::get_acs(geography = "region",
variables = vars_of_interest,
year = 2016,
survey = "acs5",
geometry = TRUE) %>%
rename(`Median Income` = estimate) %>%
filter(GEOID == 1) %>%
tibble() %>%
st_as_sfc()
#  We get acs data and geographies for our variable at only the
# ~ tract level
region_tract_data <- tidycensus::get_acs(geography = "region",
variables = vars_of_interest,
year = 2016,
survey = "acs5",
geometry = TRUE) %>%
rename(`Median Income` = estimate) %>%
filter(GEOID == 1) %>%
tibble(); region_tract_data
#  We get acs data and geographies for our variable at only the
# ~ tract level
region_tract_data <- tidycensus::get_acs(geography = "region",
variables = vars_of_interest,
year = 2016,
survey = "acs5",
geometry = TRUE) %>%
rename(`Median Income` = estimate) %>%
filter(GEOID == 1) %>%sf::st_simplify(); region_tract_data
# Make sure to check it
DT::datatable( region_tract_data)
#  We get acs data and geographies for our variable at only the
# ~ tract level
region_tract_data <- tidycensus::get_acs(geography = "region",
variables = vars_of_interest,
year = 2016,
survey = "acs5",
geometry = TRUE) %>%
rename(`Median Income` = estimate) %>%
filter(GEOID == 1); region_tract_data
unnest(region_tract_data, *, .drop = FALSE)
unnest(region_tract_data, geometry, .drop = FALSE)
#  We get acs data and geographies for our variable at only the
# ~ tract level
region_tract_data <- tidycensus::get_acs(geography = "region",
variables = vars_of_interest,
year = 2016,
survey = "acs5",
geometry = TRUE) %>%
rename(`Median Income` = estimate) %>%
filter(GEOID == 1)%>%
slice(1:3); region_tract_data
# Make sure to check it
DT::datatable( region_tract_data)
#  We get acs data and geographies for our variable at only the
# ~ tract level
region_tract_data <- tidycensus::get_acs(geography = "region",
variables = vars_of_interest,
year = 2016,
survey = "acs5",
geometry = TRUE) %>%
rename(`Median Income` = estimate) %>%
filter(GEOID == 1)%>%
mutate(y = strsplit(c("a", "d,e,f", "g,h"), ",")); region_tract_data
st_geometry(region_tract_data)
unnest(region_tract_data, geometry, .drop = FALSE)
st_as_sf(region_tract_data, coords = c("x","y"))
#  We get acs data and geographies for our variable at only the
# ~ tract level
region_tract_data <- tidycensus::get_acs(geography = "region",
variables = vars_of_interest,
year = 2016,
state = .x,
survey = "acs5",
geometry = TRUE) %>%
rename(`Median Income` = estimate) %>%
filter(GEOID == 1); region_tract_data
#  We get acs data and geographies for our variable at only the
# ~ tract level
region_tract_data <- tidycensus::get_acs(geography = "region",
variables = vars_of_interest,
year = 2016,
survey = "acs5",
geometry = TRUE)  %>%
select(GEOID, NAME, variable, estimate) %>%
spread(variable, estimate)
# Make sure to check it
DT::datatable( region_tract_data)
View(region_tract_data)
install.packages("isoband")
yes
install.packages(c("blogdown", "ipred", "tinytex", "xaringan"))
install.packages("wordcloud")
xaringan:::inf_mr()
## ------------------------------------------------------------------------
library(tidyverse)
library(gridExtra) # Used to plot things in a grid
library(viridis) # A coloring package with multiple palettes
library(scales) # Used to manipulate applications of colors
library(stringr) # Used to manipulate strings (i.e. just text)
library(ggpubr)
## ------------------------------------------------------------------------
names(election2016) # or use View(election2016) for the whole set
setwd("~/Documents/WVU/Teaching/GitHub.nosync/Workspace/edp617")
setwd("~/Documents/WVU/Teaching/Past/EDP 693/EDP 493A:693C Fall 2018/Weeks/Week 7/In Class Task")
get_acs_multi <- function(geography, variables = NULL, table = NULL,
cache_table = FALSE, years = 2017, racial = FALSE, endyear = NULL,
output = "wide", state = NULL, county = NULL, summary_var = NULL,
key = NULL, moe_level = 90, survey = "acs5", ...){
if(!require(tidyverse) | !require(tidycensus)) stop("This function requires 'tidyverse' and 'tidycensus'.")
data <- tibble()
race_iterations <- tribble(
~CODE, ~RACE,
"_", "All",
"A", "White",
"B", "Black or African-American",
"C", "American Indian and Alaska Native",
"D", "Asian",
"E", "Native Hawaiian and Other Pacific Islander",
"F", "Some Other Race",
"G", "Two or More Races",
"H", "White, not Hispanic or Latino",
"I", "Hispanic or Latino"
)
# determine table or variables
if (is.null(table) && is.null(variables)){
stop("Either a table or vector of variables must be supplied", call. = FALSE)
}
if (!is.null(table) && !is.null(variables)){
stop("Both a table and a vector of variables cannot be supplied. Provide one or the other", call. = FALSE)
}
# select correct subset of races
if (is.logical(racial)){
if(racial){
# if racial == TRUE, use all races except all
races <- slice(race_iterations, 2:10)
} else {
# if racial == FALSE, use only all
races <- slice(race_iterations, 1)
}
} else if(is.character(racial)){
# If a racial == [some string], subset possible race iterations using the string
races <- filter(race_iterations, str_detect(racial, CODE))
if (nrow(races)==0) stop("If `racial` is a string, it must contain Census race specifiers [A:I] or '_' for non-racial.")
} else stop("`racial` must be a logical or a string", call. = FALSE)
# identify mode
if (!is.null(table)) mode <- "table" else mode <- "variables"
# for each race
for(i in 1:nrow(races)){
# identify variables
THIS_RACE_CODE <- races$CODE[i]
THIS_RACE_NAME <- races$RACE[i]
# if in ALL RACES, do not modify inputs
if(THIS_RACE_NAME == "All"){
table2 <- table
variables2 <- variables
summary_var2 <- summary_var
# if in some other race, modify inputs to add racial character
} else {
if(mode == "table"){
table2 <- paste0(table, THIS_RACE_CODE)
variables2 <- NULL
}else{
variables2 <- sub(x=variables,pattern = "_", replacement = paste0(THIS_RACE_CODE, "_"))
table2 <- NULL
}
if(length(summary_var)){
summary_var2 <- sub(x=summary_var,pattern = "_", replacement = paste0(THIS_RACE_CODE, "_"))
} else summary_var2 <- NULL
}
# create `source` for print-back
if(mode == "table"){
source <- table2
}else if(length(variables)<5) {
source <- paste(variables2, collapse = ", ")
} else {
source <- paste0(paste(variables2[1:3], collapse = ", "),", ...")
}
if(length(summary_var2)) source <- paste(source, summary_var2, sep = ", ")
# for each year
for(THIS_YEAR in years){
# print update
cat(" Getting data: ", survey, " | ", str_pad(source, 8, side="right"),  " | ", THIS_YEAR, " | ", THIS_RACE_NAME, "\n")
# get data
data_this <- suppressMessages(get_acs(geography = geography, variables = variables2, table = table2,
cache_table = cache_table, year = THIS_YEAR, endyear = endyear,
output = output, state = state, county = county, summary_var = summary_var2,
key = key, moe_level = moe_level, survey = survey, ...)) %>%
mutate(YEAR = THIS_YEAR, RACE = THIS_RACE_NAME, SURVEY = survey,
GEO = case_when(
geography == "metropolitan statistical area/micropolitan statistical area" ~ "MSA",
geography == "us" ~ "nation",
TRUE ~ geography)) %>%
select(YEAR, RACE, SURVEY, GEO, everything())
# Remove race code from variable names so that join aligns
if (THIS_RACE_NAME != "All"){
names(data_this) <- gsub(x = names(data_this), pattern = paste0(THIS_RACE_CODE, "_"), replacement = "_")
}
# add data to master
data <- bind_rows(data, data_this)
}
}
return(data)
}
blogdown::build_site()
blogdown::serve_site()
xaringan:::inf_mr()
# Set the working directory as source ----
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
pagedown::chrome_print("Standards Based Evaluation.Rmd")
# Set the working directory as source ----
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
pagedown::chrome_print("Standards Based Evaluation.Rmd")
pagedown::chrome_print("Standards_Based_Evaluation.Rmd")
# Set the working directory as source ----
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
pagedown::chrome_print("Standards_Based_Evaluation.Rmd")
xaringan:::inf_mr()
# Set the working directory as source ----
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
pagedown::chrome_print("Standards_Based_Evaluation.Rmd")
setwd("~/Documents/WVU/Teaching/GitHub.nosync/Workspace/edp617")
blogdown::build_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::stop_server()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::serve_site()
blogdown::build_site()
blogdown::serve_site()
install.packages(c("effectsize", "harrypotter", "parallelly", "paws", "survival", "utf8"))
install.packages("survival")
# Set the working directory as source ----
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
library(slidex)
library(here)
loc <- here::here("Documents",
"WVU",
"Teaching",
"Past",
"EDP 617",
"EDP 617 Spring 2020",
"Weekly Tasks",
"Week 9",
"A Short Course on Evaluation Models",
"A Short Course on Evaluation Models.pptx")
convert_pptx(path = loc, author = "Abhik Roy")
xaringan:::inf_mr()
xaringan:::inf_mr()
setwd("~/Documents/WVU/Teaching/GitHub.nosync/Workspace/edp617/static/slides/A Short Course on Evaluation Models")
setwd("~/Documents/WVU/Teaching/GitHub.nosync/Workspace/edp617")
xaringan:::inf_mr()
kable(basics,
escape = FALSE,
align = 'cc',) %>%
kable_styling(full_width = FALSE) %>%
column_spec(1, width = "30em") %>%
column_spec(2, width = "20em") %>%
row_spec(0, extra_css = 'vertical-align: middle !important;') %>%
row_spec(1, extra_css = 'vertical-align: middle !important;') %>%
row_spec(2, extra_css = 'vertical-align: middle !important;') %>%
row_spec(3, extra_css = 'vertical-align: middle !important;') %>%
row_spec(4, extra_css = 'vertical-align: middle !important;')
?kable
?kable
xaringan:::inf_mr()
? row_spec
xaringan:::inf_mr()
# Set the working directory as source ----
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
library(slidex)
library(here)
blogdown::build_site()
blogdown::serve_site()
blogdown:::update_meta_addin()
xaringan:::inf_mr()
xaringan:::inf_mr()
xaringan:::inf_mr()
blogdown::build_site()
blogdown::serve_site()
blogdown::build_site()
blogdown::serve_site()
blogdown::build_site()
blogdown::serve_site()
blogdown::build_site()
blogdown::serve_site()
xaringan:::inf_mr()
xaringan:::inf_mr()
xaringan:::inf_mr()
install.packages(c("e1071", "shinyWidgets"))
xaringan:::inf_mr()
xaringan:::inf_mr()
blogdown::build_site()
blogdown::serve_site()
xaringan:::inf_mr()
blogdown::build_site()
blogdown::serve_site()
setwd("~/Documents/WVU/Teaching/GitHub.nosync/Workspace/edp617")
blogdown::build_site()
blogdown::serve_site()
install.packages(c("odbc", "RCurl", "survival", "textshaping", "units", "wk", "XML"))
xaringan:::inf_mr()
setwd("~/Documents/WVU/Teaching/GitHub.nosync/Workspace/edp617/static/slides/Criterial and Interpretive Evaluation")
xaringan:::inf_mr()
xaringan:::inf_mr()
xaringan:::inf_mr()
xaringan:::inf_mr()
xaringan:::inf_mr()
xaringan:::inf_mr()
xaringan:::inf_mr()
xaringan:::inf_mr()
xaringan:::inf_mr()
xaringan:::inf_mr()
blogdown::build_site()
setwd("~/Documents/WVU/Teaching/GitHub.nosync/Workspace/edp617")
blogdown::build_site()
blogdown::serve_site()
blogdown:::insert_image_addin()
blogdown::build_site()
blogdown:::insert_image_addin()
blogdown::build_site()
blogdown::serve_site()
blogdown::build_site()
blogdown::serve_site()
blogdown::stop_server()
blogdown::build_site()
blogdown::stop_server()
blogdown::serve_site()
xaringan:::inf_mr()
install.packages("xaringan")
install.packages("xaringanthemer")
xaringan:::inf_mr()
xaringan:::inf_mr()
xaringan:::inf_mr()
xaringan:::inf_mr()
blogdown::build_site()
blogdown::serve_site()
setwd("~/Documents/WVU/Teaching/GitHub.nosync/Workspace/edp617/static/slides/Standards Based Evaluation")
xaringan:::inf_mr()
xaringan:::inf_mr()
setwd("~/Documents/WVU/Teaching/GitHub.nosync/Workspace/edp617/static/slides/Standards Based Evaluation")
xaringan:::inf_mr()
setwd("~/Documents/WVU/Teaching/GitHub.nosync/Workspace/edp617")
blogdown::build_site()
blogdown::serve_site()
# Set the working directory as source ----
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
pagedown::chrome_print("Data Collection.Rmd")
xaringan:::inf_mr()
# Set the working directory as source ----
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
pagedown::chrome_print("Data Collection.Rmd")
# Set the working directory as source ----
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
pagedown::chrome_print("Survey_Design.Rmd")
pagedown::chrome_print("Criterial and Interpretive Evaluation.Rmd")
# Set the working directory as source ----
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
pagedown::chrome_print("Data Collection.Rmd")
pagedown::chrome_print("Data Collection.Rmd")
# Set the working directory as source ----
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
pagedown::chrome_print("Data Collection.Rmd")
pagedown::chrome_print("Data Collection.Rmd")
setwd("~/Documents/WVU/Teaching/GitHub.nosync/Workspace/edp617/static/slides/Standards Based Evaluation")
xaringan:::inf_mr()
blogdown::build_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::build_site()
blogdown::serve_site()
setwd("~/Documents/WVU/Teaching/GitHub.nosync/Workspace/edp617")
blogdown::build_site()
blogdown::serve_site()
blogdown::check_config()
blogdown::check_site()
xfun::rstudio_type('"\\\\.knit\\\\.md$", "\\\\.utf8\\\\.md$"')
xfun::rstudio_type('"\\\\.knit\\\\.md$", "\\\\.utf8\\\\.md$"')
xfun::rstudio_type('"\\\\.knit\\\\.md$", "\\\\.utf8\\\\.md$"')
blogdown::check_config()
blogdown::check_config()
blogdown::check_config()
blogdown::check_site()
blogdown::build_site()
blogdown::serve_site()
