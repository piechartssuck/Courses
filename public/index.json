[{"authors":["admin"],"categories":null,"content":"I hold a Ph.D. in Program Evaluation and am an Assistant Professor of Educational Psychology within the Department of Counseling and Learning Sciences in the College of Education and Human Services at West Virginia University. I currently perform research on the teaching of developmental evaluation, modeling of social science concepts using machine learning, and in the construction of predictive social networks.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"0ebaba4b5b8aaba6189e8c7aaa6409a6","permalink":"https://edp693e.theoreticalphysed.com/author/dr.-abhik-roy/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/dr.-abhik-roy/","section":"authors","summary":"I hold a Ph.D. in Program Evaluation and am an Assistant Professor of Educational Psychology within the Department of Counseling and Learning Sciences in the College of Education and Human Services at West Virginia University.","tags":null,"title":"Dr. Abhik Roy","type":"authors"},{"authors":["admin"],"categories":null,"content":"Abhik Roy holds a Ph.D. in Program Evaluation and is an Assistant Professor of Educational Psychology within the Department of Learning Sciences and Human Development in the College of Education and Human Services at West Virginia University. He currently performs research on the teaching of developmental evaluation, modeling of social science concepts using machine learning, and in the construction of predictive social networks.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://edp693e.theoreticalphysed.com/author/dr.-abhik-roy/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/dr.-abhik-roy/","section":"authors","summary":"Abhik Roy holds a Ph.D. in Program Evaluation and is an Assistant Professor of Educational Psychology within the Department of Learning Sciences and Human Development in the College of Education and Human Services at West Virginia University.","tags":null,"title":"Dr. Abhik Roy","type":"authors"},{"authors":null,"categories":null,"content":"  Here are multiple resources and guides related to data, R and other relevant topics. None of these are required but could be helpful in or beyond the course!\n","date":1594771200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1594771200,"objectID":"8939c748f3090c6f91bdac5d32db55ec","permalink":"https://edp693e.theoreticalphysed.com/resource/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/resource/","section":"resource","summary":"Here are multiple resources and guides related to data, R and other relevant topics. None of these are required but could be helpful in or beyond the course!","tags":null,"title":"Helpful resources","type":"docs"},{"authors":null,"categories":null,"content":"   Keeping Up Lessons  Need Help?    Foremost please note that these pages populate information about course related tasks on the left hand side when they are assigned. Due dates are given within the description of each assignment.\nKeeping Up There are a lot of moving parts to this class. Students who gain the most out of the course generally follow these general notions:\nEngaging with the readings and materials; Following all R related materials and using the software to complete any data wrangling or analysis; Putting in a solideffort but also asking for help when needed; Keeping a respectful, open, and honest line of communication with me and your peers if possible.   Lessons Most class sessions have interactive modules via Data Camp. Your task is simply to go through these.\nI will grade these modules using a check system:\n ✔+: (11.5 points (115%) in gradebook) Modules are 100% completed. Every task was attempted and answered, and most answers are correct. These are not earned often. ✔: (10 points (100%) in gradebook) Modules are 70–99% complete and answers are more or less on point. This is the expected level of performance. ✔−: (5 points (50%) in gradebook) Modules are less than 70% complete and most answers are generally off-point. This indicates that you likely need to do something like putting in ore of an effort or asking for help. Hopefully people will not earn this often.  Otherwise 0 points (0%) in gradebook.\nNeed Help? I always prefer a face to face meeting if possible but since that’s not possible, you can schedule a Zoom via the Calendar or contact me within Slack by tagging my name @Dr. Abhik Roy in a text box along with your message.\n  ","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":-62135596800,"objectID":"3aa23ffb1eb3dedbe4d8a9c2165e2c58","permalink":"https://edp693e.theoreticalphysed.com/assignment/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/assignment/","section":"assignment","summary":"Keeping Up Lessons  Need Help?    Foremost please note that these pages populate information about course related tasks on the left hand side when they are assigned.","tags":null,"title":"About the Assignments","type":"docs"},{"authors":null,"categories":null,"content":"  This section contains extra material to supplement what is covered that week. Sometimes this is just a few links for you to look at and other times its fully annotated R code that you can use as a reference for helping you along with a task. Please access the material on this site this section after you have finished the reading(s).\nFrom time to time, it may also contains video of coding some examples pieces so you can see what it looks like to work with R in real time. You’ll definitely notice that I make all sorts of errors, which is absolutely normal and happens to everyone!\nNeed Help? I always prefer a face to face meeting if possible but since that’s not possible, you can schedule a Zoom via the Calendar or contact me within Slack by tagging my name @Dr. Abhik Roy in a text box along with your message.\n ","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":-62135596800,"objectID":"00e8826988eea7dfc8b8047b4c0184ce","permalink":"https://edp693e.theoreticalphysed.com/example/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/example/","section":"example","summary":"This section contains extra material to supplement what is covered that week. Sometimes this is just a few links for you to look at and other times its fully annotated R code that you can use as a reference for helping you along with a task.","tags":null,"title":"About the Examples","type":"docs"},{"authors":null,"categories":null,"content":"   Description Each class session has an interactive lesson that you will work through after doing the readings and watching a lecture (if applicable). These lessons are a central part of the class—they will teach you how to use R and other packages eventually leading to the tidyverse family.\nInteractive training sections are provided on Data Camp1.\n Advice Carve out some time everyday to go through these. If you try to complete everything in one sitting, it will probably be overwhelming! However if you have familiarity with some modules, please feel free to work ahead.\n Grading The ultimate point of Data Camp is to get you familiarized with an environment that you likely have never seen or been exposed to. While you should absolutely go through each module, there is certainly no expectation that you will get everything right. In fact, the points that you incur don’t mean anything as far as how you are assessed so please use hints as needed! As with any things data science, you’ll learn by doing. If you are a polar personality type when it comes to work (i.e. primarily a perfectionist or mostly careless), then the modules will likely prove to be a challenge. It is highly unlikely that you will be able to comprehend everything by going beyond your limit or that it will just come to you so please work hard but also take breaks, swear2, and ask peers or me for help. Your grading is predicated on putting in a solid effort, rather than getting it right because there is no such thing in data science.\n Data Camp Schedule A tentative schedule is given below. The Course and Chapter names represent Data Camp titles3:\n  Exploration  Lesson Page  Due by  Required  Course or Project Name  Chapters covered      1  Week 1  1/27/21     Introduction to R  Intro to Basics, Vectors, Matrices, Factors, Data Frames, Lists    2  Week 2  2/3/21     Introduction to Data in R  Language of Data, Study Types and Cautionary Tales, Sampling Strategies and Experimental Design, Case Study      2/3/21     Data Visualization in R  A Quick Introduction to Base R Graphics, Different Plot Types, Adding Details to Plots, How Much is Too Much?, Advanced Plot Customization and Beyond    3  Week 3  2/10/21     Intermediate R  Conditionals and Control Flow, Loops, Functions, The apply Family, Utilities    4  Week 4  2/17/21     Exploratory Data Analysis in R  Exploring Categorical Data, Exploring Numerical Data, Numerical Summaries, Case study      2/17/21     Introduction to the Tidyverse  Data Wrangling, Data Visualization, Grouping and Summarizing, Types of Visualizations    5  Week 5  2/24/21     Reporting with R Markdown  Getting Started with R Markdown, Adding Analyses and Visualizations, Improving the Report, Customizing the Report      2/24/21     Introduction to Data Visualization with ggplot2  Introduction, Aesthetics, Geometries, Themes    6  Week 6  3/3/21     Intermediate Data Visualization with ggplot2  Statistics, Coordinates, Facets, Best Practices      3/3/21     Visualization Best Practices in R  Proportions of a Whole, Point Data, Single Distributions, Comparing Distributions    7  Week 7  3/17/21     Analyzing US Census Data in R  Census Data in R with tidycensus, Wrangling US Census Data, US Census Geographic Fata in R, Mapping US Census Data    8  Week 8  3/24/21     Text Mining with Bag-of-Words in R  Jumping Into Text Mining with Bag Of Words, Word Clouds and More Interesting Visuals, Adding to your tm Skills, Battle of the Tech Giants for Talent      3/24/21     Sentiment Analysis in R  Fast \u0026amp; Dirty: Polarity Scoring, Sentiment Analysis the Tidytext Way, Visualizing Sentiment, Case Study: Airbnb Reviews    9  Week 9  3/31/21     Network Analysis in the Tidyverse  The Hubs of the Network, In Its Weakness Lies Its Strength, Connection Patterns, Similarity Clusters      3/31/21     Visualizing Geospatial Data in R  Basic Mapping with ggplot2 and ggmap, Point and Polygon Data, Raster Data and Color, Data Import and Projections    10  Week 10  4/7/21     Building Web Applications with Shiny in R  Get Started with Shiny, Inputs, Outputs, and Layouts, Reactive Programming, Build Shiny Apps      4/7/21     Case Studies: Building Web Applications with Shiny in R  Shiny Review, Make the Perfect Plot Using Shiny, Explore a Dataset Interactively With Shiny ,Create Your Own Word Cloud in Shiny    11  Week 11  4/14/21     Introduction to Tableau  Getting Started with Tableau, Building and Customizing Visualizations, Digging Deeper, Presenting Your Data      4/14/21     Connecting Data in Tableau  Combining and Saving Data, Managing and Connecting Data    12  Week 12  4/21/21     Analyzing Data in Tableau  Preparing for Analysis, Exploring Visualizations, Mapping Analysis, Groups, Sets, and Parameters    12  Week 13  4/28/21     Creating Dashboards in Tableau  Getting Started With Dashboards, Sharing Data Insights    EC1  Week 14  5/3/21     Analyzing Survey Data in R  Introduction to survey data, Exploring categorical data, Exploring quantitative data, Modeling quantitative data    EC2  Week 14  5/3/21     Communicating with Data in the Tidyverse  Building Static Dashboards, Building Dynamic Dashboards, Customizing Style, Case Study    EC3  Week 14  5/3/21     Building Dashboards with shinydashboard  Building Static Dashboards, Building Dynamic Dashboards, Customizing Style, Case Study      Need Help? I always prefer a face to face meeting if possible but since that’s not possible, you can schedule a Zoom via the Calendar or contact me within Slack by tagging my name @Dr. Abhik Roy in a text box along with your message.\n  Please note that if you have (1) used Data Camp before and (2) are logged in with the same username, then any module that was successfully completed will not have to be done again.↩︎\n and curse my name if you have to↩︎\n Please note this is subject to change with notice.↩︎\n   ","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":-62135596800,"objectID":"45e63e789e3cb381d68e4ca47e0a453c","permalink":"https://edp693e.theoreticalphysed.com/lesson/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/lesson/","section":"lesson","summary":"Description Each class session has an interactive lesson that you will work through after doing the readings and watching a lecture (if applicable). These lessons are a central part of the class—they will teach you how to use R and other packages eventually leading to the tidyverse family.","tags":null,"title":"About the Lessons","type":"docs"},{"authors":null,"categories":null,"content":"  The Course Texts The course texts are generally for reference purposes. Please browse through the but know that in general, reading code is neither fun nor overtly beneficial. Instead you will learn by doing (and likely failing multiple times) but in the end and while it may sound silly, there is no better feeling than getting a piece of code to work correctly!\n The Course Nontext Many of us are visual learners with me included, so a lot of what I provide outside of the text and created in-house is visually based. Resources such as presentations, videos, visualizations, walkthroughs, etc. take a lot of time to construct so please go through them. Are they Hollywood? No because I’m a professor at a public university, have three children and drive a car with duct tape on it BUT they will be decent. I am always open to suggestions so if you have any, send them along! Pictures are better than words because some words are big and hard to understand. - Peter Griffin\nNeed Help? I always prefer a face to face meeting if possible but since that’s not possible, you can schedule a Zoom via the Calendar or contact me within Slack by tagging my name @Dr. Abhik Roy in a text box along with your message.\n  ","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":-62135596800,"objectID":"0aa019bdc1e0c98e24563159b8fa2f91","permalink":"https://edp693e.theoreticalphysed.com/readings/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/readings/","section":"readings","summary":"The Course Texts The course texts are generally for reference purposes. Please browse through the but know that in general, reading code is neither fun nor overtly beneficial. Instead you will learn by doing (and likely failing multiple times) but in the end and while it may sound silly, there is no better feeling than getting a piece of code to work correctly!","tags":null,"title":"About the Readings","type":"docs"},{"authors":null,"categories":null,"content":"  This section will let you know what must be completed for assessment purposes. You should still do everything else because those items are still expected and you will be scored on those skills eventually on some other course related task.\nNeed Help? I always prefer a face to face meeting if possible but since that’s not possible, you can schedule a Zoom via the Calendar or contact me within Slack by tagging my name @Dr. Abhik Roy in a text box along with your message.\n ","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":-62135596800,"objectID":"140e53d0243061ae64e96f1d35188d6a","permalink":"https://edp693e.theoreticalphysed.com/due/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/due/","section":"due","summary":"This section will let you know what must be completed for assessment purposes. You should still do everything else because those items are still expected and you will be scored on those skills eventually on some other course related task.","tags":null,"title":"So What's Due?","type":"docs"},{"authors":null,"categories":null,"content":"  You can download a BibTeX file of all the readings in the course:\n  references.bib  You can open the file in BibDesk on macOS, JabRef on Windows/macOS, or Zotero or Mendeley online.\nIf you are comfortable with the terminal in a Mac, then the bib2ris may be easy to implement.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"68be32a8da6a38dd54a9e724ab3904a0","permalink":"https://edp693e.theoreticalphysed.com/resource/citations/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/resource/citations/","section":"resource","summary":"You can download a BibTeX file of all the readings in the course:\n  references.bib  You can open the file in BibDesk on macOS, JabRef on Windows/macOS, or Zotero or Mendeley online.","tags":null,"title":"Citations and bibliography","type":"docs"},{"authors":null,"categories":null,"content":"   First Timers Note  Class Slack Account Access Find a bad graphic    First Timers Note You’ll see class related tasks posted here on a weekly basis.\nClass Slack Account Access Most important task of the week - well to me at least - is to\nGo to the course Slack account Register if you already do not have an account. Note that you do not have to use your WVU account, but its not a bad idea.   Find a bad graphic Find a bad plot in the media or online.\nSubmit via eCampus a .pdf or .docx (Word) document that includes:\nA cover page with your name and a title in the upper left hand corner. A copy of your plot. Information on the source (a citation or webpage address).\n Short succinct answers to the following questions: Is it bad because it is misleading, or because it is unclear or both? How would you improve it? What rules (from Wainer’s paper) does it follow and which principles (Chapter 2 in Tufte) does it violate?   Please post a copy of your entire task to the Slack channel #week1-class-task.\n:::\n  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"94cae82c16c517ab19420570e5d8c2ad","permalink":"https://edp693e.theoreticalphysed.com/assignment/01-assignment/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/assignment/01-assignment/","section":"assignment","summary":"First Timers Note  Class Slack Account Access Find a bad graphic    First Timers Note You’ll see class related tasks posted here on a weekly basis.","tags":null,"title":"Friends Don't Let Friends Use Pie Charts","type":"docs"},{"authors":null,"categories":null,"content":"    What’s Due?   What’s Due?    Data Camp  eCampus  R  Slack  Description  Location                  Install Course Software  Link                Read a few things  Link                Look over the website  Link                Get into the course Slack account  Link                Find a bad graphic  Link                Complete Introduction to R  Link      Note: These tasks are provided in a recommended order.\n ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"2ac82a4ccda585b1b2dd58a008ca65ad","permalink":"https://edp693e.theoreticalphysed.com/due/01-due/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/due/01-due/","section":"due","summary":"What’s Due?   What’s Due?    Data Camp  eCampus  R  Slack  Description  Location                  Install Course Software  Link                Read a few things  Link                Look over the website  Link                Get into the course Slack account  Link                Find a bad graphic  Link                Complete Introduction to R  Link      Note: These tasks are provided in a recommended order.","tags":null,"title":"Friends Don't Let Friends Use Pie Charts","type":"docs"},{"authors":null,"categories":null,"content":"   First Timers Note   First Timers Note You’ll see extra examples of visualizations and full code chunks you can copy or download directly into RStudio to edit as you want.\n ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"059bb398e999a9d10b388c3df2b5644f","permalink":"https://edp693e.theoreticalphysed.com/example/01-example/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/example/01-example/","section":"example","summary":"First Timers Note   First Timers Note You’ll see extra examples of visualizations and full code chunks you can copy or download directly into RStudio to edit as you want.","tags":null,"title":"Friends Don't Let Friends Use Pie Charts","type":"docs"},{"authors":null,"categories":null,"content":"   First Timers Note Data Camp Installing R and RStudio   First Timers Note You’ll see R related walkthroughts and other possible course tasks posted here every week.\n Data Camp The purpose of these modules is not have you become a programmer! Rather these lay a foundation for a common language and software we’ll be using. Some are better than others and some are more technical than others as well. Just remember, this is not a programming class but you need to ask for help when needed! Falling behind on these can make some material we cover in the course inaccessible. If you get stuck, please search the Internet, ask your peers or me for help or worst case scenario, move on!\nWith that said, please go ahead and start the first module covering the basics of R on Data Camp. There is a lot on there and please refer to the syllabus for the grading policy regarding those tasks.\n Installing R and RStudio Go to the Installing R, RStudio, and tidyverse page under Resources to get both R and RStudio installed on your system.\n ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"2248ef62e0fddbf88b2832cdafb38b9a","permalink":"https://edp693e.theoreticalphysed.com/lesson/01-lesson/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/lesson/01-lesson/","section":"lesson","summary":"First Timers Note Data Camp Installing R and RStudio   First Timers Note You’ll see R related walkthroughts and other possible course tasks posted here every week.","tags":null,"title":"Friends Don't Let Friends Use Pie Charts","type":"docs"},{"authors":null,"categories":null,"content":"    First Timers Note  Get Some Advice Review the Rest Read Things     .hvr-sweep-to-left { display: inline-block; vertical-align: middle; -webkit-transform: perspective(1px) translateZ(0); transform: perspective(1px) translateZ(0); box-shadow: 0 0 1px rgba(0, 0, 0, 0); position: relative; -webkit-transition-property: color; transition-property: color; -webkit-transition-duration: 0.25s; transition-duration: 0.25s; } .hvr-sweep-to-left:before { content: \"\"; position: absolute; z-index: -1; top: 0; left: 0; right: 0; bottom: 0; background: #175676; -webkit-transform: scaleX(0); transform: scaleX(0); -webkit-transform-origin: 100% 50%; transform-origin: 100% 50%; -webkit-transition-property: transform; transition-property: transform; -webkit-transition-duration: 0.3s; transition-duration: 0.3s; -webkit-transition-timing-function: ease-out; transition-timing-function: ease-out; } .hvr-sweep-to-left:hover, .hvr-sweep-to-left:focus, .hvr-sweep-to-left:active { color: white; } .hvr-sweep-to-left:hover:before, .hvr-sweep-to-left:focus:before, .hvr-sweep-to-left:active:before { -webkit-transform: scaleX(1); transform: scaleX(1); }  First Timers Note You’ll see all class related readings posted here on a weekly basis. With that said, take a look at the items below:\nGet Some Advice First things first: Read the syllabus. Far be it from us to disagree with Snoop, so you should probably go read the syllabus as soon as possible!\n Review the Rest Review the overviews of the other areas as well: Assignments, Examples, Lessons, and Schedule pages for this class.\n Read Things Data visualization isn’t just about making pretty pictures1, rather it is done to convey a great deal of information in an efficient way. With that said, you have probably come across visualizations in the media, online, etc that simply don’t make sense or are confusing. Can you recall one that was just terrible? Think about that question as you go through this week’s readings:\nWAINER, H. (1984). How to Display Data Badly. The American Statistician, 38(2), 137-147. Tufte, E. R. (2001). Graphical Excellence. The visual display of quantitative information (2nd ed., pp. 13-51). Graphics Press. Tufte, E. R. (2001). Graphical Integrity. The visual display of quantitative information (2nd ed., pp. 52-77). Graphics Press.   Download the Readings     although that is very important!↩︎\n   ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"0ca270d2bbdb77aeeab9c41859c1ca7a","permalink":"https://edp693e.theoreticalphysed.com/readings/01-readings/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/readings/01-readings/","section":"readings","summary":"First Timers Note  Get Some Advice Review the Rest Read Things     .hvr-sweep-to-left { display: inline-block; vertical-align: middle; -webkit-transform: perspective(1px) translateZ(0); transform: perspective(1px) translateZ(0); box-shadow: 0 0 1px rgba(0, 0, 0, 0); position: relative; -webkit-transition-property: color; transition-property: color; -webkit-transition-duration: 0.","tags":null,"title":"Friends Don't Let Friends Use Pie Charts","type":"docs"},{"authors":null,"categories":null,"content":"    Create Plots in Base R    .hvr-sweep-to-left { display: inline-block; vertical-align: middle; -webkit-transform: perspective(1px) translateZ(0); transform: perspective(1px) translateZ(0); box-shadow: 0 0 1px rgba(0, 0, 0, 0); position: relative; -webkit-transition-property: color; transition-property: color; -webkit-transition-duration: 0.25s; transition-duration: 0.25s; } .hvr-sweep-to-left:before { content: \"\"; position: absolute; z-index: -1; top: 0; left: 0; right: 0; bottom: 0; background: #733367; -webkit-transform: scaleX(0); transform: scaleX(0); -webkit-transform-origin: 100% 50%; transform-origin: 100% 50%; -webkit-transition-property: transform; transition-property: transform; -webkit-transition-duration: 0.3s; transition-duration: 0.3s; -webkit-transition-timing-function: ease-out; transition-timing-function: ease-out; } .hvr-sweep-to-left:hover, .hvr-sweep-to-left:focus, .hvr-sweep-to-left:active { color: white; } .hvr-sweep-to-left:hover:before, .hvr-sweep-to-left:focus:before, .hvr-sweep-to-left:active:before { -webkit-transform: scaleX(1); transform: scaleX(1); }  Create Plots in Base R Use the file AlcoholConsumption.csv to create three plots such that two are misleading or misrepresent the data while the other is indicative of what the data truly is. You are asked to stick to Base R even if you have working knowledge of tidyverse commands, though this is not a requirement. Please submit this as a single R script replacing only the areas that ask you to do so.\n# Replace this with your name # Misleading/misrepresented 1 ---- ## Put your entire code for the plot under this line ---- # ~ Replace this with a basic explanation of why it is misleading and/or misrepresented ---- # -- # Misleading/misrepresented 2 ---- ## ## Put your entire code for the plot under this line ---- # ~ A basic explanation of why it is misleading and/or misrepresented ---- # -- # True version ---- ## ## Put your entire code for the plot under this line ---- # ~ A basic explanation of why it is misleading and/or misrepresented ----  Download the Script   Download the Data  \nNotice that there are four dashes (----) after the text in every # except on the line where you should place your name. This provides a nested outline of your script that is easier to follow, especially if they get long.\nThere are a few ways to get to your outline. As you transition from a dependence on your mouse/trackpad to the old school keyboard, having a working knowledge of shortcuts creates a less disruptive experience than say having to grab that mouse/trackpad everytime you want to do something other than typing. To access the outline of your sections and subsections within an R script, hold down the keys control shift o1\nTo learn more about nesting, take a look at this post titled The Little Things.\nPlease submit your script to eCampus under Week 2 Out of Class Task.\n  The letter o not zero.↩︎\n   ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"b6a0ce80cabafe6d7d9f272294abfa85","permalink":"https://edp693e.theoreticalphysed.com/assignment/02-assignment/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/assignment/02-assignment/","section":"assignment","summary":"Create Plots in Base R    .hvr-sweep-to-left { display: inline-block; vertical-align: middle; -webkit-transform: perspective(1px) translateZ(0); transform: perspective(1px) translateZ(0); box-shadow: 0 0 1px rgba(0, 0, 0, 0); position: relative; -webkit-transition-property: color; transition-property: color; -webkit-transition-duration: 0.","tags":null,"title":"Base R is a Thing","type":"docs"},{"authors":null,"categories":null,"content":"    What’s Due?   What’s Due?    Data Camp  eCampus  R  Slack  Description  Location                  Read a couple papers  Link                Create two bad and one good visualization in Base R  Link                Complete two modules  Link      Note: These tasks are provided in a recommended order.\n ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"ac09a96a006ea325c7f2e74716cc60ae","permalink":"https://edp693e.theoreticalphysed.com/due/02-due/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/due/02-due/","section":"due","summary":"What’s Due?   What’s Due?    Data Camp  eCampus  R  Slack  Description  Location                  Read a couple papers  Link                Create two bad and one good visualization in Base R  Link                Complete two modules  Link      Note: These tasks are provided in a recommended order.","tags":null,"title":"Base R is a Thing","type":"docs"},{"authors":null,"categories":null,"content":"    Getting Prepped  First Things First! Set your Working Directory Download the script Foundational Structures Data Types Classes  Example: 100% Fake Data   Data Frames - A Format You Absolutely Want  Importing and Viewing Data Looking at Variables in a Data Frame Assigning Variables Basic Visualizations  A Bit of Context Basic Visualizations  Histograms Line Graph Scatterplots Boxplots  Plot Options  Rendering more than one plot in a window     .hvr-sweep-to-left { display: inline-block; vertical-align: middle; -webkit-transform: perspective(1px) translateZ(0); transform: perspective(1px) translateZ(0); box-shadow: 0 0 1px rgba(0, 0, 0, 0); position: relative; -webkit-transition-property: color; transition-property: color; -webkit-transition-duration: 0.25s; transition-duration: 0.25s; } .hvr-sweep-to-left:before { content: \"\"; position: absolute; z-index: -1; top: 0; left: 0; right: 0; bottom: 0; background: #003277; -webkit-transform: scaleX(0); transform: scaleX(0); -webkit-transform-origin: 100% 50%; transform-origin: 100% 50%; -webkit-transition-property: transform; transition-property: transform; -webkit-transition-duration: 0.3s; transition-duration: 0.3s; -webkit-transition-timing-function: ease-out; transition-timing-function: ease-out; } .hvr-sweep-to-left:hover, .hvr-sweep-to-left:focus, .hvr-sweep-to-left:active { color: white; } .hvr-sweep-to-left:hover:before, .hvr-sweep-to-left:focus:before, .hvr-sweep-to-left:active:before { -webkit-transform: scaleX(1); transform: scaleX(1); }  Getting Prepped First Things First! Set your Working Directory Your working directory is simply where your script will look for anything it needs like external data sets. There are a few ways to go about doing this which we will cover. However for now, just do the following:\nOpen up a new script by going to File \u0026gt; New File \u0026gt; R Script. Save it in a preferably empty folder as whatever you want. Go to the menu bar and select Session \u0026gt; Set Working Directory \u0026gt; To Source File Location.   Download the script Copying and pasting syntax from a browser can cause problems. To avoid this issue, please download a script with all of the needed code presented in this walkthrough.\n Download the Script   Foundational Structures Akin to how atoms were viewed as the building blocks of life, these are the basic structures of R.\n vector - The very basic structure of R where one type of information can be stored. These are given by a single row or column of things that have to be the same data type.\nnothing_vector \u0026lt;- c() nothing_vector ## NULL number_vector \u0026lt;- c(1,2,3,4,5) number_vector ## [1] 1 2 3 4 5 character_vector \u0026lt;- c( \u0026quot;Oban\u0026quot;, \u0026quot;Macallan\u0026quot;, \u0026quot;Pittyvaich\u0026quot;, \u0026quot;Balblair\u0026quot;, \u0026quot;Glenmorangie\u0026quot; ) character_vector ## [1] \u0026quot;Oban\u0026quot; \u0026quot;Macallan\u0026quot; \u0026quot;Pittyvaich\u0026quot; \u0026quot;Balblair\u0026quot; \u0026quot;Glenmorangie\u0026quot; object - These are the different ways you can structure your data to do something with it. All objects are made up of one or more vectors.\n   Data Types There are six types of data that R can read on its own without the help of any other piece of software. These are known as atomic vectors where atomic means the vector only holds data of a single type\ncharacter: “a”, “swc” numeric: 2, 15.5 integer: 2L (the L tells R to store this as an integer) logical: TRUE, FALSE complex: 1+4i (complex numbers with real and imaginary parts)1 raw: 01010010   Classes A class is the blueprint that helps to create an object. These are\n matrix - A two-dimensional object made up of rows and columns. These are essentially a bunch of vectors stacked on top or beside each other that have to be the same data type.\nsome_matrix \u0026lt;- matrix(c(1,1,2,3,5,8), nrow = 2, ncol = 3) some_matrix  ## [,1] [,2] [,3] ## [1,] 1 2 5 ## [2,] 1 3 8 array - A three-dimensional object made up of a bunch of matrices that have to be the same data type.\nsome_array \u0026lt;- array(1, dim = c(2, 3, 3)) some_array ## , , 1 ## ## [,1] [,2] [,3] ## [1,] 1 1 1 ## [2,] 1 1 1 ## ## , , 2 ## ## [,1] [,2] [,3] ## [1,] 1 1 1 ## [2,] 1 1 1 ## ## , , 3 ## ## [,1] [,2] [,3] ## [1,] 1 1 1 ## [2,] 1 1 1 dataframe - Similar to a matrix, BUT columns can vary by data type.\nsome_df \u0026lt;- data.frame(col1 = 1:3, col2 = c(\u0026quot;take\u0026quot;, \u0026quot;a\u0026quot;, \u0026quot;nap\u0026quot;), col3 = c(TRUE, FALSE, TRUE), col4 = c(1.5, 3.2, pi)) some_df ## col1 col2 col3 col4 ## 1 1 take TRUE 1.500000 ## 2 2 a FALSE 3.200000 ## 3 3 nap TRUE 3.141593 list - A set of objects.\nsome_list \u0026lt;-list(1,2,3,4,5) some_list ## [[1]] ## [1] 1 ## ## [[2]] ## [1] 2 ## ## [[3]] ## [1] 3 ## ## [[4]] ## [1] 4 ## ## [[5]] ## [1] 5  Example: 100% Fake Data height \u0026lt;- c(145,167,176,123,150) weight \u0026lt;- c(51,63,64,40,55) Both height and weight are called variables because they have been assigned a bunch of stuff which in this case are integers. Well we have these, might as well do something with them.\nheight \u0026lt;- c(145, 167, 176, 123, 150) weight \u0026lt;- c(51, 63, 64, 40, 55) plot(height,weight) Well that wasn’t exciting at all was it? It’ll get interesting soon.\nR provides many functions to examine features of vectors and other objects, for example\nclass() - what kind of object is it (high-level)? typeof() - what is the object’s data type (low-level)? length() - how long is it? What about two dimensional objects? attributes() - does it have any metadata? (underlying set of data that describes and gives information about other data)  class(weight) # Yup there are numbers so numeric makes sense. ## [1] \u0026quot;numeric\u0026quot; typeof(weight) # You see the term \u0026#39;double\u0026#39; here but you may also see \u0026#39;single\u0026#39; or \u0026#39;integer\u0026#39;. All this refers to is the precision of the number and you can assume they are all integers. ## [1] \u0026quot;double\u0026quot; length(weight) # There are 5 objects in weight so length(weight) = 5 makes sense. ## [1] 5 attributes(weight) # Null since there isn\u0026#39;t any other information except for what you see. ## NULL    Data Frames - A Format You Absolutely Want We want all of our data to be in this form. A data frame is a table or a two-dimensional array-like structure in which each column contains values of one variable and each row contains one set of values from each column. Characteristics of a data frame are as follows and in no particular order:\nThe column names should be non-empty. The row names should be unique. The data stored in a data frame can be of numeric, factor or character type. Each column should contain same number of data items.  NOTE: You can always check if a variable is a data frame by is.data.frame(whatever)\nImporting and Viewing Data Read in the file USpop2010to2017.csv that has data on US population estimates from 2010 to 2017. You can do this in multiple ways but for now and since you’re getting used to menu. To bring in the file, go to the Environment tab in the upper right window and then Import Dataset \u0026gt; From Text (readr) \u0026gt; Browse to find your file and load it in. Before clicking on the Import button, name the variable population under Import options. You should get an output similar to the one shown below.\nBut know that we will be moving away from the idea of using a mouse/trackpad to do things because it wastes time and is generally disruptive. Instead we’ll use the file’s relative path, that is the locations of all other files in comparison to your script to bring in data. If the USpop2010to2017.csv data set is in the same folder as your script, then run the following command\npopulation \u0026lt;- read.csv(\u0026quot;USpop2010to2017.csv\u0026quot;, header = TRUE, stringsAsFactors = TRUE)  Now take a look at the file by running\npopulation ## Census_ID Collection_year Total_Pop Male_Pop Female_Pop Estimate ## 1 POPESTIMATE2010 2010 309338421 152082993 157255428 N ## 2 POPESTIMATE2011 2011 311644280 153242210 158402070 Y ## 3 POPESTIMATE2012 2012 313993272 154452348 159540924 Y ## 4 POPESTIMATE2013 2013 316234505 155596820 160637685 Y ## 5 POPESTIMATE2014 2014 318622525 156807419 161815106 Y ## 6 POPESTIMATE2015 2015 321039839 158048153 162991686 Y ## 7 POPESTIMATE2016 2016 323405935 159243817 164162118 Y ## 8 POPESTIMATE2017 2017 325719178 160408119 165311059 Y Well that is long and annoying. We can use the head() command to make it only display six lines.\nhead(population) ## Census_ID Collection_year Total_Pop Male_Pop Female_Pop Estimate ## 1 POPESTIMATE2010 2010 309338421 152082993 157255428 N ## 2 POPESTIMATE2011 2011 311644280 153242210 158402070 Y ## 3 POPESTIMATE2012 2012 313993272 154452348 159540924 Y ## 4 POPESTIMATE2013 2013 316234505 155596820 160637685 Y ## 5 POPESTIMATE2014 2014 318622525 156807419 161815106 Y ## 6 POPESTIMATE2015 2015 321039839 158048153 162991686 Y or any number actually\nhead(population, 4) ## Census_ID Collection_year Total_Pop Male_Pop Female_Pop Estimate ## 1 POPESTIMATE2010 2010 309338421 152082993 157255428 N ## 2 POPESTIMATE2011 2011 311644280 153242210 158402070 Y ## 3 POPESTIMATE2012 2012 313993272 154452348 159540924 Y ## 4 POPESTIMATE2013 2013 316234505 155596820 160637685 Y You can actually look at the entire dataset in a spreadsheet like window by using\nView(population) If you want to know more about how a data set is made up you can use the command str() or glimpse(). This essentially asks R for information about the internal structure of any set of data.\nstr(population) ## \u0026#39;data.frame\u0026#39;: 8 obs. of 6 variables: ## $ Census_ID : chr \u0026quot;POPESTIMATE2010\u0026quot; \u0026quot;POPESTIMATE2011\u0026quot; \u0026quot;POPESTIMATE2012\u0026quot; \u0026quot;POPESTIMATE2013\u0026quot; ... ## $ Collection_year: int 2010 2011 2012 2013 2014 2015 2016 2017 ## $ Total_Pop : int 309338421 311644280 313993272 316234505 318622525 321039839 323405935 325719178 ## $ Male_Pop : int 152082993 153242210 154452348 155596820 156807419 158048153 159243817 160408119 ## $ Female_Pop : int 157255428 158402070 159540924 160637685 161815106 162991686 164162118 165311059 ## $ Estimate : chr \u0026quot;N\u0026quot; \u0026quot;Y\u0026quot; \u0026quot;Y\u0026quot; \u0026quot;Y\u0026quot; ... glimpse(population) ## Rows: 8 ## Columns: 6 ## $ Census_ID \u0026lt;chr\u0026gt; \u0026quot;POPESTIMATE2010\u0026quot;, \u0026quot;POPESTIMATE2011\u0026quot;, \u0026quot;POPESTIMATE201… ## $ Collection_year \u0026lt;int\u0026gt; 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017 ## $ Total_Pop \u0026lt;int\u0026gt; 309338421, 311644280, 313993272, 316234505, 318622525… ## $ Male_Pop \u0026lt;int\u0026gt; 152082993, 153242210, 154452348, 155596820, 156807419… ## $ Female_Pop \u0026lt;int\u0026gt; 157255428, 158402070, 159540924, 160637685, 161815106… ## $ Estimate \u0026lt;chr\u0026gt; \u0026quot;N\u0026quot;, \u0026quot;Y\u0026quot;, \u0026quot;Y\u0026quot;, \u0026quot;Y\u0026quot;, \u0026quot;Y\u0026quot;, \u0026quot;Y\u0026quot;, \u0026quot;Y\u0026quot;, \u0026quot;Y\u0026quot; This may seem like a mess but it actually tells you a lot. First thing you should notice is that all of the columns are laid out into lines to be “easily” readable but the structure of the data set does not change! Here is some other important things in no particular order:\nWe have an 8 x 5 matrix (aka a data set with 8 columns and 5 rows) It is a data frame with variables given by $. More about this below. The first column is a character vector (made up only of strings of text). The remaining columns are integer vectors (made up only of numbers in the form of integers). You may be wondering why we skipped over the factors and levels. That’s a bit complicated for this session but we will get to it because they play an important role in visualizing the data.   Looking at Variables in a Data Frame To call a variable in the dataframe, we use the $ notation.\npopulation$Census_ID ## [1] \u0026quot;POPESTIMATE2010\u0026quot; \u0026quot;POPESTIMATE2011\u0026quot; \u0026quot;POPESTIMATE2012\u0026quot; \u0026quot;POPESTIMATE2013\u0026quot; ## [5] \u0026quot;POPESTIMATE2014\u0026quot; \u0026quot;POPESTIMATE2015\u0026quot; \u0026quot;POPESTIMATE2016\u0026quot; \u0026quot;POPESTIMATE2017\u0026quot; Now try to use the same method for the other two columns.\n  Solutions  population$Collection_year ## [1] 2010 2011 2012 2013 2014 2015 2016 2017 population$Total_Pop ## [1] 309338421 311644280 313993272 316234505 318622525 321039839 323405935 ## [8] 325719178 population$Male_Pop ## [1] 152082993 153242210 154452348 155596820 156807419 158048153 159243817 ## [8] 160408119 population$Female_Pop ## [1] 157255428 158402070 159540924 160637685 161815106 162991686 164162118 ## [8] 165311059   Assigning Variables Now let’s call these something because writing those out over and over is annoying\ncensus \u0026lt;- population$Census_ID census ## [1] \u0026quot;POPESTIMATE2010\u0026quot; \u0026quot;POPESTIMATE2011\u0026quot; \u0026quot;POPESTIMATE2012\u0026quot; \u0026quot;POPESTIMATE2013\u0026quot; ## [5] \u0026quot;POPESTIMATE2014\u0026quot; \u0026quot;POPESTIMATE2015\u0026quot; \u0026quot;POPESTIMATE2016\u0026quot; \u0026quot;POPESTIMATE2017\u0026quot; or to do this quicker, use a semicolon ;.\ncensus \u0026lt;- population$Census_ID; census ## [1] \u0026quot;POPESTIMATE2010\u0026quot; \u0026quot;POPESTIMATE2011\u0026quot; \u0026quot;POPESTIMATE2012\u0026quot; \u0026quot;POPESTIMATE2013\u0026quot; ## [5] \u0026quot;POPESTIMATE2014\u0026quot; \u0026quot;POPESTIMATE2015\u0026quot; \u0026quot;POPESTIMATE2016\u0026quot; \u0026quot;POPESTIMATE2017\u0026quot; Now try to use the same method for the other columns by using the variables year, total, male and female, respectively.\n  Solutions  year \u0026lt;- population$Collection_year; year ## [1] 2010 2011 2012 2013 2014 2015 2016 2017 total \u0026lt;- population$Total_Pop; total ## [1] 309338421 311644280 313993272 316234505 318622525 321039839 323405935 ## [8] 325719178 male \u0026lt;- population$Male_Pop; male ## [1] 152082993 153242210 154452348 155596820 156807419 158048153 159243817 ## [8] 160408119 female \u0026lt;- population$Female_Pop; female ## [1] 157255428 158402070 159540924 160637685 161815106 162991686 164162118 ## [8] 165311059   Basic Visualizations Let’s plot these\nplot(year, total) # Notice that the x-axis variable goes first! OK well that’s better but it looks funny - the y-axis looks like the output on a mid 90s calculator that couldn’t handle exponents. So we’re going to divide and round. Since everything is in hundreds of millions in our data set, let’s divide each column by one hundred million but keep the original figures.\n# We don\u0026#39;t divide anything in census because it just contains the original variables census \u0026lt;- population$Census_ID # We don\u0026#39;t want to divide anything here because this column has data on years year \u0026lt;- population$Collection_year # These are the actual data so that\u0026#39;s where we\u0026#39;ll reduce. tinytotal \u0026lt;- population$Total_Pop/100000000 tinymale \u0026lt;- population$Male_Pop/100000000 tinyfemale \u0026lt;- population$Female_Pop/100000000 Now that these are proportionally smaller, let’s hope the visuals are more understandable\nplot(year, tinytotal)  Looks much better but let’s change the axis labels to be more descriptive.\nplot(year, tinytotal, xlab = \u0026quot;Years\u0026quot;, ylab = \u0026quot;Number of People (in hundreds of millions)\u0026quot;)  That’s good but the size of the labels should be bigger.\nplot(year, tinytotal, xlab = \u0026quot;Years\u0026quot;, ylab = \u0026quot;Number of People (in hundreds of millions)\u0026quot;, cex.lab = 1.5)  Well its bland so how about a little color?\nplot(year, tinytotal, xlab = \u0026quot;Years\u0026quot;, ylab = \u0026quot;Number of People(in hundreds of millions)\u0026quot;, cex.lab = 1.5, col.lab=\u0026quot;#ee4035\u0026quot;, col=\u0026quot;#7bc043\u0026quot;) Sure but those dots are difficult to see. Let’s make them different.\nplot(year, tinytotal, xlab = \u0026quot;Years\u0026quot;, ylab = \u0026quot;Number of People(in hundreds of millions)\u0026quot;, cex.lab = 1.5, col.lab=\u0026quot;#ee4035\u0026quot;, col=\u0026quot;#7bc043\u0026quot;, pch = 19) No bigger!\nplot(year, tinytotal, xlab = \u0026quot;Years\u0026quot;, ylab = \u0026quot;Number of People (in hundreds of millions)\u0026quot;, cex.lab = 1.5, col.lab=\u0026quot;#ee4035\u0026quot;, col=\u0026quot;#7bc043\u0026quot;, pch = 19, cex = 1.5) I said bigger dammit!\nplot(year, tinytotal, xlab = \u0026quot;Years\u0026quot;, ylab = \u0026quot;Number of People (in hundreds of millions)\u0026quot;, cex.lab = 1.5, col.lab=\u0026quot;#ee4035\u0026quot;, col=\u0026quot;#7bc043\u0026quot;, pch = 19, cex = 2) And without that annoying box\nplot(year, tinytotal, xlab = \u0026quot;Years\u0026quot;, ylab = \u0026quot;Number of People (in hundreds of millions)\u0026quot;, cex.lab = 1.5, col.lab=\u0026quot;#ee4035\u0026quot;, col=\u0026quot;#7bc043\u0026quot;, pch = 19, cex = 2, bty = \u0026quot;n\u0026quot;) Maybe a colorful title?\nplot(year, tinytotal, xlab = \u0026quot;Years\u0026quot;, ylab = \u0026quot;Number of People (in hundreds of millions)\u0026quot;, cex.lab = 1.5, col.lab=\u0026quot;#ee4035\u0026quot;, col=\u0026quot;#7bc043\u0026quot;, pch = 19, cex = 2, bty = \u0026quot;n\u0026quot;, main = \u0026quot;United States Population Estimates (2010-2017)\u0026quot;, cex.main = 1.5, col.main = \u0026quot;#0392cf\u0026quot;) And a line\nplot(year, tinytotal, xlab = \u0026quot;Years\u0026quot;, ylab = \u0026quot;Number of People (in hundreds of millions)\u0026quot;, cex.lab = 1.5, col.lab=\u0026quot;#ee4035\u0026quot;, col=\u0026quot;#7bc043\u0026quot;, pch = 19, cex = 2, bty = \u0026quot;n\u0026quot;, main = \u0026quot;United States Population Estimates (2010-2017)\u0026quot;, cex.main = 1.5, col.main = \u0026quot;#0392cf\u0026quot;, type = \u0026quot;o\u0026quot;) No that’s too skinny!\nplot(year, tinytotal, xlab = \u0026quot;Years\u0026quot;, ylab = \u0026quot;Number of People (in hundreds of millions)\u0026quot;, cex.lab = 1.5, col.lab=\u0026quot;#ee4035\u0026quot;, col=\u0026quot;#7bc043\u0026quot;, pch = 19, cex = 2, bty = \u0026quot;n\u0026quot;, main = \u0026quot;United States Population Estimates (2010-2017)\u0026quot;, cex.main = 1.5, col.main = \u0026quot;#0392cf\u0026quot;, type = \u0026quot;o\u0026quot;, lwd = 3.5) That’ll do for now but that is a ton of work and a lot of not so obvious commands to memorize. So what’s the big deal?\n  A Bit of Context Well what you just went through is the OG R which was released publicly in 1995. While nowadays it is commonly known as Base R, a majority of its functionality, structure and syntax were derived from another piece of software called S-Plus which was a commercial product from 1988 primarily used only by statisticians. Regardless of the name, this would continue to be the case until the 2007 when Hadley Wickham officially released an R add-on, or package called ggplot2. Little did anybody know that this would alter the future of data visualization. Starting next week, we’ll move on from Base R to ggplot and its companion packages known as the tidyverse. If you want to get a preview, click on the image below\n \n  \nNow that’s not to say there isn’t value in knowing Base R. There are many commands that are quick and easy and don’t need add-ons. In fact, some of the syntax has survived the transition to the tidy format we’ll get to next week so for now, back to Base R!\n Basic Visualizations Histograms For this part, we will use data on the number of users on facebook. Lets read the data into R like so\nfacebook \u0026lt;- read.csv(\u0026quot;ActiveFacebookUsers.csv\u0026quot;, header = TRUE, stringsAsFactors = TRUE)  Take a look at the first six rows and get some information about the columns\nhead(facebook) ## Quarter Number.of.users.in.millions ## 1 Q3 \u0026#39;08 100 ## 2 Q1 \u0026#39;09 197 ## 3 Q2 \u0026#39;09 242 ## 4 Q3 \u0026#39;09 305 ## 5 Q4 \u0026#39;09 360 ## 6 Q1 \u0026#39;10 431 str(facebook)  ## \u0026#39;data.frame\u0026#39;: 39 obs. of 2 variables: ## $ Quarter : chr \u0026quot;Q3 \u0026#39;08\u0026quot; \u0026quot;Q1 \u0026#39;09\u0026quot; \u0026quot;Q2 \u0026#39;09\u0026quot; \u0026quot;Q3 \u0026#39;09\u0026quot; ... ## $ Number.of.users.in.millions: int 100 197 242 305 360 431 482 550 608 680 ... # Alternatively, you can use glimpse() facebook$Quarter ## [1] \u0026quot;Q3 \u0026#39;08\u0026quot; \u0026quot;Q1 \u0026#39;09\u0026quot; \u0026quot;Q2 \u0026#39;09\u0026quot; \u0026quot;Q3 \u0026#39;09\u0026quot; \u0026quot;Q4 \u0026#39;09\u0026quot; \u0026quot;Q1 \u0026#39;10\u0026quot; \u0026quot;Q2 \u0026#39;10\u0026quot; \u0026quot;Q3 \u0026#39;10\u0026quot; ## [9] \u0026quot;Q4 \u0026#39;10\u0026quot; \u0026quot;Q1 \u0026#39;11\u0026quot; \u0026quot;Q2 \u0026#39;11\u0026quot; \u0026quot;Q3 \u0026#39;11\u0026quot; \u0026quot;Q4 \u0026#39;11\u0026quot; \u0026quot;Q1 \u0026#39;12\u0026quot; \u0026quot;Q2 \u0026#39;12\u0026quot; \u0026quot;Q3 \u0026#39;12\u0026quot; ## [17] \u0026quot;Q4 \u0026#39;12\u0026quot; \u0026quot;Q1 \u0026#39;13\u0026quot; \u0026quot;Q2 \u0026#39;13\u0026quot; \u0026quot;Q3 \u0026#39;13\u0026quot; \u0026quot;Q4 \u0026#39;13\u0026quot; \u0026quot;Q1 \u0026#39;14\u0026quot; \u0026quot;Q2 \u0026#39;14\u0026quot; \u0026quot;Q3 \u0026#39;14\u0026quot; ## [25] \u0026quot;Q4 \u0026#39;14\u0026quot; \u0026quot;Q1 \u0026#39;15\u0026quot; \u0026quot;Q2 \u0026#39;15\u0026quot; \u0026quot;Q3 \u0026#39;15\u0026quot; \u0026quot;Q4 \u0026#39;15\u0026quot; \u0026quot;Q1 \u0026#39;16\u0026quot; \u0026quot;Q2 \u0026#39;16\u0026quot; \u0026quot;Q3 \u0026#39;16\u0026quot; ## [33] \u0026quot;Q4 \u0026#39;16\u0026quot; \u0026quot;Q1 \u0026#39;17\u0026quot; \u0026quot;Q2 \u0026#39;17\u0026quot; \u0026quot;Q3 \u0026#39;17\u0026quot; \u0026quot;Q4 \u0026#39;17\u0026quot; \u0026quot;Q1 \u0026#39;18\u0026quot; \u0026quot;Q2 \u0026#39;18\u0026quot; facebook$Number.of.users.in.millions ## [1] 100 197 242 305 360 431 482 550 608 680 739 800 845 901 955 ## [16] 1007 1056 1110 1155 1189 1228 1276 1317 1350 1393 1441 1490 1545 1591 1654 ## [31] 1712 1788 1860 1936 2006 2072 2129 2196 2234 Let’s rename the columns\nusers \u0026lt;- facebook$Number.of.users.in.millions quarter \u0026lt;- facebook$Quarter We’re going to use the hist() function to plot a basic histogram of the number of users and quarters\nhist(users)  # Hey its a normal distribution! We can specify the number of cells for the histogram using the breaks option\nhist(users, breaks = 40)  This essentially breaks up the default way that the histogram is constructed. You can also do it within the range of the data set. First to see the minimum and maximum, we use min() and max(), respectively.\nmin(users)  ## [1] 100 max(users)  ## [1] 2234 So if I wanted to see how this histogram looks say broken into bars of 300, we can do\n(max(users) - min(users))/300 ## [1] 7.113333 or better yet if we round up, we’ll get the actual number of bars we need. To always round to the next integer, we can use the ceiling() function\nceiling((max(users) - min(users))/300) ## [1] 8 Now you can count in 300s and get the output you want\nhist(users, breaks = c(100,400,700,1000,1300,1600,1900,2100,2400)) but that’s a lot of work and its a bit odd because our data aren’t greater than the the maximum. We can still get the eight bars we want of even width if we let R do it for us using the seq, or sequence option with length.out, or the number of desired bars\nhist(users, breaks = seq(min(users), max(users), length.out=8)) Let’s make it look decent\nhist(users, breaks = seq(min(users), max(users), length.out=8), xlab = \u0026quot;Active Users (in millions)\u0026quot;, main = \u0026quot;Facebook utility worldwide as of 2nd quarter 2018\u0026quot;, col = c(\u0026quot;#3b5998\u0026quot;,\u0026quot;#6d84b4\u0026quot;, \u0026quot;#afbdd4\u0026quot;, \u0026quot;#d8dfea\u0026quot;, \u0026quot;#ffffff\u0026quot;), border = \u0026quot;#d8dfea\u0026quot;, cex.lab = 1.1)  Notice that you can define colors in a vector and the plot will simply repeat that layout.\n Line Graph2 Let’s look at another population, but this time we’ll use Twitter data\ntwitter \u0026lt;- read.csv(\u0026quot;ActiveTwitterUsers.csv\u0026quot;, header = TRUE, stringsAsFactors = TRUE)  head(twitter) ## Quarter Number.of.monthly.active.users.in.millions ## 1 20101 30 ## 2 20102 40 ## 3 20103 49 ## 4 20104 54 ## 5 20111 68 ## 6 20112 85 str(twitter) ## \u0026#39;data.frame\u0026#39;: 37 obs. of 2 variables: ## $ Quarter : int 20101 20102 20103 20104 20111 20112 20113 20114 20121 20122 ... ## $ Number.of.monthly.active.users.in.millions: num 30 40 49 54 68 85 101 117 138 151 ... twitter$Quarter ## [1] 20101 20102 20103 20104 20111 20112 20113 20114 20121 20122 20123 20124 ## [13] 20131 20132 20133 20134 20141 20142 20143 20144 20151 20152 20153 20154 ## [25] 20161 20162 20163 20164 20171 20172 20173 20174 20181 20182 20183 20184 ## [37] 20191 twitter$Number.of.monthly.active.users.in.millions ## [1] 30.0 40.0 49.0 54.0 68.0 85.0 101.0 117.0 138.0 151.0 167.0 185.0 ## [13] 204.0 218.0 231.7 241.0 255.0 271.0 284.0 288.0 302.0 304.0 307.0 305.0 ## [25] 310.0 313.0 317.0 318.0 327.0 326.0 330.0 330.0 336.0 335.0 326.0 321.0 ## [37] 330.0 Let’s rename the columns\ntweeters \u0026lt;- twitter$Number.of.monthly.active.users.in.millions season \u0026lt;- twitter$Quarter Let’s first create a basic plot\nplot(season, tweeters) There are several types of plot within the plot function which we can access by using the type option\nplot(season, tweeters, type = \u0026quot;l\u0026quot;) Now try options “o”, “p”, and “b” on your own. Check the solutions below to see if your plot rendered correctly\n  Solutions  plot(season, tweeters, type = \u0026quot;o\u0026quot;) plot(season, tweeters, type = \u0026quot;p\u0026quot;) plot(season, tweeters, type = \u0026quot;b\u0026quot;)  We can also change the line type using the lty option\nplot(season, tweeters, type = \u0026quot;l\u0026quot;, lty = \u0026quot;dashed\u0026quot;) plot(season, tweeters, type = \u0026quot;l\u0026quot;, lty = \u0026quot;dotted\u0026quot;) Well it looks like the solid line is likely the best so we’ll stick with it.\nplot(season, tweeters, type = \u0026quot;l\u0026quot;) Black and white plots can be great but that’s rarely true for data with ore information than two dimensions.\nplot(season, tweeters, type = \u0026quot;l\u0026quot;, col = \u0026quot;#5cb85c\u0026quot;) You can also use a standard palette in R by using numbers\nplot(season, tweeters, type = \u0026quot;l\u0026quot;, col = 3) That line is just too thin. We can make it thicker by using the lwd option\nplot(season, tweeters, col = \u0026quot;#5cb85c\u0026quot;, lwd = 3) Finally, we can sort out the axes and plot titles\nplot(season, tweeters, type = \u0026quot;l\u0026quot;, col = \u0026quot;#5cb85c\u0026quot;, lwd = 3, xlab = \u0026quot;Quarter\u0026quot;, ylab = \u0026quot;Tweeters (in millions)\u0026quot;, main = \u0026quot;Active Users on Twitter\u0026quot;) I did promise regression didn’t I? OK well what if we wanted to know the answer to the question: is the Twitter population increasing in size? Well we can add a basic linear regression to the plot to estimate if that’s true. First let’s calculate the regression line…\nfit1 \u0026lt;- lm (tweeters ~ season, data = twitter) summary(fit1) ## ## Call: ## lm(formula = tweeters ~ season, data = twitter) ## ## Residuals: ## Min 1Q Median 3Q Max ## -72.465 -33.476 -3.424 32.275 54.490 ## ## Coefficients: ## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) -7.218e+04 4.468e+03 -16.15 \u0026lt;2e-16 *** ## season 3.595e+00 2.218e-01 16.21 \u0026lt;2e-16 *** ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 ## ## Residual standard error: 36 on 35 degrees of freedom ## Multiple R-squared: 0.8824, Adjusted R-squared: 0.879 ## F-statistic: 262.6 on 1 and 35 DF, p-value: \u0026lt; 2.2e-16 plot(fit1)  Scatterplots Let’s load a dataset of Flower characteristics in 3 species of Iris.\ndata(iris) head(iris) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa There is a lot of data here! Let’s explore using the pairs() function\npairs(iris) This doesn’t tell us much about the species differences. We can tell R to plot using a different color for the three species of iris\npairs(iris, col = iris$Species) Sepal.Length and Petal.Length look interesting! Let’s start by looking at that\nplot(iris$Sepal.Length, iris$Petal.Length, col = iris$Species) These points are difficult to see! Let’s pick some different ones using the pch option\nplot(iris$Sepal.Length, iris$Petal.Length, col = iris$Species, pch = 15) plot(iris$Sepal.Length, iris$Petal.Length, col = iris$Species, pch = \u0026quot;A\u0026quot;) pch 21:25 also specify an edge color (col) and a background color (bg)\nplot(iris$Sepal.Length, iris$Petal.Length, col = iris$Species, pch = 21, bg = \u0026quot;blue\u0026quot;) OK settling on solid circles…\nplot(iris$Sepal.Length, iris$Petal.Length, col = iris$Species, pch = 16) …that need to be bigger\nplot(iris$Sepal.Length, iris$Petal.Length, col = iris$Species, pch = 16, cex = 2)  Boxplots We’ll continue to use the Iris dataset for this section\nhead(iris) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa Lets first examine the distribution of Sepal Length for each species\nboxplot(iris$Sepal.Length ~ iris$Species) f you wish to compare the medians of the boxplot, you can use the function “notch”. If the notches of two plots do not overlap, this is ‘strong evidence’ that the two medians differ.\nboxplot(iris$Sepal.Length ~ iris$Species, notch = T) You may have noticed that the y-axis labels are always orientated to be perpendicular to the axis. We can rotate all axis labels using the las option.\nboxplot(iris$Sepal.Length ~ iris$Species, notch = T, las = 1)  Now we can add in all the axis and plot labels…\nboxplot(iris$Sepal.Length ~ iris$Species, notch = T, las = 1, xlab = \u0026quot;Species\u0026quot;, ylab = \u0026quot;Sepal Length\u0026quot;, main = \u0026quot;Sepal Length by Species in Iris\u0026quot;)  …and change sizes\nboxplot(iris$Sepal.Length ~ iris$Species, notch = T, las = 1, xlab = \u0026quot;Species\u0026quot;, ylab = \u0026quot;Sepal Length\u0026quot;, main = \u0026quot;Sepal Length by Species in Iris\u0026quot;, cex.lab = 1.5, cex.axis = 1.5, cex.main = 2)    Plot Options Rendering more than one plot in a window # number of rows, number of columns par(mfrow=c(1,2)) plot( # x variable, y variable iris$Sepal.Length, iris$Petal.Length, # color by species col = iris$Species, # plot title main = \u0026quot;Sepal vs Petal Length in Iris\u0026quot; ) plot( # x variable, y variable iris$Sepal.Length, iris$Petal.Length, # color by species col = iris$Species, # plot title main = \u0026quot;Sepal vs Petal Length in Iris\u0026quot; )  Adding the following sets the plot window back to normal\npar(mfrow=c(1,1)) plot( # x variable, y variable iris$Sepal.Length, iris$Petal.Length, # color by species col = iris$Species, # plot title main = \u0026quot;Sepal vs Petal Length in Iris\u0026quot; )  or you can just clear the plot history by running\ndev.off()  ## null device ## 1    Remember Algebra?↩︎\n Now with 22% more linear regression↩︎\n   ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"ce879375c9ab42490f4d0d112e48c07c","permalink":"https://edp693e.theoreticalphysed.com/example/02-example/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/example/02-example/","section":"example","summary":"Getting Prepped  First Things First! Set your Working Directory Download the script Foundational Structures Data Types Classes  Example: 100% Fake Data   Data Frames - A Format You Absolutely Want  Importing and Viewing Data Looking at Variables in a Data Frame Assigning Variables Basic Visualizations  A Bit of Context Basic Visualizations  Histograms Line Graph Scatterplots Boxplots  Plot Options  Rendering more than one plot in a window     .","tags":null,"title":"Base R is a Thing","type":"docs"},{"authors":null,"categories":null,"content":"   Data Camp   Data Camp This week you have two modules to cover on Data Camp. In particular these are\n Introduction to Data in R Data Visualization in R  For more information about these, take a look at the tentative schedule.\n ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"911ebe9376618b75c6ca9ac02110b8b9","permalink":"https://edp693e.theoreticalphysed.com/lesson/02-lesson/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/lesson/02-lesson/","section":"lesson","summary":"Data Camp   Data Camp This week you have two modules to cover on Data Camp. In particular these are\n Introduction to Data in R Data Visualization in R  For more information about these, take a look at the tentative schedule.","tags":null,"title":"Base R is a Thing","type":"docs"},{"authors":null,"categories":null,"content":"    Read Things    .hvr-sweep-to-left { display: inline-block; vertical-align: middle; -webkit-transform: perspective(1px) translateZ(0); transform: perspective(1px) translateZ(0); box-shadow: 0 0 1px rgba(0, 0, 0, 0); position: relative; -webkit-transition-property: color; transition-property: color; -webkit-transition-duration: 0.25s; transition-duration: 0.25s; } .hvr-sweep-to-left:before { content: \"\"; position: absolute; z-index: -1; top: 0; left: 0; right: 0; bottom: 0; background: #175676; -webkit-transform: scaleX(0); transform: scaleX(0); -webkit-transform-origin: 100% 50%; transform-origin: 100% 50%; -webkit-transition-property: transform; transition-property: transform; -webkit-transition-duration: 0.3s; transition-duration: 0.3s; -webkit-transition-timing-function: ease-out; transition-timing-function: ease-out; } .hvr-sweep-to-left:hover, .hvr-sweep-to-left:focus, .hvr-sweep-to-left:active { color: white; } .hvr-sweep-to-left:hover:before, .hvr-sweep-to-left:focus:before, .hvr-sweep-to-left:active:before { -webkit-transform: scaleX(1); transform: scaleX(1); }  Read Things We’ll be transitioning out of Base R to the Tidyverse. To get an idea of what that looks like by reading a couple of articles from Hadley Wickham:\nWickham, H. (2010). A Layered Grammar of Graphics. Journal of Computational and Graphical Statistics 19(1), 3-28. https://doi.org/10.1198/jcgs.2009.07098 Wickham, H. (2013). Graphical Criticism: Some Historical Notes, Journal of Computational and Graphical Statistics, 22(1), 38-44. https://doi.org/ 10.1080/10618600.2012.761140   Download the Readings   ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"510696b7bb47e51213a79e8cd09e243d","permalink":"https://edp693e.theoreticalphysed.com/readings/02-readings/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/readings/02-readings/","section":"readings","summary":"Read Things    .hvr-sweep-to-left { display: inline-block; vertical-align: middle; -webkit-transform: perspective(1px) translateZ(0); transform: perspective(1px) translateZ(0); box-shadow: 0 0 1px rgba(0, 0, 0, 0); position: relative; -webkit-transition-property: color; transition-property: color; -webkit-transition-duration: 0.","tags":null,"title":"Base R is a Thing","type":"docs"},{"authors":null,"categories":null,"content":"    Create Plots in ggplot    .hvr-sweep-to-left { display: inline-block; vertical-align: middle; -webkit-transform: perspective(1px) translateZ(0); transform: perspective(1px) translateZ(0); box-shadow: 0 0 1px rgba(0, 0, 0, 0); position: relative; -webkit-transition-property: color; transition-property: color; -webkit-transition-duration: 0.25s; transition-duration: 0.25s; } .hvr-sweep-to-left:before { content: \"\"; position: absolute; z-index: -1; top: 0; left: 0; right: 0; bottom: 0; background: #733367; -webkit-transform: scaleX(0); transform: scaleX(0); -webkit-transform-origin: 100% 50%; transform-origin: 100% 50%; -webkit-transition-property: transform; transition-property: transform; -webkit-transition-duration: 0.3s; transition-duration: 0.3s; -webkit-transition-timing-function: ease-out; transition-timing-function: ease-out; } .hvr-sweep-to-left:hover, .hvr-sweep-to-left:focus, .hvr-sweep-to-left:active { color: white; } .hvr-sweep-to-left:hover:before, .hvr-sweep-to-left:focus:before, .hvr-sweep-to-left:active:before { -webkit-transform: scaleX(1); transform: scaleX(1); }  Create Plots in ggplot Use the file Middle-Class-US-Metro-Areas-5-12-16-Supplementary-Tables.xslx from Pew Research on America’s shrinking middle class to create at least 5 comparisons based on at the data set.\nPlease post a single script to ##wk3-shrinking-middle-class\nNOTE: You will have to clean up the data but do not have to do it in R.\n Download the Data   ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"af0b365ca488e9ad2d9f06d6c238b02e","permalink":"https://edp693e.theoreticalphysed.com/assignment/03-assignment/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/assignment/03-assignment/","section":"assignment","summary":"Create Plots in ggplot    .hvr-sweep-to-left { display: inline-block; vertical-align: middle; -webkit-transform: perspective(1px) translateZ(0); transform: perspective(1px) translateZ(0); box-shadow: 0 0 1px rgba(0, 0, 0, 0); position: relative; -webkit-transition-property: color; transition-property: color; -webkit-transition-duration: 0.","tags":null,"title":"ggplotting","type":"docs"},{"authors":null,"categories":null,"content":"    What’s Due?   What’s Due?    Data Camp  eCampus  R  Slack  Description  Location                  Create five plots in ggplot  Link                Complete one module  Link      Note: These tasks are provided in a recommended order.\n ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"2a9ebfd3c92be577bc4d52f8871ae75c","permalink":"https://edp693e.theoreticalphysed.com/due/03-due/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/due/03-due/","section":"due","summary":"What’s Due?   What’s Due?    Data Camp  eCampus  R  Slack  Description  Location                  Create five plots in ggplot  Link                Complete one module  Link      Note: These tasks are provided in a recommended order.","tags":null,"title":"ggplotting","type":"docs"},{"authors":null,"categories":null,"content":"    Getting Prepped  First Things First! Set your Working Directory Download the script Load Up Some Libraries  Its All About Layers  Example: Diamonds Another Example: Bar Plots Yet Another Example: More Bar Plots! Comparisons Using Bar Charts Adding Values     .hvr-sweep-to-left { display: inline-block; vertical-align: middle; -webkit-transform: perspective(1px) translateZ(0); transform: perspective(1px) translateZ(0); box-shadow: 0 0 1px rgba(0, 0, 0, 0); position: relative; -webkit-transition-property: color; transition-property: color; -webkit-transition-duration: 0.25s; transition-duration: 0.25s; } .hvr-sweep-to-left:before { content: \"\"; position: absolute; z-index: -1; top: 0; left: 0; right: 0; bottom: 0; background: #003277; -webkit-transform: scaleX(0); transform: scaleX(0); -webkit-transform-origin: 100% 50%; transform-origin: 100% 50%; -webkit-transition-property: transform; transition-property: transform; -webkit-transition-duration: 0.3s; transition-duration: 0.3s; -webkit-transition-timing-function: ease-out; transition-timing-function: ease-out; } .hvr-sweep-to-left:hover, .hvr-sweep-to-left:focus, .hvr-sweep-to-left:active { color: white; } .hvr-sweep-to-left:hover:before, .hvr-sweep-to-left:focus:before, .hvr-sweep-to-left:active:before { -webkit-transform: scaleX(1); transform: scaleX(1); }  Getting Prepped First Things First! Set your Working Directory Your working directory is simply where your script will look for anything it needs like external data sets. There are a few ways to go about doing this which we will cover. However for now, just do the following:\nOpen up a new script by going to File \u0026gt; New File \u0026gt; R Script. Save it in a preferably empty folder as whatever you want. Go to the menu bar and select Session \u0026gt; Set Working Directory \u0026gt; To Source File Location.   Download the script Copying and pasting syntax from a browser can cause problems. To avoid this issue, please download a script with all of the needed code presented in this walkthrough.\n Download the Script   Load Up Some Libraries Please go ahead and download the libraries below you don’t have and load them up\nlibrary(ggplot2) library(cowplot) library(RColorBrewer)   Its All About Layers   ggplot runs on layers1\nWe’ll work on this throughout the term, but here is a basic picture of the framework\n  Example: Diamonds We’ll use the diamonds data set that’s included in ggplot, in particular we’ll start with this plot with a bunch of foundational commands\nggplot() + layer( data = diamonds, mapping = aes(x = carat, y = price), geom = \u0026quot;point\u0026quot;, stat = \u0026quot;identity\u0026quot;, position = \u0026quot;identity\u0026quot; ) + scale_y_continuous() + scale_x_continuous() + coord_cartesian() which can be condensed to\nggplot(data = diamonds, mapping = aes(x = carat, y = price)) + geom_point() You can get lazy about arguments, in that x and y are always the first arguments to aes so we often drop the argument names\nggplot(diamonds, aes(carat, price)) + geom_point()  Another Example: Bar Plots First we’ll make up a totally fake data set. Please pay close attention to the structure and what everything means.\ndata \u0026lt;- structure(list(V1 = c(34.88372093, 35.07751938, 35.27131783, 35.46511628, 35.65891473, 35.85271318), V2 = c(0.00029997, 0.00019998, 0.00029997, 0.00029997, 0.00069993, 0.00069993)), .Names = c(\u0026quot;Perc\u0026quot;, \u0026quot;Prop\u0026quot;), row.names = c(NA, 6L), class = \u0026quot;data.frame\u0026quot;) and view it!\nView(data) The above says: I want a structure a list with two columns with variable Names V1 and V2 with the associated values in columns (given by c). Moreover, I want to name those columns Prop and Perc, with no row names (NA) and of length 6 (6 rows given by 6L). Finally, and possibly most importantly, it has to be a data frame!\nNow let’s look at a barplot of the data using\nBase R  barplot(data$Perc, data$Perc, xlab=\u0026quot;Percentage\u0026quot;, ylab=\u0026quot;Proportion\u0026quot;) ggplot  ggplot(data, aes(x=Perc, y=Prop)) + geom_bar(stat=\u0026quot;identity\u0026quot;) + labs(x=\u0026quot;Percentage\u0026quot;, y=\u0026quot;Proportion\u0026quot;) Now let’s try colors by using the Perc column\nggplot(data, aes(x=Perc, y=Prop, fill = Perc)) + geom_bar(stat=\u0026quot;identity\u0026quot;) + labs(x=\u0026quot;Percentage\u0026quot;, y=\u0026quot;Proportion\u0026quot;) + scale_color_brewer()  Yet Another Example: More Bar Plots! Please download the libraries below you don’t have and load them up\nlibrary(xlsx) # for reading in Excel data library(magrittr) # for easier syntax in one or two areas library(gridExtra) # old method for generating some comparison plots library(patchwork) # new method for generating some comparison plots library(ggplot2) # for generating the visualizations library(viridis) # because colors are fun! We’ll use the mtcars data set. It is a standard example set that comprises fuel consumption and 10 aspects of automobile design and performance for 32 automobiles.\nhead(mtcars) ## mpg cyl disp hp drat wt qsec vs am gear carb ## Mazda RX4 21.0 6 160 110 3.90 2.620 16.46 0 1 4 4 ## Mazda RX4 Wag 21.0 6 160 110 3.90 2.875 17.02 0 1 4 4 ## Datsun 710 22.8 4 108 93 3.85 2.320 18.61 1 1 4 1 ## Hornet 4 Drive 21.4 6 258 110 3.08 3.215 19.44 1 0 3 1 ## Hornet Sportabout 18.7 8 360 175 3.15 3.440 17.02 0 0 3 2 ## Valiant 18.1 6 225 105 2.76 3.460 20.22 1 0 3 1 If we wanted to get the count of vehicles that have 4, 6 and 8 cylinders we can simply identify the x-axis variable and apply geom_bar(). This, by default will plot the count of 4, 6, and 8 cylinder vehicles in the data set. However, note that if the variable is numeric it may be interpreted as a continuous variable. This is the case in the first plot you will do below which is why the x-axis is continuous in nature. However, we can force the cylinder variable to a categorical (factor) variable by applying x = factor(cyl) using the second plot you will do below which produces a discrete x-axis.\n# x-axis as continuous p1 \u0026lt;- ggplot(mtcars, aes(x = cyl)) + geom_bar() + ggtitle(\u0026quot;Fig. A: x-axis as a continuous variable\u0026quot;) # x-axis as discrete p2 \u0026lt;- ggplot(mtcars, aes(x = factor(cyl))) + geom_bar() + ggtitle(\u0026quot;Fig B: x-axis as a discrete (factor) variable\u0026quot;) We’ll see how to deal with the cut off text later\nWe’ll display the results in two ways\nUsing the gridExtra package  grid.arrange(p1, p2, ncol = 2) Using the patchwork package  p1 + p2 Although the default width of the bars is aesthetically pleasing, you do have the ability to adjust this attribute by setting the width in geom_bar(). The default width is 0.9;\nsmaller values (min width of 0) make the bars narrower and larger values (max width of 1) make the bars wider.  Here are some examples\ne1 \u0026lt;- ggplot(mtcars, aes(x = factor(cyl))) + geom_bar(width = .5) + ggtitle(\u0026quot;bar width = 0.5\u0026quot;) e2 \u0026lt;- ggplot(mtcars, aes(x = factor(cyl))) + geom_bar(width = .75) + ggtitle(\u0026quot;bar width = 0.75\u0026quot;) e3 \u0026lt;- ggplot(mtcars, aes(x = factor(cyl))) + geom_bar(width = .9) + ggtitle(\u0026quot;bar width = 0.9\u0026quot;) e4 \u0026lt;- ggplot(mtcars, aes(x = factor(cyl))) + geom_bar(width = .99) + ggtitle(\u0026quot;bar width = 0.99\u0026quot;) e1 + e2 + e3 + e4 e1 + e2 + e3 + e4 + plot_layout(ncol = 1) e1 + e2 + e3 + e4 + plot_layout(nrow = 1) Take a look at some more examples over at the patchwork vignette.\nWe can also adjust the fill and outline colors of the bars along with the opacity by applying fill, color, and alpha arguments respectively in the geom_bar() function.\nggplot(mtcars, aes(x = factor(cyl))) + geom_bar(fill = \u0026quot;dodgerblue\u0026quot;, color = \u0026quot;grey40\u0026quot;, alpha = 0.5) There are also times when we want to plot many categories along the x-axis and the length of the names make it difficult to read. One approach to resolving this issue is to use axis.text.x argument within the theme() function to rotate the text.\nt1 \u0026lt;- ggplot(mtcars, aes(x = row.names(mtcars), y = mpg)) + geom_bar(stat = \u0026quot;identity\u0026quot;) + ggtitle(\u0026quot;Fig. A: Default x-axis\u0026quot;) t1 t2 \u0026lt;- ggplot(mtcars, aes(x = row.names(mtcars), y = mpg)) + geom_bar(stat = \u0026quot;identity\u0026quot;) + theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = .5)) + ggtitle(\u0026quot;Fig. B: Rotated x-axis\u0026quot;) t2 t1 + t2 + plot_layout(ncol = 1) However, you may hate to read rotated x-axis labels since it can be difficult. In cases like these rotated bar charts are far more appealing. We can rotate the axes by applying the coord_flip() function, which flips the x and y coordinates. To make this even easier to digest we can order the vehicles based on their mpg values as illustrated in the second plot you’ll do below. To do this just reorder the x variable by applying the reorder() function.\nr1 \u0026lt;- ggplot(mtcars, aes(x = row.names(mtcars), mpg)) + geom_bar(stat = \u0026quot;identity\u0026quot;) + coord_flip() + ggtitle(\u0026quot;Fig. A: Default rotated x-axis\u0026quot;) # order bars r2 \u0026lt;- ggplot(mtcars, aes(x = reorder(row.names(mtcars), mpg), y = mpg)) + geom_bar(stat = \u0026quot;identity\u0026quot;) + coord_flip() + ggtitle(\u0026quot;Fig. B: Rotated ordered x-axis\u0026quot;) r1 + r2 + plot_layout(nrow = 1)  Comparisons Using Bar Charts Sometimes we want to compare different groups across the categorical variables of interest. This is primarily done via color, side-by-side bars, or stacked bars. To add a color dimension we simply add a fill argument to our first line of code to tell R what variable we want to use to color our bars.\nIn this example we compare mpg across all the vehicles but also color the vehicles based on number of cylinders. R will use default color codings but you can\nset the colors manually using scale_fill_manual as in the second plot you’ll do. But you can also use scale_fill_brewer to color with preset color schemes (see more about ColorBrewer here) and many others! (if you type scale_fill into your RStudio Help search field you will see all the possibilities)  Let’s compare mpg across all cars and color based on cyl\nm1 \u0026lt;- ggplot(mtcars, aes(x = reorder(row.names(mtcars), mpg), y = mpg, fill = factor(cyl))) + geom_bar(stat = \u0026quot;identity\u0026quot;) + coord_flip() + theme_minimal() + ggtitle(\u0026quot;Fig. A: Default fill colors\u0026quot;) m2 \u0026lt;- ggplot(mtcars, aes(x = reorder(row.names(mtcars), mpg), y = mpg, fill = factor(cyl))) + scale_fill_manual(values = c(\u0026quot;#e5f5e0\u0026quot;, \u0026quot;#a1d99b\u0026quot;, \u0026quot;#31a354\u0026quot;)) + geom_bar(stat = \u0026quot;identity\u0026quot;) + coord_flip() + theme_minimal() + ggtitle(\u0026quot;Fig. B: Manually set fill colors\u0026quot;) m1 + m2 + plot_layout(ncol = 2) We can also use side-by-side bars to make comparisons. Say we want to compare the average mpg for cars across the different 4, 6, and 8 cylinder categories but also assess the impact that transmission (variable am where 0 = automatic, 1 = manual) has. we apply the fill argument to color bars based on transmission type then include the position = \"dodge\" in the geom_bar() function. This tells R to have two bars for each cylinder type, color fill each bar based on the type of transmission and then adjust (aka “dodge”) the position of the bars so that they are side-by-side.\nt1 \u0026lt;- ggplot(mtcars, aes(factor(cyl), mpg, fill = factor(am))) + geom_bar(stat = \u0026quot;identity\u0026quot;, position = \u0026quot;dodge\u0026quot;) + ggtitle(\u0026quot;Default color comparison\u0026quot;) # more pleasing colors t2 \u0026lt;- ggplot(mtcars, aes(factor(cyl), mpg, fill = factor(am))) + geom_bar(stat = \u0026quot;identity\u0026quot;, position = \u0026quot;dodge\u0026quot;) + scale_fill_brewer(palette = \u0026quot;Pastel1\u0026quot;) + ggtitle(\u0026quot;Adjusted color comparison\u0026quot;) t1 + t2 + plot_layout(ncol = 2) You can adjust the dodge width by incorporating the position = position_dodge(width = x) argument in the geom_bar() function. By default, the width is 0.90 and a lower value will create overlap of your side-by-side bars and a larger value will create spacing between the bars.\nl1 \u0026lt;- ggplot(mtcars, aes(factor(cyl), mpg, fill = factor(am))) + geom_bar(stat = \u0026quot;identity\u0026quot;, position = \u0026quot;dodge\u0026quot;) + ggtitle(\u0026quot;Default dodge positioning\u0026quot;) + theme(legend.position = \u0026quot;none\u0026quot;) l2 \u0026lt;- ggplot(mtcars, aes(factor(cyl), mpg, fill = factor(am))) + geom_bar(stat = \u0026quot;identity\u0026quot;, position = position_dodge(width = .5)) + ggtitle(\u0026quot;Overlap of side-by-side bars\u0026quot;) + theme(legend.position = \u0026quot;none\u0026quot;) l3 \u0026lt;- ggplot(mtcars, aes(factor(cyl), mpg, fill = factor(am))) + geom_bar(stat = \u0026quot;identity\u0026quot;, position = position_dodge(width = 1)) + ggtitle(\u0026quot;Spacing between side-by-side bars\u0026quot;) + labs(fill = \u0026quot;AM\u0026quot;) + theme(legend.position = c(1,1), legend.justification = c(1,1), legend.background = element_blank()) l1 + l2 + l3 + plot_layout(ncol = 3) Stacked bars are the third common approach to compare groups with bar charts. By default, when you introduce a variable to color fill with in the first line, if you enter no other arguments ggplot will produce a stacked bar chart.\nggplot(mtcars, aes(factor(cyl), mpg, fill = factor(am))) + geom_bar(stat = \u0026quot;identity\u0026quot;) Unfortunately, the way ggplot color codes the bars is opposite to how the colors are displayed in the legend. We can resolve this two different ways; either reverse the legend with the arguments displayed in the guides() function in your first plotbelow. or specify the direction of the levels when transforming the transmission (am) variable into a factor as displayed in the first line of code in Fig B. Both will align the legend color coding layout to the color coding of the stacked bars but each option also helps determine which color is top versus on the bottom.\n# reverse legend color coding layout q1 \u0026lt;- ggplot(mtcars, aes(factor(cyl), mpg, fill = factor(am))) + geom_bar(stat = \u0026quot;identity\u0026quot;) + guides(fill = guide_legend(reverse = TRUE)) + labs(fill = \u0026quot;am\u0026quot;) + ggtitle(\u0026quot;Fig A: Reverse legend\u0026quot;) # or reverse stacking order by changing the factor levels q2 \u0026lt;- ggplot(mtcars, aes(factor(cyl), mpg, fill = factor(am, levels = c(1, 0)))) + geom_bar(stat = \u0026quot;identity\u0026quot;) + labs(fill = \u0026quot;am\u0026quot;) + ggtitle(\u0026quot;Fig B: Specify levels\u0026quot;) q1 + q2 + plot_layout(ncol = 2) As before we can change the color of our stacked bars by incorporating one of the many scale_fill_xxxx arguments. Here I manually specify the colors to apply with scale_fill_manual().\nggplot(mtcars, aes(factor(cyl), mpg, fill = factor(am, levels = c(1, 0)))) + geom_bar(stat = \u0026quot;identity\u0026quot;) + scale_fill_manual(values = c(\u0026quot;#a1d99b\u0026quot;, \u0026quot;#31a354\u0026quot;)) + labs(fill = \u0026quot;AM\u0026quot;)  Adding Values Often, it is helpful to provide labels/markers on the bar charts to help the reader interpret the results correctly or just to make it easier to read the graphic. For instance, we can add the actual mpg value to the following vertical bar chart by incorporating the geom_text() function and telling the function to label each bar with the mpg value. I can also tell ggplot to nudge the values left or right sit within or outside the bar and also color the text.\np1 \u0026lt;- ggplot(mtcars, aes(reorder(row.names(mtcars), mpg), mpg)) + geom_bar(stat = \u0026quot;identity\u0026quot;) + coord_flip() + geom_text(aes(label = mpg), nudge_y = 2) p2 \u0026lt;- ggplot(mtcars, aes(reorder(row.names(mtcars), mpg), mpg)) + geom_bar(stat = \u0026quot;identity\u0026quot;) + coord_flip() + geom_text(aes(label = mpg), nudge_y = -2, color = \u0026quot;white\u0026quot;) p1 + p2 + plot_layout(ncol = 2) Labeling grouped bars is similar, however, we need to add a position = position_dodge(0.9) argument to the geom_text() function to tell ggplot to adjust the text location. By default, the values will be centered on the top of the bar but you can adjust the text to the top of the bar by including a vjust = 0.5 argument or adjust the text to within the bar with vjust = 1.5\np1 \u0026lt;- ggplot(mtcars, aes(factor(cyl), mpg, fill = factor(am))) + geom_bar(stat = \u0026quot;identity\u0026quot;, position = \u0026quot;dodge\u0026quot;) + geom_text(aes(label = round(mpg, 1)), position = position_dodge(0.9)) + ggtitle(\u0026quot;Fig A: Default text alignment\u0026quot;) p2 \u0026lt;- ggplot(mtcars, aes(factor(cyl), mpg, fill = factor(am))) + geom_bar(stat = \u0026quot;identity\u0026quot;, position = \u0026quot;dodge\u0026quot;) + geom_text(aes(label = round(mpg, 1)), position = position_dodge(0.9), vjust = 1.5, color = \u0026quot;white\u0026quot;) + ggtitle(\u0026quot;Fig B: Adjusted text alignment\u0026quot;) p1 + p2 + plot_layout(ncol = 2) You can change the colors palettes using hex (aka hexidecimal) colors! Take a look here for an example. In this case, we’ll be using the viridis color set.\np1 \u0026lt;- ggplot(mtcars, aes(factor(cyl), mpg, fill = factor(am))) + geom_bar(stat = \u0026quot;identity\u0026quot;, position = \u0026quot;dodge\u0026quot;) + geom_text(aes(label = round(mpg, 1)), position = position_dodge(0.9)) + ggtitle(\u0026quot;Fig A: Default text alignment\u0026quot;) p2 \u0026lt;- ggplot(mtcars, aes(factor(cyl), mpg, fill = factor(am))) + geom_bar(stat = \u0026quot;identity\u0026quot;, position = \u0026quot;dodge\u0026quot;) + scale_fill_viridis_c(option = \u0026quot;D\u0026quot;) + geom_text(aes(label = round(mpg, 1)), position = position_dodge(0.9), vjust = 1.5, color = \u0026quot;white\u0026quot;) + ggtitle(\u0026quot;Fig B: Adjusted text alignment\u0026quot;) p2 *Uh oh! Did you see something that said ## Error: Discrete value supplied to continuous scale?\nThe error says that we tried to add a continuous scale to discrete values! Well we could use this by either\nGetting rid of the factor  p2 \u0026lt;- ggplot(mtcars, aes(factor(cyl), mpg, fill = am)) + geom_bar(stat = \u0026quot;identity\u0026quot;, position = \u0026quot;dodge\u0026quot;) + scale_fill_viridis_c(option = \u0026quot;D\u0026quot;) + geom_text(aes(label = round(mpg, 1)), position = position_dodge(0.9), vjust = 1.5, color = \u0026quot;white\u0026quot;) + ggtitle(\u0026quot;Fig B: Adjusted text alignment\u0026quot;) p2 Changing the type of scaling  p2 \u0026lt;- ggplot(mtcars, aes(factor(cyl), mpg, fill = factor(am))) + geom_bar(stat = \u0026quot;identity\u0026quot;, position = \u0026quot;dodge\u0026quot;) + scale_fill_viridis_d(option = \u0026quot;D\u0026quot;) + geom_text(aes(label = round(mpg, 1)), position = position_dodge(0.9), vjust = 1.5, color = \u0026quot;white\u0026quot;) + ggtitle(\u0026quot;Fig B: Adjusted text alignment\u0026quot;) p2 Notice that the plots are different! Your fill and color variables define how the plot will look!\n   Much like Adobe Photoshop for those of you who may be familiar with that software.↩︎\n   ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"73664027ae41c739f0c70a62c901a4c5","permalink":"https://edp693e.theoreticalphysed.com/example/03-example/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/example/03-example/","section":"example","summary":"Getting Prepped  First Things First! Set your Working Directory Download the script Load Up Some Libraries  Its All About Layers  Example: Diamonds Another Example: Bar Plots Yet Another Example: More Bar Plots!","tags":null,"title":"ggplotting","type":"docs"},{"authors":null,"categories":null,"content":"   Data Camp   Data Camp This week you have one module to cover on Data Camp. In particular this are\n Intermediate R  For more information about these, take a look at the tentative schedule.\n ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"e88a62444161c21a7f4779be93acbf33","permalink":"https://edp693e.theoreticalphysed.com/lesson/03-lesson/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/lesson/03-lesson/","section":"lesson","summary":"Data Camp   Data Camp This week you have one module to cover on Data Camp. In particular this are\n Intermediate R  For more information about these, take a look at the tentative schedule.","tags":null,"title":"ggplotting","type":"docs"},{"authors":null,"categories":null,"content":"    What’s Due?   What’s Due?    Data Camp  eCampus  R  Slack  Description  Location                  Complete two modules  Link      Note: These tasks are provided in a recommended order.\n ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"4bca9f280d6851de4bfe166681764e5c","permalink":"https://edp693e.theoreticalphysed.com/due/04-due/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/due/04-due/","section":"due","summary":"What’s Due?   What’s Due?    Data Camp  eCampus  R  Slack  Description  Location                  Complete two modules  Link      Note: These tasks are provided in a recommended order.","tags":null,"title":"Tidy Themes","type":"docs"},{"authors":null,"categories":null,"content":"    Getting Prepped  First Things First! Set your Working Directory Download the script Load Up Some Libraries  Using Themes in ggwhatever  Cleaning and Inspecting Data  Always Inspect your Data! Wrangling Data by Reduction  Manual Approach Prepackaged Approach The Nearly Everyone Does This Approach     .hvr-sweep-to-left { display: inline-block; vertical-align: middle; -webkit-transform: perspective(1px) translateZ(0); transform: perspective(1px) translateZ(0); box-shadow: 0 0 1px rgba(0, 0, 0, 0); position: relative; -webkit-transition-property: color; transition-property: color; -webkit-transition-duration: 0.25s; transition-duration: 0.25s; } .hvr-sweep-to-left:before { content: \"\"; position: absolute; z-index: -1; top: 0; left: 0; right: 0; bottom: 0; background: #003277; -webkit-transform: scaleX(0); transform: scaleX(0); -webkit-transform-origin: 100% 50%; transform-origin: 100% 50%; -webkit-transition-property: transform; transition-property: transform; -webkit-transition-duration: 0.3s; transition-duration: 0.3s; -webkit-transition-timing-function: ease-out; transition-timing-function: ease-out; } .hvr-sweep-to-left:hover, .hvr-sweep-to-left:focus, .hvr-sweep-to-left:active { color: white; } .hvr-sweep-to-left:hover:before, .hvr-sweep-to-left:focus:before, .hvr-sweep-to-left:active:before { -webkit-transform: scaleX(1); transform: scaleX(1); } * { box-sizing: border-box; } .tabs { display: flex; flex-wrap: wrap; max-width: 700px; background: #efefef; box-shadow: 0 48px 80px -32px rgba(0,0,0,0.3); } .input { position: absolute; opacity: 0; } .label { width: 100%; padding: 20px 30px; background: #e5e5e5; cursor: pointer; font-weight: bold; font-size: 18px; color: #7f7f7f; transition: background 0.1s, color 0.1s; } .label:hover { background: #d8d8d8; } .label:active { background: #ccc; } .input:focus + .label { box-shadow: inset 0px 0px 0px 3px #2aa1c0; z-index: 1; } .input:checked + .label { background: #fff; color: #000; } @media (min-width: 600px) { .label { width: auto; } } .panel { display: none; padding: 20px 30px 30px; background: #fff; } @media (min-width: 600px) { .panel { order: 99; } } .input:checked + .label + .panel { display: block; }  Getting Prepped First Things First! Set your Working Directory Your working directory is simply where your script will look for anything it needs like external data sets. There are a few ways to go about doing this which we will cover. However for now, just do the following:\nOpen up a new script by going to File \u0026gt; New File \u0026gt; R Script. Save it in a preferably empty folder as whatever you want. Go to the menu bar and select Session \u0026gt; Set Working Directory \u0026gt; To Source File Location.   Download the script Copying and pasting syntax from a browser can cause problems. To avoid this issue, please download a script with all of the needed code presented in this walkthrough.\n Download the Script   Load Up Some Libraries Please go ahead and download the libraries below you don’t have and load them up\nlibrary(tidyverse) library(viridis) library(RColorBrewer) library(ggthemes) library(ggtext)   Using Themes in ggwhatever One of the nice aspects of ggplot is in the fact that you can edit most of the aesthetics. While aes() let’s you define where those aesthetics lie and the scale family of commands allows for coloring and how the data is represented, how a plot is displayed is found by theme.\nYou can do this either manually or using a prepackaged approach where theme options are already defined. In certain situations you can even use both.\nCleaning and Inspecting Data Let’s use a cleaned version of the income data set.\nincome_data \u0026lt;- read_csv(\u0026quot;income.csv\u0026quot;) ## ## ── Column specification ──────────────────────────────────────────────────────── ## cols( ## Location = col_character(), ## Lower_2000 = col_double(), ## Middle_2000 = col_double(), ## Upper_2000 = col_double(), ## Lower_2014 = col_double(), ## Middle_2014 = col_double(), ## Upper_2014 = col_double() ## ) Always Inspect your Data!1 We can inspect the column names using the names() command\nnames(income_data) ## [1] \u0026quot;Location\u0026quot; \u0026quot;Lower_2000\u0026quot; \u0026quot;Middle_2000\u0026quot; \u0026quot;Upper_2000\u0026quot; \u0026quot;Lower_2014\u0026quot; ## [6] \u0026quot;Middle_2014\u0026quot; \u0026quot;Upper_2014\u0026quot; and what type they are using str() or glimpse()\nglimpse(income_data) ## Rows: 229 ## Columns: 7 ## $ Location \u0026lt;chr\u0026gt; \u0026quot;Akron, OH\u0026quot;, \u0026quot;Albany-Schenectady-Troy, NY\u0026quot;, \u0026quot;Albuquerque,… ## $ Lower_2000 \u0026lt;dbl\u0026gt; 19.9, 22.1, 28.6, 23.0, 32.3, 22.0, 21.9, 33.0, 20.0, 29.… ## $ Middle_2000 \u0026lt;dbl\u0026gt; 59.8, 60.1, 55.4, 60.7, 54.7, 58.2, 51.2, 54.6, 56.0, 59.… ## $ Upper_2000 \u0026lt;dbl\u0026gt; 20.3, 17.8, 16.0, 16.2, 13.0, 19.8, 26.9, 12.4, 23.9, 11.… ## $ Lower_2014 \u0026lt;dbl\u0026gt; 24.5, 20.2, 33.0, 25.2, 27.4, 20.3, 25.6, 33.6, 27.0, 30.… ## $ Middle_2014 \u0026lt;dbl\u0026gt; 54.6, 55.1, 50.7, 55.7, 52.6, 55.5, 49.3, 50.5, 50.5, 52.… ## $ Upper_2014 \u0026lt;dbl\u0026gt; 20.9, 24.8, 16.3, 19.1, 20.0, 24.2, 25.1, 16.0, 22.6, 17.… Well 229 rows is a ton of data and a bar plot would look terrible!\nggplot(income_data, aes(x = Location, y = Lower_2000, fill = Lower_2000)) + geom_bar(stat = \u0026quot;identity\u0026quot;) + xlab(\u0026quot;City and State\u0026quot;) + ylab(\u0026quot;Average Income in 2000 Lower Class\u0026quot;)  Wrangling Data by Reduction2 For simplicity sakes, let’s try just looking at the top 10 highest values in the Lower_2000 column using slice_max()3 command.\nnot_top10_income_data \u0026lt;- income_data %\u0026gt;% select(Location, Lower_2000) %\u0026gt;% slice_max(Lower_2000, n = 10); not_top10_income_data ## # A tibble: 10 x 2 ## Location Lower_2000 ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; ## 1 McAllen-Edinburg-Mission, TX 53.4 ## 2 Laredo, TX 50.9 ## 3 Brownsville-Harlingen, TX 49.8 ## 4 Las Cruces, NM 45.2 ## 5 El Centro, CA 43.9 ## 6 Visalia-Porterville, CA 42.9 ## 7 El Paso, TX 42.7 ## 8 Madera, CA 42.5 ## 9 Merced, CA 41.9 ## 10 Yuma, AZ 41.8 Now please note that this is not equivalent to another function we’ve gone over: head() which would only return the top 10 rows, not the top 10 highest values.\ntop10_income_data \u0026lt;- income_data %\u0026gt;% select(Location, Lower_2000) %\u0026gt;% head(10); top10_income_data ## # A tibble: 10 x 2 ## Location Lower_2000 ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; ## 1 Akron, OH 19.9 ## 2 Albany-Schenectady-Troy, NY 22.1 ## 3 Albuquerque, NM 28.6 ## 4 Allentown-Bethlehem-Easton, PA-NJ 23 ## 5 Amarillo, TX 32.3 ## 6 Anchorage, AK 22 ## 7 Ann Arbor, MI 21.9 ## 8 Anniston-Oxford-Jacksonville, AL 33 ## 9 Atlanta-Sandy Springs-Roswell, GA 20 ## 10 Atlantic City-Hammonton, NJ 29.3 Now let’s plot the wrangled data set\nggplot(top10_income_data, aes(x = Location, y = Lower_2000, fill = Lower_2000)) + geom_bar(stat = \u0026quot;identity\u0026quot;) + xlab(\u0026quot;Top 10 Cities and States\u0026quot;) + ylab(\u0026quot;Average Income in 2000 Lower Class\u0026quot;) That looks good but it could be better. Recall with a scale command you can color the bars\nggplot(top10_income_data, aes(x = Location, y = Lower_2000, fill = Lower_2000)) + geom_bar(stat = \u0026quot;identity\u0026quot;) + scale_fill_viridis_c() + xlab(\u0026quot;Top 10 Cities and States\u0026quot;) + ylab(\u0026quot;Average Income in 2000 Lower Class\u0026quot;) Well the colors are arguably better, though there are other palettes the viridis package provides. We can also reorder the bars from greatest to least or vice versa using the reorder() command4\n Bars from Greatest to Least ggplot(top10_income_data, aes(x = reorder(Location, -Lower_2000), y = Lower_2000, fill = Lower_2000)) + geom_bar(stat = \u0026quot;identity\u0026quot;) + scale_fill_viridis_c() + xlab(\u0026quot;Top 10 Cities and States\u0026quot;) + ylab(\u0026quot;Average Income in 2000 Lower Class\u0026quot;)  Bars from Least to Greatest ggplot(top10_income_data, aes(x = reorder(Location, Lower_2000), y = Lower_2000, fill = Lower_2000)) + geom_bar(stat = \u0026quot;identity\u0026quot;) + scale_fill_viridis_c() + xlab(\u0026quot;Top 10 Cities and States\u0026quot;) + ylab(\u0026quot;Average Income in 2000 Lower Class\u0026quot;)    Well that’s great but with the grey background, overlapping text on the axis, etc., its certainly not really presentation worthy. Luckily we can use the theme() option to edit it!\n  Manual Approach If you like controlling every little aspect of an experience, then you may be a ggplot control freak and the manual approach is perfect!\nTo get a feel for what options you have, try running the following\n?theme Scroll down to Usage to see the commands and Arguments to see a description of each. If you don’t like the tiny Help window or find it convoluted, try giving the tidyverse Reference site a look. It has some additional examples as well, though they may or may not be helpful depending on your needs.\nIn the following, we’ll use the descending data set and themes() to fix it up a bit\nggplot(top10_income_data, aes(x = reorder(Location, -Lower_2000), y = Lower_2000, fill = Lower_2000)) + geom_bar(stat = \u0026quot;identity\u0026quot;) + scale_fill_viridis_c() + theme(axis.text.x = element_text(angle = 33, face = \u0026quot;bold\u0026quot;, vjust = 0.5), axis.title = element_text(size = 14, face = \u0026quot;bold\u0026quot;), legend.position = \u0026quot;right\u0026quot;, legend.direction = \u0026quot;vertical\u0026quot;, panel.grid.minor.x = element_blank(), panel.grid.minor.y = element_line(), panel.grid.major.x = element_blank(), panel.grid.major.y = element_line()) + xlab(\u0026quot;Top 10 Cities and States\u0026quot;) + ylab(\u0026quot;Average Income in 2000 Lower Class\u0026quot;) Well that’s slightly better but its certainly flawed. For example, it is not immediately clear which values on the x-axis goes where. We can do a lot more and we’ll get to it in a bit.\nIf you would like to have more of a drag and drop experience while learning themes in ggplot2, consider downloading and running the package esquisse.\n Prepackaged Approach If you fine with having someone else mostly control an experience allowing you to tinker here and there, then you may be a ggplot doodler and the prepackaged approach is likely a great fit!\nIt may be that you don’t like the default ggplot output but would rather not go through the process of editing every little thing. In these cases you can use predefined themes within ggplot2 or ggthemes package, though there are others. You can see how the the original top10_income_data set looks with these themes.\nDefault in ggplot2  Grey Theme ggplot(top10_income_data, aes(x = reorder(Location, -Lower_2000), y = Lower_2000, fill = Lower_2000)) + geom_bar(stat = \u0026quot;identity\u0026quot;) + theme_grey() + # or theme_gray() xlab(\u0026quot;Top 10 Cities and States\u0026quot;) + ylab(\u0026quot;Average Income in 2000 Lower Class\u0026quot;)  Black and White Theme ggplot(top10_income_data, aes(x = reorder(Location, -Lower_2000), y = Lower_2000, fill = Lower_2000)) + geom_bar(stat = \u0026quot;identity\u0026quot;) + theme_bw() + xlab(\u0026quot;Top 10 Cities and States\u0026quot;) + ylab(\u0026quot;Average Income in 2000 Lower Class\u0026quot;)  Linedraw Theme ggplot(top10_income_data, aes(x = reorder(Location, -Lower_2000), y = Lower_2000, fill = Lower_2000)) + geom_bar(stat = \u0026quot;identity\u0026quot;) + theme_linedraw() + xlab(\u0026quot;Top 10 Cities and States\u0026quot;) + ylab(\u0026quot;Average Income in 2000 Lower Class\u0026quot;)     Light Theme ggplot(top10_income_data, aes(x = reorder(Location, -Lower_2000), y = Lower_2000, fill = Lower_2000)) + geom_bar(stat = \u0026quot;identity\u0026quot;) + theme_light() + xlab(\u0026quot;Top 10 Cities and States\u0026quot;) + ylab(\u0026quot;Average Income in 2000 Lower Class\u0026quot;)  Dark Theme ggplot(top10_income_data, aes(x = reorder(Location, -Lower_2000), y = Lower_2000, fill = Lower_2000)) + geom_bar(stat = \u0026quot;identity\u0026quot;) + theme_dark() + xlab(\u0026quot;Top 10 Cities and States\u0026quot;) + ylab(\u0026quot;Average Income in 2000 Lower Class\u0026quot;)  Minimal Theme ggplot(top10_income_data, aes(x = reorder(Location, -Lower_2000), y = Lower_2000, fill = Lower_2000)) + geom_bar(stat = \u0026quot;identity\u0026quot;) + theme_minimal() + xlab(\u0026quot;Top 10 Cities and States\u0026quot;) + ylab(\u0026quot;Average Income in 2000 Lower Class\u0026quot;)     Classic Theme ggplot(top10_income_data, aes(x = reorder(Location, -Lower_2000), y = Lower_2000, fill = Lower_2000)) + geom_bar(stat = \u0026quot;identity\u0026quot;) + theme_classic() + xlab(\u0026quot;Top 10 Cities and States\u0026quot;) + ylab(\u0026quot;Average Income in 2000 Lower Class\u0026quot;)  Void Theme ggplot(top10_income_data, aes(x = reorder(Location, -Lower_2000), y = Lower_2000, fill = Lower_2000)) + geom_bar(stat = \u0026quot;identity\u0026quot;) + theme_void() + xlab(\u0026quot;Top 10 Cities and States\u0026quot;) + ylab(\u0026quot;Average Income in 2000 Lower Class\u0026quot;)     Using ggthemes  Few Theme ggplot(top10_income_data, aes(x = reorder(Location, -Lower_2000), y = Lower_2000, fill = Lower_2000)) + geom_bar(stat = \u0026quot;identity\u0026quot;) + theme_few() + xlab(\u0026quot;Top 10 Cities and States\u0026quot;) + ylab(\u0026quot;Average Income in 2000 Lower Class\u0026quot;)  Five Thirty Eight Theme ggplot(top10_income_data, aes(x = reorder(Location, -Lower_2000), y = Lower_2000, fill = Lower_2000)) + geom_bar(stat = \u0026quot;identity\u0026quot;) + theme_fivethirtyeight() + xlab(\u0026quot;Top 10 Cities and States\u0026quot;) + ylab(\u0026quot;Average Income in 2000 Lower Class\u0026quot;)  Google Docs Theme ggplot(top10_income_data, aes(x = reorder(Location, -Lower_2000), y = Lower_2000, fill = Lower_2000)) + geom_bar(stat = \u0026quot;identity\u0026quot;) + theme_gdocs() + xlab(\u0026quot;Top 10 Cities and States\u0026quot;) + ylab(\u0026quot;Average Income in 2000 Lower Class\u0026quot;)     Highcharts JS Theme ggplot(top10_income_data, aes(x = reorder(Location, -Lower_2000), y = Lower_2000, fill = Lower_2000)) + geom_bar(stat = \u0026quot;identity\u0026quot;) + theme_hc() + xlab(\u0026quot;Top 10 Cities and States\u0026quot;) + ylab(\u0026quot;Average Income in 2000 Lower Class\u0026quot;)  Inverse Grey Theme ggplot(top10_income_data, aes(x = reorder(Location, -Lower_2000), y = Lower_2000, fill = Lower_2000)) + geom_bar(stat = \u0026quot;identity\u0026quot;) + theme_igray() + xlab(\u0026quot;Top 10 Cities and States\u0026quot;) + ylab(\u0026quot;Average Income in 2000 Lower Class\u0026quot;)     Solarized Palette Theme ggplot(top10_income_data, aes(x = reorder(Location, -Lower_2000), y = Lower_2000, fill = Lower_2000)) + geom_bar(stat = \u0026quot;identity\u0026quot;) + theme_solarized() + xlab(\u0026quot;Top 10 Cities and States\u0026quot;) + ylab(\u0026quot;Average Income in 2000 Lower Class\u0026quot;)  Solid Theme ggplot(top10_income_data, aes(x = reorder(Location, -Lower_2000), y = Lower_2000, fill = Lower_2000)) + geom_bar(stat = \u0026quot;identity\u0026quot;) + theme_solid() + xlab(\u0026quot;Top 10 Cities and States\u0026quot;) + ylab(\u0026quot;Average Income in 2000 Lower Class\u0026quot;)  Stata Theme ggplot(top10_income_data, aes(x = reorder(Location, -Lower_2000), y = Lower_2000, fill = Lower_2000)) + geom_bar(stat = \u0026quot;identity\u0026quot;) + theme_tufte() + xlab(\u0026quot;Top 10 Cities and States\u0026quot;) + ylab(\u0026quot;Average Income in 2000 Lower Class\u0026quot;)     Tufte Theme ggplot(top10_income_data, aes(x = reorder(Location, -Lower_2000), y = Lower_2000, fill = Lower_2000)) + geom_bar(stat = \u0026quot;identity\u0026quot;) + theme_tufte() + xlab(\u0026quot;Top 10 Cities and States\u0026quot;) + ylab(\u0026quot;Average Income in 2000 Lower Class\u0026quot;)  Wall Street Journal Theme ggplot(top10_income_data, aes(x = reorder(Location, -Lower_2000), y = Lower_2000, fill = Lower_2000)) + geom_bar(stat = \u0026quot;identity\u0026quot;) + theme_wsj() + xlab(\u0026quot;Top 10 Cities and States\u0026quot;) + ylab(\u0026quot;Average Income in 2000 Lower Class\u0026quot;)  Excel Theme5 ggplot(top10_income_data, aes(x = reorder(Location, -Lower_2000), y = Lower_2000, fill = Lower_2000)) + geom_bar(stat = \u0026quot;identity\u0026quot;) + theme_excel() + xlab(\u0026quot;Top 10 Cities and States\u0026quot;) + ylab(\u0026quot;Average Income in 2000 Lower Class\u0026quot;)      The Nearly Everyone Does This Approach If you are great with controlling when needed and allowing others to control an experience, then the traditional path of least resistance outlook on ggplot will do just fine!\nYou can in many circumstances combine manual and prepackaged themes together. The extent to which you can do this often varies by theme. In any case, let’s see the fivethirtyeight theme with some manual edits.\nggplot(top10_income_data, aes(x = reorder(Location, -Lower_2000), y = Lower_2000, fill = Lower_2000)) + geom_bar(position = \u0026#39;dodge\u0026#39;, stat = \u0026quot;identity\u0026quot;) + scale_fill_viridis_c() + theme_fivethirtyeight() + theme(axis.text.x = element_text(angle = 45, vjust = 0.5), legend.position = \u0026quot;right\u0026quot;, legend.direction = \u0026quot;vertical\u0026quot;) + xlab(\u0026quot;Top 10 Cities and States\u0026quot;) + ylab(\u0026quot;Average Income in 2000 Lower Class\u0026quot;) + guides(fill=guide_legend(title=\u0026quot;Income\u0026quot;)) Or sometimes controlling the text itself is nice too but we’ll cover that soon. In the meantime, here’s a preview\nggplot(top10_income_data, aes(x = reorder(Location, -Lower_2000), y = Lower_2000, fill = Lower_2000)) + geom_bar(position = \u0026#39;dodge\u0026#39;, width = 0.9, stat = \u0026quot;identity\u0026quot;, color = \u0026quot;#FFFFFF\u0026quot;) + geom_richtext(aes(label = Location), color = \u0026quot;#FFFFFF\u0026quot;, position = position_dodge(width = 0.9), hjust = 0, vjust = -0.1, angle = 45, fontface = \u0026quot;bold\u0026quot;, show.legend = FALSE) + scale_fill_gradient(low = \u0026quot;#52bf90\u0026quot;, high = \u0026quot;#317256\u0026quot;) + theme_minimal() + theme(axis.text.x = element_blank(), axis.title = element_text(size = 14, face = \u0026quot;bold\u0026quot;), legend.position = \u0026quot;right\u0026quot;, legend.direction = \u0026quot;vertical\u0026quot;, panel.grid.minor.x = element_blank(), panel.grid.minor.y = element_line(), panel.grid.major.x = element_blank(), panel.grid.major.y = element_line()) + xlab(\u0026quot;Top 10 Cities and States\u0026quot;) + ylab(\u0026quot;Average Income in 2000 Lower Class\u0026quot;) + guides(fill = guide_legend(title = \u0026quot;Income\u0026quot;, reverse = TRUE)) + expand_limits(x=c(0,14), y=c(0, 60))    This includes opening up the data set and viewing a corresponding codebook if available.↩︎\n While you’ve likely heard it before many many many times, it is generally unethical, not to mention statistically destructive to throw out any data without using proper methodology and reasoning↩︎\n or you can use slice_min() for the lowest values↩︎\n We can actually do this in many ways. This particular method is called the data.table approach.↩︎\n For some reason↩︎\n   ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"c977a82d5f9c9c6bf14f43f56de0b41e","permalink":"https://edp693e.theoreticalphysed.com/example/04-example/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/example/04-example/","section":"example","summary":"Getting Prepped  First Things First! Set your Working Directory Download the script Load Up Some Libraries  Using Themes in ggwhatever  Cleaning and Inspecting Data  Always Inspect your Data!","tags":null,"title":"Tidy Themes","type":"docs"},{"authors":null,"categories":null,"content":"   Data Camp   Data Camp This week you have twos module to cover on Data Camp. In particular this are\n Exploratory Data Analysis in R\n Introduction to the Tidyverse\n  For more information about these, take a look at the tentative schedule.\n ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"5a003ab3247913ac8f1034d05b4692ee","permalink":"https://edp693e.theoreticalphysed.com/lesson/04-lesson/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/lesson/04-lesson/","section":"lesson","summary":"Data Camp   Data Camp This week you have twos module to cover on Data Camp. In particular this are\n Exploratory Data Analysis in R","tags":null,"title":"Tidy Themes","type":"docs"},{"authors":null,"categories":null,"content":"    What to Do: Replicate Using ggplot  Visualization Choices  Choice 1: Government Data Choice 2: Surface Temperatures Choice 3: Average Temperatures Choice 4: Baseball   How to Do It:  More about Rmarkdown     .hvr-sweep-to-left { display: inline-block; vertical-align: middle; -webkit-transform: perspective(1px) translateZ(0); transform: perspective(1px) translateZ(0); box-shadow: 0 0 1px rgba(0, 0, 0, 0); position: relative; -webkit-transition-property: color; transition-property: color; -webkit-transition-duration: 0.25s; transition-duration: 0.25s; } .hvr-sweep-to-left:before { content: \"\"; position: absolute; z-index: -1; top: 0; left: 0; right: 0; bottom: 0; background: #733367; -webkit-transform: scaleX(0); transform: scaleX(0); -webkit-transform-origin: 100% 50%; transform-origin: 100% 50%; -webkit-transition-property: transform; transition-property: transform; -webkit-transition-duration: 0.3s; transition-duration: 0.3s; -webkit-transition-timing-function: ease-out; transition-timing-function: ease-out; } .hvr-sweep-to-left:hover, .hvr-sweep-to-left:focus, .hvr-sweep-to-left:active { color: white; } .hvr-sweep-to-left:hover:before, .hvr-sweep-to-left:focus:before, .hvr-sweep-to-left:active:before { -webkit-transform: scaleX(1); transform: scaleX(1); }  What to Do: Replicate Using ggplot In this task, you are asked to do three things:\n Pick one of the Plots given in the tabs.\n Replicate a static version of it using ggplot2\n Produce one alternative visualization using the same dataset in ggplot2\n  Visualization Choices Choice 1: Government Data This graphic was published in the New York Times back in 2012. You are tasked to replicate and construct an alternative for it.\nDownload the visual\nDownload the data set divided.csv to construct this visualization.\n Choice 2: Surface Temperatures You are looking at the surface temperature Dec 2001 on a very coarse 24 by 24 grid covering Central America. You are tasked to replicate and construct an alternative for it (Hint: use geom_tile())\nDownload the visual\nTo get the data, run the following in your script and Rmarkdown document:\ninstall.packages(\u0026quot;nasaweather\u0026quot;) library(nasaweather) jan2001 \u0026lt;- subset(atmos, year == 2000 \u0026amp; month == 1)  Choice 3: Average Temperatures This data set for the following plot includes the average mean, minimum, and maximum daily temperature in Corvallis, Oregon based on a ten year span. You are tasked to replicate and construct an alternative for it: (Hint: use geom_pointrange())\nDownload the visual\nDownload the data set corv.csv to construct this visualization.\n Choice 4: Baseball This graphic was published in the New York Times back in 2013. You are tasked to replicate and construct an alternative for it.\nDownload the visual\nTo get the data, run the following in your script and Rmarkdown document:\ninstall.packages(Lahman) library(Lahman) library(dplyr) # Pipes everwhere! so_by_team \u0026lt;- select(Teams, yearID, name, G, SO) %\u0026gt;% mutate(strikeouts_per_game = SO/G) avg_so_by_year \u0026lt;- so_by_team %\u0026gt;% group_by(yearID) %\u0026gt;% summarise(avg_so = mean(strikeouts_per_game)) # you can either use both so_by_team \u0026amp; avg_so_by_year, # or use only so_by_team and look at ?stat_summary    How to Do It: Open the Relications_Practice_Script.R blank R script or simple create one as you normally would. Then get to replicating one of the visualizations given above using the corresponding data set.\n After you are happy with your plots, double click and open the file Replications.rmd. It should load up into RStudio.\n Follow the directions and copy the appropriate parts over. Make sure to compile the document!\n Submit the PDF output of the Rmarkdown to #wk-5-replications\n  You can download all of the scripts to fetch data, Relications_Practice_Script.R and Replications.rmd by clicking below\n Download the files  More about Rmarkdown Its not a bad idea to see what you can do with an Rmarkdown document. For example, you can actually output a file in nearly any format (e.g. Pages, PDF, HTML, Word, etc.) In fact this course website is written on an Rmarkdown platform called Blogdown.\nHere are some resources that may be helpful at the current time:\n Getting Started with Rmarkdown R Markdown Cheat Sheet R Markdown for beginners Using R Markdown    ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"7337e9261c3514039025dedd39df2948","permalink":"https://edp693e.theoreticalphysed.com/assignment/05-assignment/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/assignment/05-assignment/","section":"assignment","summary":"What to Do: Replicate Using ggplot  Visualization Choices  Choice 1: Government Data Choice 2: Surface Temperatures Choice 3: Average Temperatures Choice 4: Baseball   How to Do It:  More about Rmarkdown     .","tags":null,"title":"Making Copies","type":"docs"},{"authors":null,"categories":null,"content":"    What’s Due?   What’s Due?    Data Camp  eCampus  R  Slack  Description  Location                  Create a replication and alternative visualization  Link                Complete two modules  Link      Note: These tasks are provided in a recommended order.\n ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"a231b77af4723575ec2f6a55e71ed37d","permalink":"https://edp693e.theoreticalphysed.com/due/05-due/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/due/05-due/","section":"due","summary":"What’s Due?   What’s Due?    Data Camp  eCampus  R  Slack  Description  Location                  Create a replication and alternative visualization  Link                Complete two modules  Link      Note: These tasks are provided in a recommended order.","tags":null,"title":"Making Copies","type":"docs"},{"authors":null,"categories":null,"content":"    Getting Prepped  First Things First! Set your Working Directory Download the script Read the Submission Directions Load Up Some Libraries  Part 1: More ggplotting  Finding variables Getting counts Example: Using R to Test Hypotheses  Hypothesis Exploring the Data   Part 2: Aesthetics Part 3: Grouping Part 4: Facets    .hvr-sweep-to-left { display: inline-block; vertical-align: middle; -webkit-transform: perspective(1px) translateZ(0); transform: perspective(1px) translateZ(0); box-shadow: 0 0 1px rgba(0, 0, 0, 0); position: relative; -webkit-transition-property: color; transition-property: color; -webkit-transition-duration: 0.25s; transition-duration: 0.25s; } .hvr-sweep-to-left:before { content: \"\"; position: absolute; z-index: -1; top: 0; left: 0; right: 0; bottom: 0; background: #003277; -webkit-transform: scaleX(0); transform: scaleX(0); -webkit-transform-origin: 100% 50%; transform-origin: 100% 50%; -webkit-transition-property: transform; transition-property: transform; -webkit-transition-duration: 0.3s; transition-duration: 0.3s; -webkit-transition-timing-function: ease-out; transition-timing-function: ease-out; } .hvr-sweep-to-left:hover, .hvr-sweep-to-left:focus, .hvr-sweep-to-left:active { color: white; } .hvr-sweep-to-left:hover:before, .hvr-sweep-to-left:focus:before, .hvr-sweep-to-left:active:before { -webkit-transform: scaleX(1); transform: scaleX(1); } * { box-sizing: border-box; } .tabs { display: flex; flex-wrap: wrap; max-width: 700px; background: #efefef; box-shadow: 0 48px 80px -32px rgba(0,0,0,0.3); } .input { position: absolute; opacity: 0; } .label { width: 100%; padding: 20px 30px; background: #e5e5e5; cursor: pointer; font-weight: bold; font-size: 18px; color: #7f7f7f; transition: background 0.1s, color 0.1s; } .label:hover { background: #d8d8d8; } .label:active { background: #ccc; } .input:focus + .label { box-shadow: inset 0px 0px 0px 3px #2aa1c0; z-index: 1; } .input:checked + .label { background: #fff; color: #000; } @media (min-width: 600px) { .label { width: auto; } } .panel { display: none; padding: 20px 30px 30px; background: #fff; } @media (min-width: 600px) { .panel { order: 99; } } .input:checked + .label + .panel { display: block; }  Getting Prepped First Things First! Set your Working Directory Your working directory is simply where your script will look for anything it needs like external data sets. There are a few ways to go about doing this which we will cover. However for now, just do the following:\nOpen up a new script by going to File \u0026gt; New File \u0026gt; R Script. Save it in a preferably empty folder as whatever you want. Go to the menu bar and select Session \u0026gt; Set Working Directory \u0026gt; To Source File Location.   Download the script Copying and pasting syntax from a browser can cause problems. To avoid this issue, please download a script with all of the needed code presented in this walkthrough.\n Download the Script   Read the Submission Directions On a separate document (WORD or PDF), answer the questions in parts 1, 2, and 4. You may work alone of together in groups of up to three people and submit one task on eCampus by the end of class today.\n Load Up Some Libraries Please go ahead and download the libraries below you don’t have and load them up\nlibrary(tidyverse)   Part 1: More ggplotting Scenario: Do cars with big engines use more fuel than cars with small engines?\nOK so you probably know the answer but let’s make the justification as precise as possible.\nLet’s use the mpg data frame found in ggplot2. The data frame contains observations collected by the US Environment Protection Agency on 38 car models. To see all of the unique values, we can run\nunique(mpg$manufacturer) ## [1] \u0026quot;audi\u0026quot; \u0026quot;chevrolet\u0026quot; \u0026quot;dodge\u0026quot; \u0026quot;ford\u0026quot; \u0026quot;honda\u0026quot; ## [6] \u0026quot;hyundai\u0026quot; \u0026quot;jeep\u0026quot; \u0026quot;land rover\u0026quot; \u0026quot;lincoln\u0026quot; \u0026quot;mercury\u0026quot; ## [11] \u0026quot;nissan\u0026quot; \u0026quot;pontiac\u0026quot; \u0026quot;subaru\u0026quot; \u0026quot;toyota\u0026quot; \u0026quot;volkswagen\u0026quot; which is equivalent to the following as a tibble\nmpg %\u0026gt;% select(manufacturer) %\u0026gt;% distinct() ## # A tibble: 15 x 1 ## manufacturer ## \u0026lt;chr\u0026gt; ## 1 audi ## 2 chevrolet ## 3 dodge ## 4 ford ## 5 honda ## 6 hyundai ## 7 jeep ## 8 land rover ## 9 lincoln ## 10 mercury ## 11 nissan ## 12 pontiac ## 13 subaru ## 14 toyota ## 15 volkswagen Finding variables We can use glimpse to see more about each variable\nglimpse(mpg) ## Rows: 234 ## Columns: 11 ## $ manufacturer \u0026lt;chr\u0026gt; \u0026quot;audi\u0026quot;, \u0026quot;audi\u0026quot;, \u0026quot;audi\u0026quot;, \u0026quot;audi\u0026quot;, \u0026quot;audi\u0026quot;, \u0026quot;audi\u0026quot;, \u0026quot;audi\u0026quot;, … ## $ model \u0026lt;chr\u0026gt; \u0026quot;a4\u0026quot;, \u0026quot;a4\u0026quot;, \u0026quot;a4\u0026quot;, \u0026quot;a4\u0026quot;, \u0026quot;a4\u0026quot;, \u0026quot;a4\u0026quot;, \u0026quot;a4\u0026quot;, \u0026quot;a4 quattro\u0026quot;, … ## $ displ \u0026lt;dbl\u0026gt; 1.8, 1.8, 2.0, 2.0, 2.8, 2.8, 3.1, 1.8, 1.8, 2.0, 2.0, 2… ## $ year \u0026lt;int\u0026gt; 1999, 1999, 2008, 2008, 1999, 1999, 2008, 1999, 1999, 20… ## $ cyl \u0026lt;int\u0026gt; 4, 4, 4, 4, 6, 6, 6, 4, 4, 4, 4, 6, 6, 6, 6, 6, 6, 8, 8,… ## $ trans \u0026lt;chr\u0026gt; \u0026quot;auto(l5)\u0026quot;, \u0026quot;manual(m5)\u0026quot;, \u0026quot;manual(m6)\u0026quot;, \u0026quot;auto(av)\u0026quot;, \u0026quot;aut… ## $ drv \u0026lt;chr\u0026gt; \u0026quot;f\u0026quot;, \u0026quot;f\u0026quot;, \u0026quot;f\u0026quot;, \u0026quot;f\u0026quot;, \u0026quot;f\u0026quot;, \u0026quot;f\u0026quot;, \u0026quot;f\u0026quot;, \u0026quot;4\u0026quot;, \u0026quot;4\u0026quot;, \u0026quot;4\u0026quot;, \u0026quot;4\u0026quot;, \u0026quot;… ## $ cty \u0026lt;int\u0026gt; 18, 21, 20, 21, 16, 18, 18, 18, 16, 20, 19, 15, 17, 17, … ## $ hwy \u0026lt;int\u0026gt; 29, 29, 31, 30, 26, 26, 27, 26, 25, 28, 27, 25, 25, 25, … ## $ fl \u0026lt;chr\u0026gt; \u0026quot;p\u0026quot;, \u0026quot;p\u0026quot;, \u0026quot;p\u0026quot;, \u0026quot;p\u0026quot;, \u0026quot;p\u0026quot;, \u0026quot;p\u0026quot;, \u0026quot;p\u0026quot;, \u0026quot;p\u0026quot;, \u0026quot;p\u0026quot;, \u0026quot;p\u0026quot;, \u0026quot;p\u0026quot;, \u0026quot;… ## $ class \u0026lt;chr\u0026gt; \u0026quot;compact\u0026quot;, \u0026quot;compact\u0026quot;, \u0026quot;compact\u0026quot;, \u0026quot;compact\u0026quot;, \u0026quot;compact\u0026quot;, \u0026quot;…  Getting counts We can use a quick(ish) plot of the manufacturers and how many of each is represented in the data set1\nggplot(mpg, aes(x = manufacturer, fill = manufacturer)) + geom_bar() + geom_text(stat = \u0026#39;count\u0026#39;, aes(label = after_stat(count)), vjust = -0.5) + theme_minimal() + theme(axis.text.x = element_text(angle = 45, vjust = 1.3, hjust = 1))  but sometimes its just easier to use dplyr\nmpg %\u0026gt;% select(manufacturer) %\u0026gt;% group_by(manufacturer) %\u0026gt;% tally() %\u0026gt;% ungroup() ## # A tibble: 15 x 2 ## manufacturer n ## * \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; ## 1 audi 18 ## 2 chevrolet 19 ## 3 dodge 37 ## 4 ford 25 ## 5 honda 9 ## 6 hyundai 14 ## 7 jeep 8 ## 8 land rover 4 ## 9 lincoln 3 ## 10 mercury 4 ## 11 nissan 13 ## 12 pontiac 5 ## 13 subaru 14 ## 14 toyota 34 ## 15 volkswagen 27 which is basically saying\nGet the `mpg` tibble %\u0026gt;% Only show me the column `manufacturer` %\u0026gt;% Perform any wrangling by car manufacturer %\u0026gt;% Count by car manufacturer %\u0026gt;% Dont do any more wrangling by car manufacturer The last step is somewhat important. R remembers certain things and grouping is one of them so its a good idea to ungroup() columns unless you know that is needed.\nSo what would happen if we didn’t group? Well let’s see\nmpg %\u0026gt;% select(manufacturer) %\u0026gt;% tally()  ## # A tibble: 1 x 1 ## n ## \u0026lt;int\u0026gt; ## 1 234 It just gave us a full count of all cars. So grouping is a lifesaver if you want to perform any operations by the values in a column.\n Example: Using R to Test Hypotheses Notice from the output\nnames(mpg) ## [1] \u0026quot;manufacturer\u0026quot; \u0026quot;model\u0026quot; \u0026quot;displ\u0026quot; \u0026quot;year\u0026quot; \u0026quot;cyl\u0026quot; ## [6] \u0026quot;trans\u0026quot; \u0026quot;drv\u0026quot; \u0026quot;cty\u0026quot; \u0026quot;hwy\u0026quot; \u0026quot;fl\u0026quot; ## [11] \u0026quot;class\u0026quot; that\ndispl: a car’s engine size in liters. hwy: a car’s fuel efficiency on the highway, in miles per gallon (mpg).  Hypothesis In all cases, a car with a low fuel efficiency consumes more fuel than a car with a high fuel efficiency when they travel the same distance.\n Exploring the Data Let’s take the variables displ and hwy and try to use them in plots\nggplot(data = mpg) + geom_point(aes(x = displ, y = hwy)) So what happened here? Well we simply put displ on the x-axis and hwy on the y-axis to compare them using points. The plot shows a negative relationship between engine size (displ) and fuel efficiency (hwy). In other words, cars with big engines use more fuel. Does this confirm or refute the hypothesis about fuel efficiency and engine size?\nPart 1 Questions for You to Turn In Run ggplot(data = mpg). What do you see and why is it that way? How many rows are in mpg? How many columns? What does the drv variable describe? Make a scatterplot of hwy vs cyl. What happens if you make a scatterplot of class vs drv? Is the plot useful? Why or why not?      Part 2: Aesthetics Aesthetics are more than just coloring a plot, you can define directions, shapes, sizes, types, and provide a useful way to bring in a third variable into a static two dimensional image.\nSo how is this done? Well in a nutshell you can add a third variable to a two dimensional scatterplot by mapping it to an aesthetic. Recall that an aesthetic is a visual property of the objects in your plot.\nYou can convey information about your data by mapping the aesthetics in your plot to the variables in your dataset. For example, you can map the colors of your points to the class variable to reveal the class of each car.\nggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy, color = class))  or if you like British English, colour can be used interchangeably\nAs a reminder, to map an aesthetic to a variable, associate the name of the aesthetic to the name of the variable inside aes(). ggplot2 will automatically assign a unique level of the aesthetic - here a unique color - to each unique value of the variable, a process known as scaling.\nggplot2 will also add a legend that explains which levels correspond to which values but you can turn that off as well.\nWith that said, we mapped class to the color aesthetic, and though pretty2 that may not be the best method since the graphic is a bit hard to decipher immediately. Instead, we could have mapped class to the size aesthetic in the same way.\nggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy, size = class))  ## Warning: Using size for a discrete variable is not advised. So what’s up with the warning? In this case, the exact size of each point would reveal its class affiliation. So the warning is telling us that mapping an unordered variable (class) to an ordered aesthetic (size) is not a good idea.\nBasically you are trying to plot a categorical variable - the manufacturers of cars - against a continuous variable - a vehicle’s fuel efficiency on the highway - and its telling you that you probably shouldn’t do that3.\nOk well let’s try something else to distinguish the types of vehicles.\nWhat about the alpha level better known as transparency, or how much of the color can you see through?\nggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy, alpha = class)) ## Warning: Using alpha for a discrete variable is not advised. No? Maybe the shape then\nggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy, shape = class)) ## Warning: The shape palette can deal with a maximum of 6 discrete values because ## more than 6 becomes difficult to discriminate; you have 7. Consider ## specifying shapes manually if you must have them. ## Warning: Removed 62 rows containing missing values (geom_point). Uh oh. Something is missing from the plot! So what happened to the SUVs? ggplot2 will only use six shapes at a time. By default, additional groups will go unplotted when you use the shape aesthetic so remember this and you’ll save yourself from throwing a computer.\nIf you are a controlling person, you can also set the aesthetic properties of your geom manually. For example, we can make all of the points in our plot blue\nggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy), color = \u0026quot;blue\u0026quot;) or even WVU Blue\nggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy), color = \u0026quot;#002855\u0026quot;) Part 2 Questions for You to Turn In Run the following:  ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy, color = \u0026quot;blue\u0026quot;)) Why are the points not blue? What has gone wrong with this code and what is it actually doing?\nWhich variables in mpg are   categorical? continuous?  Map a continuous variable to color, size, and shape. How do these aesthetics behave differently for categorical vs. continuous variables?\n Briefly describe happens if you map the same variable to multiple aesthetics?\n What does the stroke aesthetic do? What shapes does it work with? (Hint: you could use ?geom_point)\n What happens if you map an aesthetic to something other than a variable name, like aes(colour = displ \u0026lt; 5)?\n    Part 3: Grouping Maybe you’d like to use multiple colors. Let try something fun based off of this palette\nggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy), color = c(\u0026quot;#34738f\u0026quot;, \u0026quot;#122f3d\u0026quot;, \u0026quot;#be3e2b\u0026quot;, \u0026quot;#ed8a45\u0026quot;, \u0026quot;#f6de6c\u0026quot;)) Uh oh. That didn’t work. Why not?\nWell to ggplot there are 234 different data points and it doesn’t know how you want that color palette distributed. By the power of mathematics, 5 \u0026lt; 234 so you get an error. To fix it, you either assign 1 color to every data point or 234 different colors. Neither of these sound great. So what can we do?\nWell we can group by category. That may help. If you run\nmpg$class ## [1] \u0026quot;compact\u0026quot; \u0026quot;compact\u0026quot; \u0026quot;compact\u0026quot; \u0026quot;compact\u0026quot; \u0026quot;compact\u0026quot; ## [6] \u0026quot;compact\u0026quot; \u0026quot;compact\u0026quot; \u0026quot;compact\u0026quot; \u0026quot;compact\u0026quot; \u0026quot;compact\u0026quot; ## [11] \u0026quot;compact\u0026quot; \u0026quot;compact\u0026quot; \u0026quot;compact\u0026quot; \u0026quot;compact\u0026quot; \u0026quot;compact\u0026quot; ## [16] \u0026quot;midsize\u0026quot; \u0026quot;midsize\u0026quot; \u0026quot;midsize\u0026quot; \u0026quot;suv\u0026quot; \u0026quot;suv\u0026quot; ## [21] \u0026quot;suv\u0026quot; \u0026quot;suv\u0026quot; \u0026quot;suv\u0026quot; \u0026quot;2seater\u0026quot; \u0026quot;2seater\u0026quot; ## [26] \u0026quot;2seater\u0026quot; \u0026quot;2seater\u0026quot; \u0026quot;2seater\u0026quot; \u0026quot;suv\u0026quot; \u0026quot;suv\u0026quot; ## [31] \u0026quot;suv\u0026quot; \u0026quot;suv\u0026quot; \u0026quot;midsize\u0026quot; \u0026quot;midsize\u0026quot; \u0026quot;midsize\u0026quot; ## [36] \u0026quot;midsize\u0026quot; \u0026quot;midsize\u0026quot; \u0026quot;minivan\u0026quot; \u0026quot;minivan\u0026quot; \u0026quot;minivan\u0026quot; ## [41] \u0026quot;minivan\u0026quot; \u0026quot;minivan\u0026quot; \u0026quot;minivan\u0026quot; \u0026quot;minivan\u0026quot; \u0026quot;minivan\u0026quot; ## [46] \u0026quot;minivan\u0026quot; \u0026quot;minivan\u0026quot; \u0026quot;minivan\u0026quot; \u0026quot;pickup\u0026quot; \u0026quot;pickup\u0026quot; ## [51] \u0026quot;pickup\u0026quot; \u0026quot;pickup\u0026quot; \u0026quot;pickup\u0026quot; \u0026quot;pickup\u0026quot; \u0026quot;pickup\u0026quot; ## [56] \u0026quot;pickup\u0026quot; \u0026quot;pickup\u0026quot; \u0026quot;suv\u0026quot; \u0026quot;suv\u0026quot; \u0026quot;suv\u0026quot; ## [61] \u0026quot;suv\u0026quot; \u0026quot;suv\u0026quot; \u0026quot;suv\u0026quot; \u0026quot;suv\u0026quot; \u0026quot;pickup\u0026quot; ## [66] \u0026quot;pickup\u0026quot; \u0026quot;pickup\u0026quot; \u0026quot;pickup\u0026quot; \u0026quot;pickup\u0026quot; \u0026quot;pickup\u0026quot; ## [71] \u0026quot;pickup\u0026quot; \u0026quot;pickup\u0026quot; \u0026quot;pickup\u0026quot; \u0026quot;pickup\u0026quot; \u0026quot;suv\u0026quot; ## [76] \u0026quot;suv\u0026quot; \u0026quot;suv\u0026quot; \u0026quot;suv\u0026quot; \u0026quot;suv\u0026quot; \u0026quot;suv\u0026quot; ## [81] \u0026quot;suv\u0026quot; \u0026quot;suv\u0026quot; \u0026quot;suv\u0026quot; \u0026quot;pickup\u0026quot; \u0026quot;pickup\u0026quot; ## [86] \u0026quot;pickup\u0026quot; \u0026quot;pickup\u0026quot; \u0026quot;pickup\u0026quot; \u0026quot;pickup\u0026quot; \u0026quot;pickup\u0026quot; ## [91] \u0026quot;subcompact\u0026quot; \u0026quot;subcompact\u0026quot; \u0026quot;subcompact\u0026quot; \u0026quot;subcompact\u0026quot; \u0026quot;subcompact\u0026quot; ## [96] \u0026quot;subcompact\u0026quot; \u0026quot;subcompact\u0026quot; \u0026quot;subcompact\u0026quot; \u0026quot;subcompact\u0026quot; \u0026quot;subcompact\u0026quot; ## [101] \u0026quot;subcompact\u0026quot; \u0026quot;subcompact\u0026quot; \u0026quot;subcompact\u0026quot; \u0026quot;subcompact\u0026quot; \u0026quot;subcompact\u0026quot; ## [106] \u0026quot;subcompact\u0026quot; \u0026quot;subcompact\u0026quot; \u0026quot;subcompact\u0026quot; \u0026quot;midsize\u0026quot; \u0026quot;midsize\u0026quot; ## [111] \u0026quot;midsize\u0026quot; \u0026quot;midsize\u0026quot; \u0026quot;midsize\u0026quot; \u0026quot;midsize\u0026quot; \u0026quot;midsize\u0026quot; ## [116] \u0026quot;subcompact\u0026quot; \u0026quot;subcompact\u0026quot; \u0026quot;subcompact\u0026quot; \u0026quot;subcompact\u0026quot; \u0026quot;subcompact\u0026quot; ## [121] \u0026quot;subcompact\u0026quot; \u0026quot;subcompact\u0026quot; \u0026quot;suv\u0026quot; \u0026quot;suv\u0026quot; \u0026quot;suv\u0026quot; ## [126] \u0026quot;suv\u0026quot; \u0026quot;suv\u0026quot; \u0026quot;suv\u0026quot; \u0026quot;suv\u0026quot; \u0026quot;suv\u0026quot; ## [131] \u0026quot;suv\u0026quot; \u0026quot;suv\u0026quot; \u0026quot;suv\u0026quot; \u0026quot;suv\u0026quot; \u0026quot;suv\u0026quot; ## [136] \u0026quot;suv\u0026quot; \u0026quot;suv\u0026quot; \u0026quot;suv\u0026quot; \u0026quot;suv\u0026quot; \u0026quot;suv\u0026quot; ## [141] \u0026quot;suv\u0026quot; \u0026quot;compact\u0026quot; \u0026quot;compact\u0026quot; \u0026quot;midsize\u0026quot; \u0026quot;midsize\u0026quot; ## [146] \u0026quot;midsize\u0026quot; \u0026quot;midsize\u0026quot; \u0026quot;midsize\u0026quot; \u0026quot;midsize\u0026quot; \u0026quot;midsize\u0026quot; ## [151] \u0026quot;suv\u0026quot; \u0026quot;suv\u0026quot; \u0026quot;suv\u0026quot; \u0026quot;suv\u0026quot; \u0026quot;midsize\u0026quot; ## [156] \u0026quot;midsize\u0026quot; \u0026quot;midsize\u0026quot; \u0026quot;midsize\u0026quot; \u0026quot;midsize\u0026quot; \u0026quot;suv\u0026quot; ## [161] \u0026quot;suv\u0026quot; \u0026quot;suv\u0026quot; \u0026quot;suv\u0026quot; \u0026quot;suv\u0026quot; \u0026quot;suv\u0026quot; ## [166] \u0026quot;subcompact\u0026quot; \u0026quot;subcompact\u0026quot; \u0026quot;subcompact\u0026quot; \u0026quot;subcompact\u0026quot; \u0026quot;compact\u0026quot; ## [171] \u0026quot;compact\u0026quot; \u0026quot;compact\u0026quot; \u0026quot;compact\u0026quot; \u0026quot;suv\u0026quot; \u0026quot;suv\u0026quot; ## [176] \u0026quot;suv\u0026quot; \u0026quot;suv\u0026quot; \u0026quot;suv\u0026quot; \u0026quot;suv\u0026quot; \u0026quot;midsize\u0026quot; ## [181] \u0026quot;midsize\u0026quot; \u0026quot;midsize\u0026quot; \u0026quot;midsize\u0026quot; \u0026quot;midsize\u0026quot; \u0026quot;midsize\u0026quot; ## [186] \u0026quot;midsize\u0026quot; \u0026quot;compact\u0026quot; \u0026quot;compact\u0026quot; \u0026quot;compact\u0026quot; \u0026quot;compact\u0026quot; ## [191] \u0026quot;compact\u0026quot; \u0026quot;compact\u0026quot; \u0026quot;compact\u0026quot; \u0026quot;compact\u0026quot; \u0026quot;compact\u0026quot; ## [196] \u0026quot;compact\u0026quot; \u0026quot;compact\u0026quot; \u0026quot;compact\u0026quot; \u0026quot;suv\u0026quot; \u0026quot;suv\u0026quot; ## [201] \u0026quot;pickup\u0026quot; \u0026quot;pickup\u0026quot; \u0026quot;pickup\u0026quot; \u0026quot;pickup\u0026quot; \u0026quot;pickup\u0026quot; ## [206] \u0026quot;pickup\u0026quot; \u0026quot;pickup\u0026quot; \u0026quot;compact\u0026quot; \u0026quot;compact\u0026quot; \u0026quot;compact\u0026quot; ## [211] \u0026quot;compact\u0026quot; \u0026quot;compact\u0026quot; \u0026quot;compact\u0026quot; \u0026quot;compact\u0026quot; \u0026quot;compact\u0026quot; ## [216] \u0026quot;compact\u0026quot; \u0026quot;compact\u0026quot; \u0026quot;compact\u0026quot; \u0026quot;compact\u0026quot; \u0026quot;compact\u0026quot; ## [221] \u0026quot;compact\u0026quot; \u0026quot;subcompact\u0026quot; \u0026quot;subcompact\u0026quot; \u0026quot;subcompact\u0026quot; \u0026quot;subcompact\u0026quot; ## [226] \u0026quot;subcompact\u0026quot; \u0026quot;subcompact\u0026quot; \u0026quot;midsize\u0026quot; \u0026quot;midsize\u0026quot; \u0026quot;midsize\u0026quot; ## [231] \u0026quot;midsize\u0026quot; \u0026quot;midsize\u0026quot; \u0026quot;midsize\u0026quot; \u0026quot;midsize\u0026quot; that doesn’t help you much in figuring out the types of vehicles we have (yes we did find it before by plotting but assume we hadn’t). Unless you like to clean this type of mess, we simply want to find the unique values and moreover, for coloring purposes, how many we have.\nAgain to find a list of unique values, we can run\nunique(mpg$class) ## [1] \u0026quot;compact\u0026quot; \u0026quot;midsize\u0026quot; \u0026quot;suv\u0026quot; \u0026quot;2seater\u0026quot; \u0026quot;minivan\u0026quot; ## [6] \u0026quot;pickup\u0026quot; \u0026quot;subcompact\u0026quot; Well that’s better but I’m lazy and don’t want to count so let’s find the number of unique values\nlength(unique(mpg$class)) ## [1] 7 Oh good! There are 7 so that implies when we plot by class (type of vehicle), we need to have seven colors.\nggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy, color = class)) which we did earlier. But to fill it with what we want, we need to override the default colors\nggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy, color = class)) + scale_color_manual(values = c(\u0026quot;#490A3D\u0026quot;, \u0026quot;#BD1550\u0026quot;, \u0026quot;#E97F02\u0026quot;, \u0026quot;#F8CA00\u0026quot;, \u0026quot;#8A9B0F\u0026quot;, \u0026quot;#95C7D8\u0026quot;, \u0026quot;#FFBFF5\u0026quot;)) Note that since the class variable (type of vehicle) is discrete, we can use scale_color_manual(). Other discrete scales in ggplot can be found here\nContinuous variables use other scales and you can fins more about that and other scales can be found here\nNow those dots are pretty small. Let’s make them bigger.\nggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy, color = class), size = 2) + scale_color_manual(values = c(\u0026quot;#490A3D\u0026quot;, \u0026quot;#BD1550\u0026quot;, \u0026quot;#E97F02\u0026quot;, \u0026quot;#F8CA00\u0026quot;, \u0026quot;#8A9B0F\u0026quot;, \u0026quot;#95C7D8\u0026quot;, \u0026quot;#FFBFF5\u0026quot;)) That does look better but why is the size now within the geom_point aesthetic? If you don’t know, that’s ok! We’ll get to that later but for now, think about it.\nNOTE You’re writing code so you will get errors! But one common problem when creating ggplot2 graphics is to put the + in the wrong place:\nIt has to come at the end of the line, not the start. In other words, make sure you haven’t accidentally written code like this\nggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy)) If you’re still stuck, try the help. You can get help about any R function by running ?function_name in the console, or selecting the function name and pressing F1 in RStudio. Don’t worry if the help doesn’t seem that helpful - instead skip down to the examples and look for examples that may match what you’re trying to do. For the aesthetics, run\n?aes\n  Part 4: Facets Another way to add additional variables is with aesthetics. Another way, particularly useful for categorical variables, is to split your plot into facets, subplots that each display one subset of the data set.\nTo facet your plot by a single variable, you can use facet_wrap() or facet_grid(). Let’s fow now just concentrate on wrapping the data set.\nThe first argument of facet_wrap() should be a formula, which you create with ~ followed by a variable name - here “formula” is the name of a data structure in R, not a synonym for an “equation”.\nThe variable that you pass to facet_wrap() should be discrete so it can essentially be split apart.\nggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy, color = class), size = 2) + scale_color_manual(values = c(\u0026quot;#490A3D\u0026quot;, \u0026quot;#BD1550\u0026quot;, \u0026quot;#E97F02\u0026quot;, \u0026quot;#F8CA00\u0026quot;, \u0026quot;#8A9B0F\u0026quot;, \u0026quot;#95C7D8\u0026quot;, \u0026quot;#FFBFF5\u0026quot;)) + facet_wrap(~ class, nrow = 2) To facet your plot on the combination of two variables, use facet_grid() to your plot The first argument of this is also a formula. This time the formula should contain two variable names separated by a ~.\nggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy, color = class), size = 2) + scale_color_manual(values = c(\u0026quot;#490A3D\u0026quot;, \u0026quot;#BD1550\u0026quot;, \u0026quot;#E97F02\u0026quot;, \u0026quot;#F8CA00\u0026quot;, \u0026quot;#8A9B0F\u0026quot;, \u0026quot;#95C7D8\u0026quot;, \u0026quot;#FFBFF5\u0026quot;)) + facet_grid(drv ~ cyl) If you prefer to not facet particular rows or columns, you can just use a . instead of a variable name to imply the entire data set\nggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy, color = class), size = 2) + scale_color_manual(values = c(\u0026quot;#490A3D\u0026quot;, \u0026quot;#BD1550\u0026quot;, \u0026quot;#E97F02\u0026quot;, \u0026quot;#F8CA00\u0026quot;, \u0026quot;#8A9B0F\u0026quot;, \u0026quot;#95C7D8\u0026quot;, \u0026quot;#FFBFF5\u0026quot;)) + facet_grid(. ~ cyl) Part 4 Questions for You to Turn In What happens if you facet on a continuous variable?\n What do the empty cells in plot with facet_grid(drv ~ cyl) mean? How do they relate to this plot?\n  ggplot(data = mpg) + geom_point(mapping = aes(x = drv, y = cyl)) What plots does the following code make? What does . do?   Plot 1  ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy)) + facet_grid(drv ~ .)  Plot 2  ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy)) + facet_grid(. ~ cyl) Take the faceted plot below and compare it to the one with color you did earlier  ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy)) + facet_wrap(~ class, nrow = 2) What are the advantages to using faceting instead of the color aesthetic? What are the disadvantages? How might the balance change if you had a larger dataset?\nRead ?facet_wrap. What does nrow do? What does ncol do? What other options control the layout of the individual panels? Why doesn’t facet_grid() have nrow and ncol arguments (aka options)?\n When using facet_grid() you should usually put the variable with more unique levels in the columns. Why?\n     Take some time to change the values in the ggplot to see how it changes.↩︎\n I think↩︎\n but never say never!↩︎\n   ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"ac11eb4b300887ac6e4fc5c1906670ba","permalink":"https://edp693e.theoreticalphysed.com/example/05-example/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/example/05-example/","section":"example","summary":"Getting Prepped  First Things First! Set your Working Directory Download the script Read the Submission Directions Load Up Some Libraries  Part 1: More ggplotting  Finding variables Getting counts Example: Using R to Test Hypotheses  Hypothesis Exploring the Data   Part 2: Aesthetics Part 3: Grouping Part 4: Facets    .","tags":null,"title":"Making Copies","type":"docs"},{"authors":null,"categories":null,"content":"   Data Camp   Data Camp This week you have two modules to cover on Data Camp. In particular this are\n Reporting with R Markdown\n Introduction to Data Visualization with ggplot2\n  For more information about these, take a look at the tentative schedule.\n ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"aa54929a56a6d237dc8692bd2c9cd024","permalink":"https://edp693e.theoreticalphysed.com/lesson/05-lesson/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/lesson/05-lesson/","section":"lesson","summary":"Data Camp   Data Camp This week you have two modules to cover on Data Camp. In particular this are\n Reporting with R Markdown\n Introduction to Data Visualization with ggplot2","tags":null,"title":"Making Copies","type":"docs"},{"authors":null,"categories":null,"content":"    Getting Prepped  First Things First! Set your Working Directory Download the script Read the Submission Directions Load Up Some Libraries PART I: The Map  Country Level Data State Level Data County Level Data  PART II: The US Census  Gathering and Making Important Decisions (Optional) Scraping the Web using R  Getting the Data You Want PART III: Plotting     .hvr-sweep-to-left { display: inline-block; vertical-align: middle; -webkit-transform: perspective(1px) translateZ(0); transform: perspective(1px) translateZ(0); box-shadow: 0 0 1px rgba(0, 0, 0, 0); position: relative; -webkit-transition-property: color; transition-property: color; -webkit-transition-duration: 0.25s; transition-duration: 0.25s; } .hvr-sweep-to-left:before { content: \"\"; position: absolute; z-index: -1; top: 0; left: 0; right: 0; bottom: 0; background: #003277; -webkit-transform: scaleX(0); transform: scaleX(0); -webkit-transform-origin: 100% 50%; transform-origin: 100% 50%; -webkit-transition-property: transform; transition-property: transform; -webkit-transition-duration: 0.3s; transition-duration: 0.3s; -webkit-transition-timing-function: ease-out; transition-timing-function: ease-out; } .hvr-sweep-to-left:hover, .hvr-sweep-to-left:focus, .hvr-sweep-to-left:active { color: white; } .hvr-sweep-to-left:hover:before, .hvr-sweep-to-left:focus:before, .hvr-sweep-to-left:active:before { -webkit-transform: scaleX(1); transform: scaleX(1); } * { box-sizing: border-box; } .tabs { display: flex; flex-wrap: wrap; max-width: 700px; background: #efefef; box-shadow: 0 48px 80px -32px rgba(0,0,0,0.3); } .input { position: absolute; opacity: 0; } .label { width: 100%; padding: 20px 30px; background: #e5e5e5; cursor: pointer; font-weight: bold; font-size: 18px; color: #7f7f7f; transition: background 0.1s, color 0.1s; } .label:hover { background: #d8d8d8; } .label:active { background: #ccc; } .input:focus + .label { box-shadow: inset 0px 0px 0px 3px #2aa1c0; z-index: 1; } .input:checked + .label { background: #fff; color: #000; } @media (min-width: 600px) { .label { width: auto; } } .panel { display: none; padding: 20px 30px 30px; background: #fff; } @media (min-width: 600px) { .panel { order: 99; } } .input:checked + .label + .panel { display: block; }  Getting Prepped First Things First! Set your Working Directory Your working directory is simply where your script will look for anything it needs like external data sets. There are a few ways to go about doing this which we will cover. However for now, just do the following:\nOpen up a new script by going to File \u0026gt; New File \u0026gt; R Script. Save it in a preferably empty folder as whatever you want. Go to the menu bar and select Session \u0026gt; Set Working Directory \u0026gt; To Source File Location.   Download the script Copying and pasting syntax from a browser can cause problems. To avoid this issue, please download a script with all of the needed code presented in this walkthrough.\n Download the Script   Read the Submission Directions On a separate document (WORD or PDF), answer the questions in parts 1, 2, and 4. You may work alone of together in groups of up to three people and submit one task on eCampus by the end of class today.\n Load Up Some Libraries Please go ahead and download the libraries below you don’t have and load them up\nlibrary(ggmap) # Provides the ability to visualize spatial data library(maps) # Computes the areas of regions in a projected map library(mapdata) # Providing both larger and higher-resolution databases. library(rgdal) # Bindings for the Geospatial Data Abstraction Library # (https://www.gdal.org/) library(tidyverse) library(tools) # Core package for R and is worth noting library(viridis) Sys.setenv(CENSUS_KEY=\u0026quot;YOUR API KEY HERE\u0026quot;)  PART I: The Map Country Level Data Load some United States demographic data.\nusa \u0026lt;- map_data(\u0026quot;usa\u0026quot;) Before you look at it by running usa, Census data sets are typically huge for obvious reasons. Let’s see how big the file actually is.\ndim(usa) ## [1] 7243 6 With 43,458 entries, that’s pretty big! Maybe we shouldn’t load it up (even in View). Let’s instead just see the first and last six rows to get an idea of what it looks like to get an idea.\nhead(usa)  ## long lat group order region subregion ## 1 -101.4078 29.74224 1 1 main \u0026lt;NA\u0026gt; ## 2 -101.3906 29.74224 1 2 main \u0026lt;NA\u0026gt; ## 3 -101.3620 29.65056 1 3 main \u0026lt;NA\u0026gt; ## 4 -101.3505 29.63911 1 4 main \u0026lt;NA\u0026gt; ## 5 -101.3219 29.63338 1 5 main \u0026lt;NA\u0026gt; ## 6 -101.3047 29.64484 1 6 main \u0026lt;NA\u0026gt;  tail(usa)  ## long lat group order region subregion ## 7247 -122.6187 48.37482 10 7247 whidbey island \u0026lt;NA\u0026gt; ## 7248 -122.6359 48.35764 10 7248 whidbey island \u0026lt;NA\u0026gt; ## 7249 -122.6703 48.31180 10 7249 whidbey island \u0026lt;NA\u0026gt; ## 7250 -122.7218 48.23732 10 7250 whidbey island \u0026lt;NA\u0026gt; ## 7251 -122.7104 48.21440 10 7251 whidbey island \u0026lt;NA\u0026gt; ## 7252 -122.6703 48.17429 10 7252 whidbey island \u0026lt;NA\u0026gt; We have columns that can be used! The most obvious choice for map data is using the coordinates for longitude and latitude. So let’s plot using the longitudinal (long) and latitudinal (lat) columns.\nggplot() + geom_polygon(data = usa, aes(x=long, y = lat, group = group)) Well that looks terrible. So what’s happening here? In a nutshell, it’s plotting exactly how you would see the US if you flattened (aka projected) the coordinates from a sphere to a flat surface. Most maps account for this using a correction via an aspect ratio. In R, we use a command called coord_fixed\nggplot() + geom_polygon(data = usa, aes(x=long, y = lat, group = group)) + coord_fixed(1.3) # 1.3 is a decent standard estimate There we go. That looks better but of course its just a grey silhouette. Let’s first try adding some base color.\nggplot() + geom_polygon(data = usa, aes(x=long, y = lat, group = group), color = \u0026quot;#1b85b8\u0026quot;, fill = \u0026quot;#559e83\u0026quot;) + coord_fixed(1.3) Its looking better but something is missing. Hmmm….Oh I know. Its the “S” part of “USA” - To get that, we need to look at state level data.\n State Level Data We have two choices: we can either bring in a particular state or bring them all in and then filter later. Unless you specifically know which state you want, its a good rule of thumb to bring in all state level data.\nstate \u0026lt;- map_data(\u0026quot;state\u0026quot;) As a side note, if you know which state you want to look at, then just do the following. I’ll use California as an example.\nCalifornia \u0026lt;- map_data(\u0026quot;state\u0026quot;, region = \u0026quot;CA\u0026quot;) A good thing to note is that region = is a bit misleading. At first you may think that it is a state’s abbreviation but it is not. In fact, you can’t even use abbreviations in that field. For example, if we use the abbreviation for Kansas, you’ll get nonsense\nKansas \u0026lt;- map_data(\u0026quot;state\u0026quot;, region = \u0026quot;KS\u0026quot;) ## Error in map.poly(database, regions, exact, xlim, ylim, boundary, interior, : no recognized region names (Yes the output is going off the page and no I can’t do anything about it)\nThe command region = is actually a filter so you need to put as much information as you can to ensure that you only get the state you want. For example, let’s see what happens when I do the following\nMichigan \u0026lt;- map_data(\u0026quot;state\u0026quot;, region = \u0026quot;MI\u0026quot;) Well MI is certainly the standard abbreviation for Michigan but again, that is not what the command is doing. Other states have those letters:\nunique(Michigan$region) ## [1] \u0026quot;michigan\u0026quot; \u0026quot;minnesota\u0026quot; \u0026quot;mississippi\u0026quot; \u0026quot;missouri\u0026quot;  That is not what we wanted so please make sure you use the region filter correctly. In a worst case scenario or if you don’t mind the extra effort, just type in the name of the state.\nMichigan \u0026lt;- map_data(\u0026quot;state\u0026quot;, region = \u0026quot;Michigan\u0026quot;) unique(Michigan$region) ## [1] \u0026quot;michigan\u0026quot; That’s much better! OK back to mapping. I’m actually going to stick with Michigan. Notice here that I am using the entire state data set and filtering Michigan out with the command subset and the == (double equals sign).\nmi \u0026lt;- subset(state, region==\u0026quot;michigan\u0026quot;) For a basic plot, we do the following:\nggplot() + geom_polygon(data = mi, aes(x=long, y = lat, group = group)) + coord_fixed(1.3)  Michigan’s shape is pretty unique and that sure looks like it but the plot is pretty bland. Let’s give it some color and a legend.\nggplot() + geom_polygon(data = mi, aes(x=long, y = lat, group = group, fill=region)) + scale_fill_manual(values=c(\u0026quot;#6A0032\u0026quot;)) + coord_fixed(1.3) Not bad but we can get even more granular. Let’s look at county level data.\n County Level Data Much like before, we’re going to pull in all of the county level data,\ncounty \u0026lt;- map_data(\u0026quot;county\u0026quot;) then we’ll filter it for Michigan,\nmi_count \u0026lt;- subset(county, region==\u0026quot;michigan\u0026quot;)  and finally we’ll plot it.\nggplot() + geom_polygon(data = mi_count, aes(x=long, y = lat, group = group, fill=subregion), color = \u0026quot;#FFFFFF\u0026quot;) + scale_fill_viridis(discrete = TRUE, alpha=0.7, option=\u0026quot;inferno\u0026quot;) + theme_bw() + theme(plot.title = element_text(size = 26, color =\u0026quot;#105456\u0026quot;, vjust = -1), legend.position =\u0026quot;bottom\u0026quot;, legend.direction = \u0026#39;vertical\u0026#39;, # legend.key = element_rect(size = 1.5, color = NA), # legend.key.size = unit(0.1, \u0026#39;lines\u0026#39;), legend.text = element_text(size=15, color = \u0026quot;#59595B\u0026quot;), legend.title = element_blank(), legend.title.align = 0.5, legend.spacing.x = unit(0.5, \u0026quot;cm\u0026quot;), legend.spacing.y = unit(0.5, \u0026quot;cm\u0026quot;), # legend.box.margin = unit(c(0,0,0,0),\u0026quot;cm\u0026quot;), legend.background = element_rect(linetype = 0, size = 0.5, colour = 1), panel.background = element_blank(), axis.title.x = element_blank(), axis.title.y = element_blank(), axis.ticks = element_blank(), axis.text = element_blank(), panel.border = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank()) + # guides(color=FALSE) + coord_fixed(1.3) Your output may look a little different depending on your system settings.\nThat legend is taking up way too much space AND we don’t need the counties color coded by their names. Let’s get rid of it with guide = FALSE within scale_fill_viridis to get rid of that particular one or to turn all fill legends off, you can use guides(fill=FALSE) which is switch off in the plot above. In the example below, let’s try the one with guide = FALSE.\nggplot() + geom_polygon(data = mi_count, aes(x=long, y = lat, group = group, fill=subregion), color = \u0026quot;#FFFFFF\u0026quot;) + scale_fill_viridis(discrete = TRUE, alpha=0.7, option=\u0026quot;inferno\u0026quot;, guide = FALSE) + #HERE IT IS theme_bw() + theme(plot.title = element_text(size = 26, color =\u0026quot;#105456\u0026quot;, vjust = -1), legend.position =\u0026quot;bottom\u0026quot;, legend.direction = \u0026#39;vertical\u0026#39;, # legend.key = element_rect(size = 1.5, color = NA), # legend.key.size = unit(0.1, \u0026#39;lines\u0026#39;), legend.text = element_text(size=15, color = \u0026quot;#59595B\u0026quot;), legend.title = element_blank(), legend.title.align = 0.5, legend.spacing.x = unit(0.5, \u0026quot;cm\u0026quot;), legend.spacing.y = unit(0.5, \u0026quot;cm\u0026quot;), # legend.box.margin = unit(c(0,0,0,0),\u0026quot;cm\u0026quot;), legend.background = element_rect(linetype = 0, size = 0.5, colour = 1), panel.background = element_blank(), axis.title.x = element_blank(), axis.title.y = element_blank(), axis.ticks = element_blank(), axis.text = element_blank(), panel.border = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank()) + # guides(color=FALSE) + coord_fixed(1.3) Well now we definitely have county level data for Michigan. I would strongly advise you to take a moment to review and play around with every layer. Many of the typical things you would want to change or amend about a plot are included.\nOK now we should probably do something with this map. Let get some Census data.\n  PART II: The US Census Gathering and Making Important Decisions There are a few things you need to do when grabbing Census data.\nYou must have a key from https://api.census.gov/data/key_signup.html\n Load up (or install and then load up) the library censusapi\n  library(censusapi) ## ## Attaching package: \u0026#39;censusapi\u0026#39; ## The following object is masked from \u0026#39;package:methods\u0026#39;: ## ## getFunction Add key to the .Renviron (the place in the censusapi where your unique identifier, or key, is stored)  Sys.setenv(CENSUS_KEY=\u0026quot;YOUR UNIQUE IDENTIFIER HERE\u0026quot;) Reload the .Renviron  readRenviron(\u0026quot;~/.Renviron\u0026quot;) # You may get a warning...ignore it Check to see that your key stored within R  Sys.getenv(\u0026quot;CENSUS_KEY\u0026quot;) ## [1] \"YOUR UNIQUE IDENTIFIER HERE\"\nChoose an endpoint aka a set of data that you want.  At this point it is completely understandable if you are wondering what an API is. Without getting overtly technical, an API is the acronym for Application Programming Interface. This is essentially a text based software that allows two applications to talk to each other. Why text based? Well its really the only aspect that all computers share. In fact, each time you use an app like YouTube, send a text message, or check the weather on your phone, etc. from any device worldwide, you’re using an API. As an example, take a look at the Twitter API https://developer.twitter.com/en/docs/tweets/search/api-reference.html that we’ll be using later in the term to perform some network data visualizations.\nNow when looking at our endpoint, what should we choose? As of 2018, there are over 200 Census API endpoints are available, including the Decennial Census, American Community Survey, Poverty Statistics, and Population Estimates. You can find a list here: https://api.census.gov/data.html. Please look them over!\nThe censusapi package is designed to let you get data from all of those APIs using the same main function getCensus and the same syntax for each data set. In this example case, let’s look at the 2017 Density Estimates (variables can be found here: https://api.census.gov/data/2017/pep/population/variables.html) for all states within the US. Alternatively you can get that information directly through the API we have been using:\napis \u0026lt;- listCensusApis() View(apis) Now certain repositories require certain basic variables to be run (for example if years are a factor). To get an idea, the 2017 American Community Survey which is used to update some data within the primary Census.\n Here are the available variables  acs2017_vars \u0026lt;- listCensusMetadata(name = \u0026quot;2017/pep/population/\u0026quot;, type = \u0026quot;variables\u0026quot;) head(acs2017_vars) ## name label concept predicateType ## 1 MDIV Metropolitan Division code Selectable Geographies int ## 2 COUSUB Minor Civil Division FIPS code Estimates int ## 3 SUMLEV Summary Level Estimates \u0026lt;NA\u0026gt; ## 4 STATE State FIPS code Estimates \u0026lt;NA\u0026gt; ## 5 GEONAME Geographic Name Estimates \u0026lt;NA\u0026gt; ## 6 DATE_ Date Estimates int ## group limit required ## 1 N/A 0 \u0026lt;NA\u0026gt; ## 2 N/A 0 \u0026lt;NA\u0026gt; ## 3 N/A 0 \u0026lt;NA\u0026gt; ## 4 N/A 0 \u0026lt;NA\u0026gt; ## 5 N/A 0 \u0026lt;NA\u0026gt; ## 6 N/A 0 default displayed Here are the available geographies  acs2017_geos \u0026lt;- listCensusMetadata(name = \u0026quot;2017/pep/population/\u0026quot;, type = \u0026quot;geography\u0026quot;) View(acs2017_geos) If you want to see which variables are required for mapping, then there is a problem and that is actually due to bad luck as a result of timing. The Census is going through a new update with a new API format that was supposed to go live two weeks ago. It has, however, been pushed back to October 31. Until then, you will have to utilize the website. However if you are adamant about using R for the whole process as I typically am, then you can get table, aka tabular data from any website. If this interests you, please seethe section below. Otherwise move on to the next section.\n (Optional) Scraping the Web using R In order to grab data off of the web, you will need to several things. At first it may seem arduous but having lengthy tables as data within R can be very beneficial, especially when filtering or if you just don’t want to manually load or type in entries. Included are steps to get the data you need in a usable form within R.\nDownload and run the rvest package (though there are others like a package called XML that may be useful in other circumstances)  library(rvest) ## Loading required package: xml2 ## ## Attaching package: \u0026#39;rvest\u0026#39; ## The following object is masked from \u0026#39;package:purrr\u0026#39;: ## ## pluck ## The following object is masked from \u0026#39;package:readr\u0026#39;: ## ## guess_encoding Define the website you want to pull the data from  webpage \u0026lt;- read_html(\u0026quot;https://api.census.gov/data/2017/pep/population/variables.html\u0026quot;) Tell rvest that you want the tables using the command html_nodes. This does a lot of things but in a nutshell, it recognizes if a page is a webpage by scanning the HTML code and then finds what you need. In our case, we’re asking it to recognize the Census webpage from above and to identify the HTML codes where the term table exists.  tbls \u0026lt;- html_nodes(webpage, \u0026quot;table\u0026quot;)  See information regarding all of the tables  tbls # or if there are multiple tables, consider using head(tbls) ## {xml_nodeset (1)} ## [1] \u0026lt;table\u0026gt;\\n\u0026lt;caption\u0026gt;Census Data API: Variables in /data/2017/pep/population ... By the output, we only have one table which is indicated by [1].\nNow do some piping via dplyr to get a list of everything within that table  tbls_ls \u0026lt;- webpage %\u0026gt;% html_nodes(\u0026quot;table\u0026quot;) %\u0026gt;% # Creates a multidimensional list (i.e. a list # with layers and depth akin to folders within # folders within folders, ect.) .[1] %\u0026gt;% # We only have table so we put.[1] here. If we had multiple # tables and we wanted say the first three, we could have # used .[1:3] html_table(fill = TRUE) # Convert the data to a table format and populate # the entries See the result  View(tbls_ls) Notice that its a list and can go pretty deep down the rabbit hole depending on how many tables you are looking at. In this case, we have one so ts pretty simple.\nNow narrow down the results. Say you only wanted the ones that were required. You can figure that out by filtering for the term default displayed under the column Required. To do this, we first run the following which splits up all of the tables and then attaches them together by corresponding entries.  tbls_ls \u0026lt;- do.call(rbind.data.frame, tbls_ls) # Concatenates a list of data frames # into a single data frame (Optional) Take a look to see that it looks like an actual table  View(tbls_ls) Now we get rid of the rows that that don’t have default displayed under Required  filtered_tbls_ls \u0026lt;- tbls_ls[tbls_ls$Required == \u0026quot;default displayed\u0026quot;, ] # Filter out the rows that # don\u0026#39;t have `default # displayed` under the # column **Required** Just show the names of the required variables  filtered_tbls_ls$Name # Just shows the Names of the required variables ## [1] \u0026quot;DATE_\u0026quot; \u0026quot;UNIVERSE\u0026quot; So here we see that the variables DATE and UNIVERSE are required.\n Alternatively and if you understand the above, you can simply use the following in one fell swoop using dplyr:\nlibrary(rvest) read_html(\u0026quot;https://api.census.gov/data/2017/pep/population/variables.html\u0026quot;) %\u0026gt;% html_nodes(\u0026quot;table\u0026quot;) %\u0026gt;% # Creates a multidimensional list (i.e. a list with layers # and depth akin to folders within folders within folders, # ect.) .[1] %\u0026gt;% # We only have table so we put.[1] here. If we had multiple tables and # we wanted say the first three, we could have used .[1:3] html_table(fill = TRUE) %\u0026gt;% # Convert the data to a table format and populate the # entries bind_rows() %\u0026gt;% # Concatenates a list of data frames into a single data frame filter(Required == \u0026quot;default displayed\u0026quot;) %\u0026gt;% # Filter out the rows that don\u0026#39;t have # `default displayed` under the column # **Required** select(Name) # Just shows the Names of the required variables ## New names: ## * NA -\u0026gt; ...9 ## Name ## 1 DATE_ ## 2 UNIVERSE Life is much easier with pipes! Note that this and the other method should work with many of the Census web tables but may not for all, especially for older tables that may have not been updated and do not have the column Required. Part of understanding what is going on in each line affords you the ability to change commands and variables as necessary.\nOK now back to the mapping!\n  Getting the Data You Want Backtracking on the two methods presented above, if we wanted to figure out which variables are available in general, we could\n Go back to step 9 and run  tbls_ls$Name ## [1] \u0026quot;23 variables\u0026quot; \u0026quot;CBSA\u0026quot; \u0026quot;CONCIT\u0026quot; \u0026quot;COUNTY\u0026quot; \u0026quot;COUSUB\u0026quot; ## [6] \u0026quot;CSA\u0026quot; \u0026quot;DATE_\u0026quot; \u0026quot;DATE_DESC\u0026quot; \u0026quot;DENSITY\u0026quot; \u0026quot;DIVISION\u0026quot; ## [11] \u0026quot;for\u0026quot; \u0026quot;FUNCSTAT\u0026quot; \u0026quot;GEONAME\u0026quot; \u0026quot;in\u0026quot; \u0026quot;LASTUPDATE\u0026quot; ## [16] \u0026quot;MDIV\u0026quot; \u0026quot;NATION\u0026quot; \u0026quot;PLACE\u0026quot; \u0026quot;POP\u0026quot; \u0026quot;PRIMGEOFLAG\u0026quot; ## [21] \u0026quot;REGION\u0026quot; \u0026quot;STATE\u0026quot; \u0026quot;SUMLEV\u0026quot; \u0026quot;UNIVERSE\u0026quot; OR\n Rerun parts of the piping system  read_html(\u0026quot;https://api.census.gov/data/2017/pep/population/variables.html\u0026quot;) %\u0026gt;% html_nodes(\u0026quot;table\u0026quot;) %\u0026gt;% # This is a multidimensional list (i.e. a list with layers) .[1] %\u0026gt;% html_table(fill = TRUE) %\u0026gt;% bind_rows() %\u0026gt;% select(Name) ## New names: ## * NA -\u0026gt; ...9 ## Name ## 1 23 variables ## 2 CBSA ## 3 CONCIT ## 4 COUNTY ## 5 COUSUB ## 6 CSA ## 7 DATE_ ## 8 DATE_DESC ## 9 DENSITY ## 10 DIVISION ## 11 for ## 12 FUNCSTAT ## 13 GEONAME ## 14 in ## 15 LASTUPDATE ## 16 MDIV ## 17 NATION ## 18 PLACE ## 19 POP ## 20 PRIMGEOFLAG ## 21 REGION ## 22 STATE ## 23 SUMLEV ## 24 UNIVERSE Alternative if you are pretty sure that a variable is already in a Census table and want verification, you cab check for it. For example, let’s see if the variable DENSITY exists in the 2017 Density Estimates (I bet it does since the word Density is right in the title) for the state of Michigan.\ngetCensus(name = \u0026quot;2017/pep/population\u0026quot;, vars = c(\u0026quot;DENSITY\u0026quot;), region = \u0026quot;state:26\u0026quot;) ## state DENSITY ## 1 26 176.139 Yup its available but right now you may be wondering how I got that number 26. Well the Census assigns a number (called a FIPS state code) to every territory the US controls. You can find grouped listings here https://www.census.gov/geo/reference/ansi_statetables.html.\nWell let’s get county and state level data and run it!\nTigers \u0026lt;- getCensus(name = \u0026quot;2017/pep/population\u0026quot;, vars = c(\u0026quot;GEONAME\u0026quot;, \u0026quot;COUNTY\u0026quot;, \u0026quot;DENSITY\u0026quot;), region = \u0026quot;county:*\u0026quot;, regionin = \u0026quot;state:26\u0026quot;)  Now take a peek at the first 15 entries in the Michigan list.\nhead(Tigers, n=15L) ## state county GEONAME COUNTY DENSITY ## 1 26 073 Isabella County, Michigan 073 124.088901 ## 2 26 075 Jackson County, Michigan 075 226.080702 ## 3 26 077 Kalamazoo County, Michigan 077 467.780995 ## 4 26 079 Kalkaska County, Michigan 079 31.504614 ## 5 26 081 Kent County, Michigan 081 765.161412 ## 6 26 083 Keweenaw County, Michigan 083 3.897341 ## 7 26 085 Lake County, Michigan 085 21.165346 ## 8 26 087 Lapeer County, Michigan 087 136.875440 ## 9 26 089 Leelanau County, Michigan 089 62.378722 ## 10 26 091 Lenawee County, Michigan 091 131.575529 ## 11 26 093 Livingston County, Michigan 093 335.585145 ## 12 26 095 Luce County, Michigan 095 7.071703 ## 13 26 097 Mackinac County, Michigan 097 10.482856 ## 14 26 099 Macomb County, Michigan 099 1818.397780 ## 15 26 101 Manistee County, Michigan 101 45.041218 Notice that we can get rid of the columns state, county, and COUNTY since we only need the columns GEOMNAME and DENSITY. We can do this by running the following\ndrops \u0026lt;- c(\u0026quot;state\u0026quot;, \u0026quot;county\u0026quot;, \u0026quot;COUNTY\u0026quot;) # Assigns column names to be dropped Tigers \u0026lt;- Tigers[ , !(names(Tigers) %in% drops)] # Drops those columns Now let’s take a look at the Census data set now.\nhead(Tigers) ## GEONAME DENSITY ## 1 Isabella County, Michigan 124.088901 ## 2 Jackson County, Michigan 226.080702 ## 3 Kalamazoo County, Michigan 467.780995 ## 4 Kalkaska County, Michigan 31.504614 ## 5 Kent County, Michigan 765.161412 ## 6 Keweenaw County, Michigan 3.897341 Recall that our map data looks like this\nhead(mi_count) ## long lat group order region subregion ## 38512 -83.88675 44.85686 1198 38512 michigan alcona ## 38513 -83.36536 44.86832 1198 38513 michigan alcona ## 38514 -83.33098 44.83968 1198 38514 michigan alcona ## 38515 -83.30806 44.80530 1198 38515 michigan alcona ## 38516 -83.30233 44.77665 1198 38516 michigan alcona ## 38517 -83.28515 44.72509 1198 38517 michigan alcona We have to merge both of these sets so that the Census data and map data line up. We have a bit of work to do but its all about identifying what we need. Now I should note that the process below is just one way to get there. Steps are provided for convenience but again they are contingent on your own table.\n. The column GEONAME is a concatenation of county and state level data. Let’s split them up using the , (comma) as the delimiter…\nTigers \u0026lt;- Tigers %\u0026gt;% separate(GEONAME, into = paste0(\u0026#39;thing\u0026#39;, 1:2), sep = \u0026#39;[,]\u0026#39;) …and then take a look at the results.\nhead(Tigers) ## thing1 thing2 DENSITY ## 1 Isabella County Michigan 124.088901 ## 2 Jackson County Michigan 226.080702 ## 3 Kalamazoo County Michigan 467.780995 ## 4 Kalkaska County Michigan 31.504614 ## 5 Kent County Michigan 765.161412 ## 6 Keweenaw County Michigan 3.897341 Notice that the columns have been split and renamed thing1 and thing2. But we want the column names to be representative of what they are. So we can rename them in order of appearance from left to right  Tigers \u0026lt;- setNames(Tigers, c(\u0026quot;County\u0026quot;,\u0026quot;State\u0026quot;,\u0026quot;Density\u0026quot;))  …and then take a look at the results.\nhead(Tigers) ## County State Density ## 1 Isabella County Michigan 124.088901 ## 2 Jackson County Michigan 226.080702 ## 3 Kalamazoo County Michigan 467.780995 ## 4 Kalkaska County Michigan 31.504614 ## 5 Kent County Michigan 765.161412 ## 6 Keweenaw County Michigan 3.897341 Now notice that the term County appears perpetually with the County columns and does not appear in the mi_count set. So we have a choice in that we can either leave it be here and add the term County to mi_count or drop the term from this set. I like to have less clutter so choosing the latter makes sense. However, you could just as well do the other and the intended outcome that columns look the same would work all the same.\nNow there are many ways to attack this. Similar to the process above, you could just split the column again based on the space and then delete one of the resulting columns with the term County in it. However, since you have already been exposed to the stringr package, let’s use that.  Tigers$County \u0026lt;- str_replace_all(Tigers$County, \u0026quot; County\u0026quot;, \u0026quot;\u0026quot;) # Find the term County in the County column and replace it nothing (given by \u0026quot;\u0026quot;). Notice # that there is a space between the first quote and the term County to account for the # space between the two words. Finally we certainly know that we’re in Michigan so let’s get rid of that column  dropFromCensus \u0026lt;- c(\u0026quot;State\u0026quot;) Tigers \u0026lt;- Tigers[ , !(names(Tigers) %in% dropFromCensus)] # Drops those columns . OK we are done with the Census data for now. Moving on the map data, lets compare both again\nhead(Tigers) ## County Density ## 1 Isabella 124.088901 ## 2 Jackson 226.080702 ## 3 Kalamazoo 467.780995 ## 4 Kalkaska 31.504614 ## 5 Kent 765.161412 ## 6 Keweenaw 3.897341 head(mi_count) ## long lat group order region subregion ## 38512 -83.88675 44.85686 1198 38512 michigan alcona ## 38513 -83.36536 44.86832 1198 38513 michigan alcona ## 38514 -83.33098 44.83968 1198 38514 michigan alcona ## 38515 -83.30806 44.80530 1198 38515 michigan alcona ## 38516 -83.30233 44.77665 1198 38516 michigan alcona ## 38517 -83.28515 44.72509 1198 38517 michigan alcona First thing here and because of personal preference, I want to get rid of the clutter. In this case, that means dropping columns we do not need. In this case, these are group, order, and region. Now the code down here is a bit tricky if you are not used to it. In the first line, we are just defining a column vector with column names so there’s nothing new here. The second line needs a bit more explanation because there is a lot going on. Foremost, the rows and columns for all data frames can be called using [row,column]. For example, I can tell R that I want to do something to the rows in mi_count by stating mi_count[some operation here , ]. Alternatively, I can also tell R that I want to do something to the columns in mi_count by stating mi_count[ , some operation here ] which is exactly what was done. I realize that may be confusing so think about it and ask questions. Now for the operation itself, we read those in parts:\n names(mi_count) tells R the to look at the names of the columns in mi_count.\n names(mi_count) %in% dropFromMapData tells R to take the names of the columns in mi_count and look for them in the vector dropFromMapData.\n !(names(mi_count) %in% dropFromMapData) tells R to take those names from dropFromMapData that are also in mi_count and to not use them (aka to drop them).\n  dropFromMapData \u0026lt;- c(\u0026quot;group\u0026quot;, \u0026quot;order\u0026quot;, \u0026quot;region\u0026quot;) mi_count \u0026lt;- mi_count[ , !(names(mi_count) %in% dropFromMapData)] # Drops those columns head(mi_count) ## long lat subregion ## 38512 -83.88675 44.85686 alcona ## 38513 -83.36536 44.86832 alcona ## 38514 -83.33098 44.83968 alcona ## 38515 -83.30806 44.80530 alcona ## 38516 -83.30233 44.77665 alcona ## 38517 -83.28515 44.72509 alcona Looking at the code as whole is often overwhelming. Remember you are learning a new language so first view its most basic parts and then build up.\n. Then rename the column we’re going to merge one which in this case means renaming subregion to County while maintaining the others as is.\nmi_count \u0026lt;- setNames(mi_count, c(\u0026quot;long\u0026quot;,\u0026quot;lat\u0026quot;,\u0026quot;County\u0026quot;))  …and take a look.\nhead(mi_count) ## long lat County ## 38512 -83.88675 44.85686 alcona ## 38513 -83.36536 44.86832 alcona ## 38514 -83.33098 44.83968 alcona ## 38515 -83.30806 44.80530 alcona ## 38516 -83.30233 44.77665 alcona ## 38517 -83.28515 44.72509 alcona And finally, let’s capitalize the column county.  mi_count$County \u0026lt;- str_to_title(mi_count$County) …and take a look.\nhead(mi_count) ## long lat County ## 38512 -83.88675 44.85686 Alcona ## 38513 -83.36536 44.86832 Alcona ## 38514 -83.33098 44.83968 Alcona ## 38515 -83.30806 44.80530 Alcona ## 38516 -83.30233 44.77665 Alcona ## 38517 -83.28515 44.72509 Alcona In fact, let’s look it both to make sure they’re structurally similar\nhead(Tigers) ## County Density ## 1 Isabella 124.088901 ## 2 Jackson 226.080702 ## 3 Kalamazoo 467.780995 ## 4 Kalkaska 31.504614 ## 5 Kent 765.161412 ## 6 Keweenaw 3.897341 head(mi_count) ## long lat County ## 38512 -83.88675 44.85686 Alcona ## 38513 -83.36536 44.86832 Alcona ## 38514 -83.33098 44.83968 Alcona ## 38515 -83.30806 44.80530 Alcona ## 38516 -83.30233 44.77665 Alcona ## 38517 -83.28515 44.72509 Alcona Yes! Now you might be thinking that mi_count is full of repeated county names. Well that’s good because (1) its the file that will inform ggplot of county borders and (2) we simply need the terms and column titles to look the same; they can differ in length (aka number of rows or how many times any entry repeats).\nWe’re going to use joins which is basically a fancy way of using logic derived from a computer language called SQL. Take a look at the data-wrangling-cheatsheet PDF file or go to http://stat545.com/bit001_dplyr-cheatsheet.html to see detailed examples.\nIn each situation, you have to think about the end product and the data set that will get you there. Foremost, we want a county map of Michigan with Census density data. Which one is more important? Well logic would dictate that I can’t really draw density data without a map, or in research (and Algebraic) terms, density data is dependent on the map. So with that idea, we need the map data (from mi_count) as our primary source to merge on. The command left_join will work here as long as mi_count is literally to the left of the other data set: Tigers. Below you can see this and also that we’re merging, or joining on the common column County.\ntotal_thing \u0026lt;- left_join(mi_count, Tigers, by = c(\u0026quot;County\u0026quot;)) …and take a look.\nhead(mi_count) ## long lat County ## 38512 -83.88675 44.85686 Alcona ## 38513 -83.36536 44.86832 Alcona ## 38514 -83.33098 44.83968 Alcona ## 38515 -83.30806 44.80530 Alcona ## 38516 -83.30233 44.77665 Alcona ## 38517 -83.28515 44.72509 Alcona Nice! it worked! Now let’s try to plot it.\n PART III: Plotting Well let’s give it a go!\nggplot() + geom_polygon(data = total_thing, aes(x=long, y = lat, fill=Density, group=County), color = \u0026quot;#f8f8fa\u0026quot;, size = 0.25, show.legend = T) + scale_color_viridis(alpha=1, option=\u0026quot;viridis\u0026quot;) + # color tells R to look for discrete data to color theme_bw() + theme(plot.title = element_text(size = 26,color =\u0026quot;#105456\u0026quot;, vjust = -1), legend.position =\u0026quot;right\u0026quot;, legend.direction = \u0026#39;vertical\u0026#39;, legend.key = element_rect(size = 5, color = NA), legend.key.size = unit(1.5, \u0026#39;lines\u0026#39;), legend.text = element_text(size=15, color = \u0026quot;#59595B\u0026quot;), legend.title = element_blank(), legend.title.align = 0.5, legend.spacing.x = unit(0.5, \u0026quot;cm\u0026quot;), legend.spacing.y = unit(0.5, \u0026quot;cm\u0026quot;), # legend.box.margin = unit(c(0,0,0,0),\u0026quot;cm\u0026quot;), legend.background = element_rect(linetype = 0, size = 0.5, colour = 1), panel.background = element_blank(), axis.title.x = element_blank(), axis.title.y = element_blank(), axis.ticks = element_blank(), axis.text = element_blank(), panel.border = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank()) + coord_fixed(1.3) Clearly there’s a problem here. It looks like R is plotting the densities individually which means its treating the data as discrete. We don’t want this! Population data or any derivation thereof are typically given in ranges due to the massive variability in measures. This type of data is called continuous. So in this case, we need to change the form of the current data set from discrete to continuous. To do that, we must convert them to characters and then to generic numbers. While this sounds silly, R is not capable of this conversion directly (or it is possible that I am not aware of how to do it directly and would absolutely love to be proven wrong!)\ntotal_thing$Density \u0026lt;- as.numeric(as.character(total_thing$Density))  OK so let’s try again:\nggplot() + geom_polygon(data = total_thing, aes(x=long, y = lat, fill=Density, group=County), color = \u0026quot;#f8f8fa\u0026quot;, size = 0.25, show.legend = T) + scale_fill_viridis(alpha=1, option=\u0026quot;viridis\u0026quot;) + # fill tells R to look for continuous data to color theme_bw() + theme(plot.title = element_text(size = 26,color =\u0026quot;#105456\u0026quot;, vjust = -1), legend.position =\u0026quot;right\u0026quot;, legend.direction = \u0026#39;vertical\u0026#39;, legend.key = element_rect(size = 5, color = NA), legend.key.size = unit(1.5, \u0026#39;lines\u0026#39;), legend.text = element_text(size=15, color = \u0026quot;#59595B\u0026quot;), legend.title = element_blank(), legend.title.align = 0.5, legend.spacing.x = unit(0.5, \u0026quot;cm\u0026quot;), legend.spacing.y = unit(0.5, \u0026quot;cm\u0026quot;), # legend.box.margin = unit(c(0,0,0,0),\u0026quot;cm\u0026quot;), legend.background = element_rect(linetype = 0, size = 0.5, colour = 1), panel.background = element_blank(), axis.title.x = element_blank(), axis.title.y = element_blank(), axis.ticks = element_blank(), axis.text = element_blank(), panel.border = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank()) + coord_fixed(1.3) And we’ve got it! Was that a pain? Certainly! But you also have a powerful tool to grab a lot of demographic data and the knowledge to play and tweak aspects to fit other needs. In fact, some repositories only have their data within an API. If you are interested in pulling data from other government sites via APIs or otherwise, take a look at a running list here: https://catalog.data.gov/dataset\n  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"a66b8951081722f5755747f3314e83f0","permalink":"https://edp693e.theoreticalphysed.com/example/06-example/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/example/06-example/","section":"example","summary":"Getting Prepped  First Things First! Set your Working Directory Download the script Read the Submission Directions Load Up Some Libraries PART I: The Map  Country Level Data State Level Data County Level Data  PART II: The US Census  Gathering and Making Important Decisions (Optional) Scraping the Web using R  Getting the Data You Want PART III: Plotting     .","tags":null,"title":"Mapping","type":"docs"},{"authors":null,"categories":null,"content":"  There are a ton of places to find data related to whatever you want. The ones below are some of the more larger repositories:\n Data World: A plethora of open data sets to peruse. If you are a data fiend, consider collaborating to solve problems.\n Data is Plural newsletter: Jeremy Singer-Vine sends a weekly newsletter of the most interesting public datasets he’s found. You should subscribe to it. He also has an archive of all the datasets he’s highlighted.\n Google Dataset Search: Google indexes thousands of public datasets; search for them here.\n Kaggle: Kaggle hosts machine learning competitions where people compete to create the fastest, most efficient, most predictive algorithms. A byproduct of these competitions is a host of fascinating datasets that are generally free and open to the public.\n US City Open Data Census: More than 100 US cities have committed to sharing dozens of types of data, including data about crime, budgets, campaign finance, lobbying, transit, and zoning. This site from the Sunlight Foundation and Code for America collects this data and rates cities by how well they’re doing.\n  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"2210aa8aeb5724b04bdf63d813d61030","permalink":"https://edp693e.theoreticalphysed.com/resource/data/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/resource/data/","section":"resource","summary":"There are a ton of places to find data related to whatever you want. The ones below are some of the more larger repositories:\n Data World: A plethora of open data sets to peruse.","tags":null,"title":"Data","type":"docs"},{"authors":null,"categories":null,"content":"   Accessibility Colors Fonts Graphic assets  Images Vectors Vectors, photos, videos, and other assets    Accessibility  Color Oracle: Simulate how your images look for people with different forms of colorblindness (desktop-based, more types of colorblindness) Vischeck: Simulate how your images look for people with different forms of colorblindness (web-based)   Colors  Adobe Color: Create, share, and explore rule-based and custom color palettes. ColorBrewer: Sequential, diverging, and qualitative color palettes that take accessibility into account. Colorgorical: Create color palettes based on fancy mathematical rules for perceptual distance. Color Hex Color Codes: A collection of colors and palettes given only by hex identifiers. Colorpicker for data: More fancy mathematical rules for color palettes (explanation). ColourLovers: Like Facebook for color palettes. Comprehensive list of color palettes in r: A wided ranging collection of various palettes from the entire R community. These can now all be downloaded within a the package paleteer by running install.packages(\"paletteer\"). More information can be found here. iWantHue: Yet another perceptual distance-based color palette builder. Photochrome: Word-based color palettes. PolicyViz Design Color Tools: Large collection of useful color resources Scientific Colour-Maps: Perceptually uniform color scales like viridis. Use them in R with scico. viridis: Perceptually uniform color scales. Wes Anderson Palettes: Palettes based off of Wes Anderson films and also one of my personal favorite sites to choose colors.   Fonts  Google Fonts: Huge collection of free, well-made fonts. The Ultimate Collection of Google Font Pairings: A list of great, well-designed font pairings from all those fonts hosted by Google (for when you’re looking for good contrasting or complementary fonts).   Graphic assets Images  Burst freephotos.cc Pexels Pixabay StockSnap.io Unsplash Use the Creative Commons filters on Google Images or Flickr   Vectors  aiconica: 1,000+ vector icons Noun Project: Thousands of free simple vector images Vecteezy: Thousands of free vector images   Vectors, photos, videos, and other assets  Stockio    ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"16fd04c4714e3d096bffcf19e6c524ca","permalink":"https://edp693e.theoreticalphysed.com/resource/design/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/resource/design/","section":"resource","summary":"Accessibility Colors Fonts Graphic assets  Images Vectors Vectors, photos, videos, and other assets    Accessibility  Color Oracle: Simulate how your images look for people with different forms of colorblindness (desktop-based, more types of colorblindness) Vischeck: Simulate how your images look for people with different forms of colorblindness (web-based)   Colors  Adobe Color: Create, share, and explore rule-based and custom color palettes.","tags":null,"title":"Design","type":"docs"},{"authors":null,"categories":null,"content":"   RStudio.cloud RStudio on your computer  Install R Install RStudio Install tidyverse    You will do all of your work in this class with the open source (and free!) programming language R. You will use RStudio as the main program to access R. Think of R as an engine and RStudio as a car dashboard—R handles all the calculations and the actual statistics, while RStudio provides a nice interface for running R code.\nRStudio.cloud R is free, but it can sometimes be a pain to install and configure. To make life easier, you can (and should!) use the free RStudio.cloud service initially, which lets you run a full instance of RStudio in your web browser. This means you won’t have to install anything on your computer to get started with R! We will have a shared class workspace in RStudio.cloud that will let you quickly copy templates for labs and problem sets.\nGo to https://rstudio.cloud/ and create an account. You’ll receive a link to join the shared class workspace separately. If you don’t get this link, let me know and I will invite you.\n RStudio on your computer RStudio.cloud is convenient, but it can be slow and it is not designed to be able to handle larger datasets, more complicated analysis, or fancier graphics. Over the course of the semester, you should wean yourself off of RStudio.cloud and install all these things locally. This is also important if you want to customize fonts, since RStudio.cloud has extremely limited support for fonts other than Helvetica.\nHere’s how you install all these things\nInstall R First you need to install R itself (the engine).\nGo to the CRAN (Collective R Archive Network)1 website: https://cran.r-project.org/\n Click on “Download R for XXX”, where XXX is either Mac or Windows:\n If you use macOS, scroll down to the first .pkg file in the list of files (as of this writing, it’s R-4.0.0.pkg; as of right now but download the most current version.\n If you use Windows, click “base” (or click on the bolded “install R for the first time” link) and download it.\n  Double click on the downloaded file (check your Downloads folder). Click yes through all the prompts to install like any other program.\n If you use macOS, download and install XQuartz. You do not need to do this on Windows.\n   Install RStudio Next, you need to install RStudio, the nicer graphical user interface (GUI) for R (the dashboard). Once R and RStudio are both installed, you can ignore R and only use RStudio. RStudio will use R automatically and you won’t ever have to interact with it directly.\nGo to the free download location on RStudio’s website: https://www.rstudio.com/products/rstudio/download/#download\n The website should automatically detect your operating system (macOS or Windows) and show a big download button for it:\nIf not, scroll down a little to the large table and choose the version of RStudio that matches your operating system.\n Double click on the downloaded file (again, check your Downloads folder). Click yes through all the prompts to install like any other program.\n  Double click on RStudio to run it (check your applications folder or start menu).\n Install tidyverse R packages are easy to install with RStudio. Select the packages panel, click on “Install,” type the name of the package you want to install, and press enter.\nThis can sometimes be tedious when you’re installing lots of packages, though. The tidyverse, for instance, consists of dozens of packages (including ggplot2) that all work together. Rather than install each individually, you can install a single magical package and get them all at the same time.\nGo to the packages panel in RStudio, click on “Install,” type “tidyverse”, and press enter. You’ll see a bunch of output in the RStudio console as all the tidyverse packages are installed.\nNotice also that RStudio will generate a line of code for you and run it: install.packages(\"tidyverse\"). You can also just paste and run this instead of using the packages panel.\n   It’s a goofy name, but CRAN is where most R packages—and R itself—lives.↩︎\n   ","date":1594771200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1594771200,"objectID":"efb59c0882a965443ffcbafa3cd27ca6","permalink":"https://edp693e.theoreticalphysed.com/resource/install/","publishdate":"2020-07-15T00:00:00Z","relpermalink":"/resource/install/","section":"resource","summary":"RStudio.cloud RStudio on your computer  Install R Install RStudio Install tidyverse    You will do all of your work in this class with the open source (and free!","tags":null,"title":"Installing R, RStudio, and tidyverse","type":"docs"},{"authors":null,"categories":null,"content":"   Basic Markdown formatting Math Tables Footnotes Front matter Citations Other references   Markdown is a special kind of markup language that lets you format text with simple syntax. You can then use a converter program like pandoc to convert Markdown into whatever format you want: HTML, PDF, Word, PowerPoint, etc. (see the full list of output types here)\nBasic Markdown formatting     Type… …or… …to get    Some text in a paragraph. More text in the next paragraph. Always use empty lines between paragraphs.  Some text in a paragraph.\nMore text in the next paragraph. Always use empty lines between paragraphs.\n  *Italic* _Italic_ Italic  **Bold** __Bold__ Bold  # Heading 1  Heading 1   ## Heading 2  Heading 2   ### Heading 3  Heading 3   (Go up to heading level 6 with ######)    [Link text](http://www.example.com)  Link text  ![Image caption](/path/to/image.png)    `Inline code` with backticks  Inline code with backticks  \u0026gt; Blockquote   Blockquote\n  - Things in - an unordered - list * Things in * an unordered * list  Things in an unordered list   1. Things in 2. an ordered 3. list 1) Things in 2) an ordered 3) list Things in an ordered list   Horizontal line --- Horizontal line *** Horizontal line\n     Math Markdown uses LaTeX to create fancy mathematical equations. There are like a billion little options and features available for math equations—you can find helpful examples of the the most common basic commands here.\nYou can use math in two different ways: inline or in a display block. To use math inline, wrap it in single dollar signs, like $y = mx + b$:\n    Type… …to get    Based on the DAG, the regression model for estimating the effect of education on wages is $\\hat{y} = \\beta_0 + \\beta_1 x_1 + \\epsilon$, or $\\text{Wages} = \\beta_0 + \\beta_1 \\text{Education} + \\epsilon$. Based on the DAG, the regression model for estimating the effect of education on wages is \\(\\hat{y} = \\beta_0 + \\beta_1 x_1 + \\epsilon\\), or \\(\\text{Wages} = \\beta_0 + \\beta_1 \\text{Education} + \\epsilon\\).    To put an equation on its own line in a display block, wrap it in double dollar signs, like this:\nType…\nThe quadratic equation was an important part of high school math: $$ x = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a} $$ But now we just use computers to solve for $x$. …to get…\n The quadratic equation was an important part of high school math:\n\\[ x = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a} \\]\nBut now we just use computers to solve for \\(x\\).\n Because dollar signs are used to indicate math equations, you can’t just use dollar signs like normal if you’re writing about actual dollars. For instance, if you write This book costs $5.75 and this other costs $40, Markdown will treat everything that comes between the dollar signs as math, like so: “This book costs $5.75 and this other costs $40”.\nTo get around that, put a backslash (\\) in front of the dollar signs, so that This book costs \\$5.75 and this other costs \\$40 becomes “This book costs $5.75 and this other costs $40”.\n Tables There are 4 different ways to hand-create tables in Markdown—I say “hand-create” because it’s normally way easier to use R to generate these things with packages like pander (use pandoc.table()) or knitr (use kable()). The two most common are simple tables and pipe tables. You should look at the full documentation here.\nFor simple tables, type…\n Right Left Center Default ------- ------ ---------- ------- 12 12 12 12 123 123 123 123 1 1 1 1 Table: Caption goes here …to get…\n Caption goes here  Right Left Center Default    12 12 12 12  123 123 123 123  1 1 1 1    For pipe tables, type…\n| Right | Left | Default | Center | |------:|:-----|---------|:------:| | 12 | 12 | 12 | 12 | | 123 | 123 | 123 | 123 | | 1 | 1 | 1 | 1 | Table: Caption goes here …to get…\n Caption goes here  Right Left Default Center    12 12 12 12  123 123 123 123  1 1 1 1     Footnotes There are two different ways to add footnotes (see here for complete documentation): regular and inline.\nRegular notes need (1) an identifier and (2) the actual note. The identifier can be whatever you want. Some people like to use numbers like [^1], but if you ever rearrange paragraphs or add notes before #1, the numbering will be wrong (in your Markdown file, not in the output; everything will be correct in the output). Because of that, I prefer to use some sort of text label:\nType…\nHere is a footnote reference[^1] and here is another [^note-on-dags]. [^1]: This is a note. [^note-on-dags]: DAGs are neat. And here\u0026#39;s more of the document. …to get…\n Here is a footnote reference1 and here is another.2\nAnd here’s more of the document.\n  This is a note.↩︎   DAGs are neat.↩︎     You can also use inline footnotes with ^[Text of the note goes here], which are often easier because you don’t need to worry about identifiers:\nType…\nCausal inference is neat.^[But it can be hard too!] …to get…\n Causal inference is neat.1\n  But it can be hard too!↩︎      Front matter You can include a special section at the top of a Markdown document that contains metadata (or data about your document) like the title, date, author, etc. This section uses a special simple syntax named YAML (or “YAML Ain’t Markup Language”) that follows this basic outline: setting: value for setting. Here’s an example YAML metadata section. Note that it must start and end with three dashes (---).\n--- title: Title of your document date: \u0026quot;January 13, 2020\u0026quot; author: \u0026quot;Your name\u0026quot; --- You can put the values inside quotes (like the date and name in the example above), or you can leave them outside of quotes (like the title in the example above). I typically use quotes just to be safe—if the value you’re using has a colon (:) in it, it’ll confuse Markdown since it’ll be something like title: My cool title: a subtitle, which has two colons. It’s better to do this:\n--- title: \u0026quot;My cool title: a subtitle\u0026quot; --- If you want to use quotes inside one of the values (e.g. your document is An evaluation of \"scare quotes\"), you can use single quotes instead:\n--- title: \u0026#39;An evaluation of \u0026quot;scare quotes\u0026quot;\u0026#39; ---  Citations One of the most powerful features of Markdown + pandoc is the ability to automatically cite things and generate bibliographies. to use citations, you need to create a BibTeX file (ends in .bib) that contains a database of the things you want to cite. You can do this with bibliography managers designed to work with BibTeX directly (like BibDesk on macOS), or you can use Zotero (macOS and Windows) to export a .bib file. You can download an example .bib file of all the readings from this class here.\nComplete details for using citations can be found here. In brief, you need to do three things:\nAdd a bibliography: entry to the YAML metadata:\n--- title: Title of your document date: \u0026quot;January 13, 2020\u0026quot; author: \u0026quot;Your name\u0026quot; bibliography: name_of_file.bib --- Choose a citation style based on a CSL file. The default is Chicago author-date, but you can choose from 2,000+ at this repository. Download the CSL file, put it in your project folder, and add an entry to the YAML metadata (or provide a URL to the online version):\n--- title: Title of your document date: \u0026quot;January 13, 2020\u0026quot; author: \u0026quot;Your name\u0026quot; bibliography: name_of_file.bib csl: \u0026quot;https://raw.githubusercontent.com/citation-style-language/styles/master/apa.csl\u0026quot; --- Some of the most common CSLs are:\n Chicago author-date Chicago note-bibliography Chicago full note-bibliography (no shortened notes or ibids){target=\"_blank\"} APA 7th edition MLA 8th edition  Cite things in your document. Check the documentation for full details of how to do this. Essentially, you use @citationkey inside square brackets ([]):\n    Type… …to get…    Causal inference is neat [@Rohrer:2018; @AngristPischke:2015]. Causal inference is neat (Rohrer 2018; Angrist and Pischke 2015).  Causal inference is neat [see @Rohrer:2018, p. 34; also @AngristPischke:2015, chapter 1]. Causal inference is neat (see Rohrer 2018, 34; also Angrist and Pischke 2015, chap. 1).  Angrist and Pischke say causal inference is neat [-@AngristPischke:2015; see also @Rohrer:2018]. Angrist and Pischke say causal inference is neat (2015; see also Rohrer 2018).  @AngristPischke:2015 [chapter 1] say causal inference is neat, and @Rohrer:2018 agrees. Angrist and Pischke (2015, chap. 1) say causal inference is neat, and Rohrer (2018) agrees.    After compiling, you should have a perfectly formatted bibliography added to the end of your document too:\n Angrist, Joshua D., and Jörn-Steffen Pischke. 2015. Mastering ’Metrics: The Path from Cause to Effect. Princeton, NJ: Princeton University Press.\nRohrer, Julia M. 2018. “Thinking Clearly About Correlations and Causation: Graphical Causal Models for Observational Data.” Advances in Methods and Practices in Psychological Science 1 (1): 27–42. https://doi.org/10.1177/2515245917745629.\n   Other references These websites have additional details and examples and practice tools:\n CommonMark’s Markdown tutorial: A quick interactive Markdown tutorial. Markdown tutorial: Another interactive tutorial to practice using Markdown. Markdown cheatsheet: Useful one-page reminder of Markdown syntax. The Plain Person’s Guide to Plain Text Social Science: A comprehensive explanation and tutorial about why you should write data-based reports in Markdown.   ","date":1594771200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1594771200,"objectID":"dcf6a5ae191a1cca4f4c8ff8ac114538","permalink":"https://edp693e.theoreticalphysed.com/resource/markdown/","publishdate":"2020-07-15T00:00:00Z","relpermalink":"/resource/markdown/","section":"resource","summary":"Basic Markdown formatting Math Tables Footnotes Front matter Citations Other references   Markdown is a special kind of markup language that lets you format text with simple syntax.","tags":null,"title":"Using Markdown","type":"docs"},{"authors":null,"categories":null,"content":"   Learning R R in the Wild Sample of R Visualizations   Learning R I highly recommend subscribing to the R Weekly newsletter. This e-mail is sent every Monday and is full of helpful tutorials about how to do stuff with R.\nSearching for help with R on Google can sometimes be tricky because the program name is a single letter. Google is generally smart enough to figure out what you mean when you search for “r scatterplot”, but if it does struggle, try searching for “rstats” instead (e.g. “rstats scatterplot”). Also, since most of your R work in this class will deal with the tidyverse family of packages, it’s often easier to just search for that instead of the letter “R” (e.g. “tidy pivoting”).\nIf you use Twitter, post R-related questions and content with #rstats. The community there is exceptionally generous and helpful. Also check out StackOverflow (a Q\u0026amp;A site with hundreds of thousands of answers to all sorts of programming questions) and RStudio Community (a forum specifically designed for people using RStudio and the tidyverse (i.e. you)).\nThese resources are also really really helpful:\n CSE 631: Principles \u0026amp; Practice of Data Visualization: Yet another introductory course for R and ggplot2 by Dr. Alison Presmanes Hill at RStudio. A Complete Guide to scales: This absolutely gem of a site is partially interactive and dedicated to the scales family of functions that are used in ggplot2 where you can learn what each does, when to use it, and all corresponding options available.\n LHS 610: Exploratory Data Analysis for Health: A comprehensive way to learn R using health based data sets by Dr. Karandeep Singh out of the University of Michigan. R for Data Science: A free online book for learning the basics of R and the tidyverse. R and RStudio cheat sheets: A large collection of simple cheat sheets for RStudio, ggplot2, and other R-related things. RStudio Conference cheat sheets: A comprehensive collection of all recognized RStudio cheat sheets from rstudio::conf 2019. In fact if you are interested inWrap up R, check out the conference workshop materials. Stat 545: Dr. Jenny Bryan at RStudio has an entire introductory course in R, visualization, and data analysis online. STA 112FS: Data Science: Dr. Mine Çetinkaya-Rundel at the University of Edinburgh / Duke University has an entire introductory course in R, visualization, and data science online. Stats Illustrations: Dr. Allison Horst created and continues to build beautiful illustrations of many R commands you will probably use. Teacup Giraffes: A fantastic and visually stunning way to learn R using animations accessible to children but for adults by Dr. Desirée De Leon at RStudio.   R in the Wild A popular (and increasingly standard) way for sharing your analyses and visualizations is to post an annotated explanation of your process somewhere online. RStudio allows you to publish knitted HTML files directly to RPubs, but you can also post your output to a blog or other type of website.1 Reading these kinds of posts is one of the best ways to learn R, since they walk you through each step of the process and show the code and output.\n Sample of R Visualizations  Bob Ross - Joy of Painting Bechdel analysis using the tidyverse: There are also a bunch of other examples using data from FiveThirtyEight Comparison of Quentin Tarantino Movies by Box Office and the Bechdel Test A decade(ish) of listening to Sigur Rós Disproving Approval R color Palettes by Emil Hvitfeldt is a very comprehensive list of pre packaged color palettes you can get. He has even compiled all of them into an R package called paletteer General (Attys) Distributions Health care indicators in Utah counties Mapping Fall Foliage Personal Blog from Isabella Benabaye with some fun and colorful R and Python data visualizations Sexism on the Silver Screen: Exploring film’s gender divide Song lyrics across the United States Text analysis of Trump’s tweets confirms he writes only the (angrier) Android half (with a follow-up) When is Tom peeping these days?: There are a also bunch of final projects from other R and data visualization classes here and here. Who came to vote in Utah’s caucuses?    If you want to be really fancy, you can use blogdown, which makes a complete website with R Markdown files. That’s actually how this site is built (see the original source code @ andrewheiss). You can build your own site with this tutorial.↩︎\n   ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"0f6270d48011ac62645a8455a86a24bf","permalink":"https://edp693e.theoreticalphysed.com/resource/r/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/resource/r/","section":"resource","summary":"Learning R R in the Wild Sample of R Visualizations   Learning R I highly recommend subscribing to the R Weekly newsletter. This e-mail is sent every Monday and is full of helpful tutorials about how to do stuff with R.","tags":null,"title":"R","type":"docs"},{"authors":null,"categories":null,"content":"   Key terms Add chunks Chunk names Chunk options Inline chunks Output formats   R Markdown is regular Markdown with R code and output sprinkled in. You can do everything you can with regular Markdown, but you can incorporate graphs, tables, and other R output directly in your document. You can create HTML, PDF, and Word documents, PowerPoint and HTML presentations, websites, books, and even interactive dashboards with R Markdown. This whole course website is created with R Markdown (and a package named blogdown).\nThe documentation for R Markdown is extremely comprehensive, and their tutorials and cheatsheets are excellent—rely on those.\nHere are the most important things you’ll need to know about R Markdown in this class:\nKey terms  Document: A Markdown file where you type stuff\n Chunk: A piece of R code that is included in your document. It looks like this:\n```{r} # Code goes here ``` There must be an empty line before and after the chunk. The final three backticks must be the only thing on the line—if you add more text, or if you forget to add the backticks, or accidentally delete the backticks, your document will not knit correctly.\n Knit: When you “knit” a document, R runs each of the chunks sequentially and converts the output of each chunk into Markdown. R then runs the knitted document through pandoc to convert it to HTML or PDF or Word (or whatever output you’ve selected).\nYou can knit by clicking on the “Knit” button at the top of the editor window, or by pressing ⌘⇧K on macOS or control + shift + K on Windows.\n   Add chunks There are three ways to insert chunks:\n Press ⌘⌥I on macOS or control + alt + I on Windows\n Click on the “Insert” button at the top of the editor window\n Manually type all the backticks and curly braces (don’t do this)\n   Chunk names You can add names to chunks to make it easier to navigate your document. If you click on the little dropdown menu at the bottom of your editor in RStudio, you can see a table of contents that shows all the headings and chunks. If you name chunks, they’ll appear in the list. If you don’t include a name, the chunk will still show up, but you won’t know what it does.\nTo add a name, include it immediately after the {r in the first line of the chunk. Names cannot contain spaces, but they can contain underscores and dashes. All chunk names in your document must be unique.\n```{r name-of-this-chunk} # Code goes here ```  Chunk options There are a bunch of different options you can set for each chunk. You can see a complete list in the RMarkdown Reference Guide or at knitr’s website.\nOptions go inside the {r} section of the chunk:\n```{r name-of-this-chunk, warning=FALSE, message=FALSE} # Code goes here ``` The most common chunk options are these:\n fig.width=5 and fig.height=3 (or whatever number you want): Set the dimensions for figures echo=FALSE: The code is not shown in the final document, but the results are message=FALSE: Any messages that R generates (like all the notes that appear after you load a package) are omitted warning=FALSE: Any warnings that R generates are omitted include=FALSE: The chunk still runs, but the code and results are not included in the final document  You can also set chunk options by clicking on the little gear icon in the top right corner of any chunk:\n Inline chunks You can also include R output directly in your text, which is really helpful if you want to report numbers from your analysis. To do this, use `r r_code_here`.\nIt’s generally easiest to calculate numbers in a regular chunk beforehand and then use an inline chunk to display the value in your text. For instance, this document…\n```{r find-avg-mpg, echo=FALSE} avg_mpg \u0026lt;- mean(mtcars$mpg) ``` The average fuel efficiency for cars from 1974 was `r round(avg_mpg, 1)` miles per gallon. … would knit into this:\n The average fuel efficiency for cars from 1974 was 20.1 miles per gallon.\n  Output formats You can specify what kind of document you create when you knit in the YAML front matter.\ntitle: \u0026quot;My document\u0026quot; output: html_document: default pdf_document: default word_document: default You can also click on the down arrow on the “Knit” button to choose the output and generate the appropriate YAML. If you click on the gear icon next to the “Knit” button and choose “Output options”, you change settings for each specific output type, like default figure dimensions or whether or not a table of contents is included.\nThe first output type listed under output: will be what is generated when you click on the “Knit” button or press the keyboard shortcut (⌘⇧K on macOS; control + shift + K on Windows). If you choose a different output with the “Knit” button menu, that output will be moved to the top of the output section.\nThe indentation of the YAML section matters, especially when you have settings nested under each output type. Here’s what a typical output section might look like:\n--- title: \u0026quot;My document\u0026quot; author: \u0026quot;My name\u0026quot; date: \u0026quot;August 19, 2020\u0026quot; output: html_document: toc: yes fig_caption: yes fig_height: 8 fig_width: 10 pdf_document: latex_engine: xelatex # More modern PDF typesetting engine toc: yes word_document: toc: yes fig_caption: yes fig_height: 4 fig_width: 5 ---  ","date":1594771200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1594771200,"objectID":"00c0b36df90b91640842af65d1311657","permalink":"https://edp693e.theoreticalphysed.com/resource/rmarkdown/","publishdate":"2020-07-15T00:00:00Z","relpermalink":"/resource/rmarkdown/","section":"resource","summary":"Key terms Add chunks Chunk names Chunk options Inline chunks Output formats   R Markdown is regular Markdown with R code and output sprinkled in. You can do everything you can with regular Markdown, but you can incorporate graphs, tables, and other R output directly in your document.","tags":null,"title":"Using R Markdown","type":"docs"},{"authors":null,"categories":null,"content":"   R style conventions Main style things to pay attention to for this class  Spacing Long lines Pipes (%\u0026gt;%) and ggplot layers (+) Comments    R style conventions R is fairly forgiving about how you type code (unlike other languages like Python, where miscounting spaces can ruin your code!). All of these things will do exactly the same thing:\nmpg %\u0026gt;% filter(cty \u0026gt; 10, class == \u0026quot;compact\u0026quot;) mpg %\u0026gt;% filter(cty \u0026gt; 10, class == \u0026quot;compact\u0026quot;) mpg %\u0026gt;% filter(cty \u0026gt; 10, class == \u0026quot;compact\u0026quot;) mpg %\u0026gt;% filter(cty\u0026gt;10, class==\u0026quot;compact\u0026quot;) filter(mpg,cty\u0026gt;10,class==\u0026quot;compact\u0026quot;) mpg %\u0026gt;% filter(cty \u0026gt; 10, class == \u0026quot;compact\u0026quot;) filter ( mpg,cty\u0026gt;10, class==\u0026quot;compact\u0026quot; ) But you’ll notice that only a few of those iterations (the first three) are easily readable.\nTo help improve readability and make it easier to share code with others, there’s an unofficial style guide for writing R code. It’s fairly short and just has lots of examples of good and bad ways of writing code (naming variables, dealing with long lines, using proper indentation levels, etc.)—you should glance through it some time.\nRStudio has a built-in way of cleaning up your code. Select some code, press ctrl + i (on Windows) or ⌘ + i (on macOS), and R will reformat the code for you. It’s not always perfect, but it’s really helpful for getting indentation right without having to manually hit space a billion times.\n Main style things to pay attention to for this class  Important note: I won’t ever grade you on any of this! If you submit something like filter(mpg,cty\u0026gt;10,class==\"compact\"), I might recommend adding spaces, but it won’t affect your grade or points or anything.\n Spacing  See the “Spacing” section in the tidyverse style guide.\n Put spaces after commas (like in regular English):\n# Good filter(mpg, cty \u0026gt; 10) # Bad filter(mpg , cty \u0026gt; 10) filter(mpg ,cty \u0026gt; 10) filter(mpg,cty \u0026gt; 10) Put spaces around operators like +, -, \u0026gt;, =, etc.:\n# Good filter(mpg, cty \u0026gt; 10) # Bad filter(mpg, cty\u0026gt;10) filter(mpg, cty\u0026gt; 10) filter(mpg, cty \u0026gt;10) Don’t put spaces around parentheses that are parts of functions:\n# Good filter(mpg, cty \u0026gt; 10) # Bad filter (mpg, cty \u0026gt; 10) filter ( mpg, cty \u0026gt; 10) filter( mpg, cty \u0026gt; 10 )  Long lines  See the “Long lines” section in the tidyverse style guide.\n It’s generally good practice to not have really long lines of code. A good suggestion is to keep lines at a maximum of 80 characters. Instead of counting characters by hand (ew), in RStudio go to “Tools” \u0026gt; “Global Options” \u0026gt; “Code” \u0026gt; “Display” and check the box for “Show margin”. You should now see a really thin line indicating 80 characters. Again, you can go beyond this—that’s fine. It’s just good practice to avoid going too far past it.\nYou can add line breaks inside longer lines of code. Line breaks should come after commas, and things like function arguments should align within the function:\n# Good filter(mpg, cty \u0026gt; 10, class == \u0026quot;compact\u0026quot;) # Good filter(mpg, cty \u0026gt; 10, class == \u0026quot;compact\u0026quot;) # Good filter(mpg, cty \u0026gt; 10, class == \u0026quot;compact\u0026quot;) # Bad filter(mpg, cty \u0026gt; 10, class %in% c(\u0026quot;compact\u0026quot;, \u0026quot;pickup\u0026quot;, \u0026quot;midsize\u0026quot;, \u0026quot;subcompact\u0026quot;, \u0026quot;suv\u0026quot;, \u0026quot;2seater\u0026quot;, \u0026quot;minivan\u0026quot;)) # Good filter(mpg, cty \u0026gt; 10, class %in% c(\u0026quot;compact\u0026quot;, \u0026quot;pickup\u0026quot;, \u0026quot;midsize\u0026quot;, \u0026quot;subcompact\u0026quot;, \u0026quot;suv\u0026quot;, \u0026quot;2seater\u0026quot;, \u0026quot;minivan\u0026quot;))  Pipes (%\u0026gt;%) and ggplot layers (+) Put each layer of a ggplot plot on separate lines, with the + at the end of the line, indented with two spaces:\n# Good ggplot(mpg, aes(x = cty, y = hwy, color = class)) + geom_point() + geom_smooth() + theme_bw() # Bad ggplot(mpg, aes(x = cty, y = hwy, color = class)) + geom_point() + geom_smooth() + theme_bw() # Super bad ggplot(mpg, aes(x = cty, y = hwy, color = class)) + geom_point() + geom_smooth() + theme_bw() # Super bad and won\u0026#39;t even work ggplot(mpg, aes(x = cty, y = hwy, color = class)) + geom_point() + geom_smooth() + theme_bw() Put each step in a dplyr pipeline on separate lines, with the %\u0026gt;% at the end of the line, indented with two spaces:\n# Good mpg %\u0026gt;% filter(cty \u0026gt; 10) %\u0026gt;% group_by(class) %\u0026gt;% summarize(avg_hwy = mean(hwy)) # Bad mpg %\u0026gt;% filter(cty \u0026gt; 10) %\u0026gt;% group_by(class) %\u0026gt;% summarize(avg_hwy = mean(hwy)) # Super bad mpg %\u0026gt;% filter(cty \u0026gt; 10) %\u0026gt;% group_by(class) %\u0026gt;% summarize(avg_hwy = mean(hwy)) # Super bad and won\u0026#39;t even work mpg %\u0026gt;% filter(cty \u0026gt; 10) %\u0026gt;% group_by(class) %\u0026gt;% summarize(avg_hwy = mean(hwy))  Comments  See the “Comments” section in the tidyverse style guide.\n Comments should start with a comment symbol and a single space: #\n# Good #Bad #Bad If the comment is really short (and won’t cause you to go over 80 characters in the line), you can include it in the same line as the code, separated by at least two spaces (it works with one space, but using a couple can enhance readability):\nmpg %\u0026gt;% filter(cty \u0026gt; 10) %\u0026gt;% # Only rows where cty is 10 + group_by(class) %\u0026gt;% # Divide into class groups summarize(avg_hwy = mean(hwy)) # Find the average hwy in each group You can add extra spaces to get inline comments to align, if you want:\nmpg %\u0026gt;% filter(cty \u0026gt; 10) %\u0026gt;% # Only rows where cty is 10 + group_by(class) %\u0026gt;% # Divide into class groups summarize(avg_hwy = mean(hwy)) # Find the average hwy in each group If the comment is really long, you can break it into multiple lines. RStudio can do this for you if you go to “Code” \u0026gt; “Reflow comment”\n# Good # Happy families are all alike; every unhappy family is unhappy in its own way. # Everything was in confusion in the Oblonskys’ house. The wife had discovered # that the husband was carrying on an intrigue with a French girl, who had been # a governess in their family, and she had announced to her husband that she # could not go on living in the same house with him. This position of affairs # had now lasted three days, and not only the husband and wife themselves, but # all the members of their family and household, were painfully conscious of it. # Bad # Happy families are all alike; every unhappy family is unhappy in its own way. Everything was in confusion in the Oblonskys’ house. The wife had discovered that the husband was carrying on an intrigue with a French girl, who had been a governess in their family, and she had announced to her husband that she could not go on living in the same house with him. This position of affairs had now lasted three days, and not only the husband and wife themselves, but all the members of their family and household, were painfully conscious of it. Though, if you’re dealing with comments that are that long, consider putting the text in R Markdown instead and having it be actual prose.\n  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f4734e734c67442efdc8d228e91ad766","permalink":"https://edp693e.theoreticalphysed.com/resource/style/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/resource/style/","section":"resource","summary":"R style conventions Main style things to pay attention to for this class  Spacing Long lines Pipes (%\u0026gt;%) and ggplot layers (+) Comments    R style conventions R is fairly forgiving about how you type code (unlike other languages like Python, where miscounting spaces can ruin your code!","tags":null,"title":"R style suggestions","type":"docs"},{"authors":null,"categories":null,"content":"   Interesting and excellent real world examples How to select the appropriate chart type General resources Visualization in Excel Visualization in Tableau   Interesting and excellent real world examples  Australia as 100 people: You can make something like this with d3 and the potato project. Marrying Later, Staying Single Longer The Stories Behind a Line   How to select the appropriate chart type Many people have created many useful tools for selecting the correct chart type for a given dataset or question. Here are some of the best:\n The Chartmaker Directory: Examples of how to create 51 different types of visualizations in 31 different software packages, including Excel, Tableau, and R. Emery’s Essentials: Descriptions and examples of 26 different chart types. From Data to Viz: A decision tree for dozens of chart types with links to R and Python code. The Data Visualisation Catalogue: Descriptions, explanations, examples, and tools for creating 60 different types of visualizations. The Data Viz Project: Descriptions and examples for 150 different types of visualizations. Also allows you to search by data shape and chart function (comparison, correlation, distribution, geographical, part to whole, trend over time, etc.). R Graph Catalog: R code for 124 ggplot graphs.   General resources  Ann K. Emery’s blog: Blog and tutorials by Ann Emery. Data Literacy Starter Kit: Compilation of resources to become data literate by Laura Calloway. The Data Visualization Checklist: A helpful set of criteria for grading the effectiveness of a graphic. Evergreen Data: Helpful resources by Stephanie Evergreen. FlowingData: Blog by Nathan Yau. Info We Trust: Detailed explorations of visualizations by RJ Andrews, including a beautiful visual history of the field. Information is Beautiful: Blog by David McCandless. PolicyViz: Regular podcast and site full of helpful resources by Jon Schwabisch. Visualising Data: Fantastic collection of visualization resources, articles, and tutorials by Andy Kirk. Storytelling with Data: Blog and site full of resources by Cole Nussbaumer Knaflic. Junk Charts: Blog by Kaiser Fung. WTF Visualizations: Visualizations that make you ask “wtf?” R Psychologist: A fantastic collection of interactive applications of statistical concepts by Kristoffer Magnusson Seeing Data: A series of research projects about perceptions and visualizations.   Visualization in Excel  How to Build Data Visualizations in Excel: Detailed tutorials for creating 14 different visualizations in Excel. Ann Emery’s tutorials: Fantastic series of tutorials for creating charts in Excel.   Visualization in Tableau Because it is focused entirely on visualization (and because it’s a well-supported commercial product), Tableau has a phenomenal library of tutorials and training videos. There’s a helpful collections of videos here, as well.\n ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"ca403ba352e0871f06b445d2470037b3","permalink":"https://edp693e.theoreticalphysed.com/resource/visualization/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/resource/visualization/","section":"resource","summary":"Interesting and excellent real world examples How to select the appropriate chart type General resources Visualization in Excel Visualization in Tableau   Interesting and excellent real world examples  Australia as 100 people: You can make something like this with d3 and the potato project.","tags":null,"title":"Visualization","type":"docs"},{"authors":null,"categories":null,"content":"  Because RStudio projects typically consist of multiple files (R scripts, datasets, graphical output, etc.) the easiest way to distribute them to you for examples, assignments, and projects is to combine all the different files in to a single compressed collection called a zip file. When you unzip a zipped file, your operating system extracts all the files that are contained inside into a new folder on your computer.\nUnzipping files on macOS is trivial, but unzipping files on Windows can mess you up if you don’t pay careful attention. Here’s a helpful guide to unzipping files on both macOS and Windows.\nUnzipping files on macOS Double click on the downloaded .zip file. macOS will automatically create a new folder with the same name as the .zip file, and all the file’s contents will be inside. Double click on the RStudio Project file (.Rproj) to get started.\n Unzipping files on Windows tl;dr: Right click on the .zip file, select “Extract All…”, and work with the resulting unzipped folder.\nUnlike macOS, Windows does not automatically unzip things for you. If you double click on the .zip file, Windows will show you what’s inside, but it will do so without actually extracting anything. This can be is incredibly confusing! Here’s what it looks like—the only clues that this folder is really a .zip file are that there’s a “Compressed Folder Tools” tab at the top, and there’s a “Ratio” column that shows how much each file is compressed.\nIt is very tempting to try to open files from this view. However, if you do, things will break and you won’t be able to correctly work with any of the files in the zipped folder. If you open the R Project file, for instance, RStudio will point to a bizarre working directory buried deep in some temporary folder:\nYou most likely won’t be able to open any data files or save anything, which will be frustrating.\nInstead, you need to right click on the .zip file and select “Extract All…”:\nThen choose where you want to unzip all the files and click on “Extract”\nYou should then finally have a real folder with all the contents of the zipped file. Open the R Project file and RStudio will point to the correct working directory and everything will work.\n ","date":1588723200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588723200,"objectID":"c14c352fd4c4ab8c12a3cd60b30b9d8c","permalink":"https://edp693e.theoreticalphysed.com/resource/unzipping/","publishdate":"2020-05-06T00:00:00Z","relpermalink":"/resource/unzipping/","section":"resource","summary":"Because RStudio projects typically consist of multiple files (R scripts, datasets, graphical output, etc.) the easiest way to distribute them to you for examples, assignments, and projects is to combine all the different files in to a single compressed collection called a zip file.","tags":null,"title":"Unzipping files","type":"docs"},{"authors":null,"categories":null,"content":"  Anything SPSS Can Do, R Can Do Better Getting Prepped Set your working directory Your working directory is simply where your script will look for anything it needs like external data sets. There are a few ways to go about doing this which we will cover. However for now, just do the following:\nGo to the menu bar and select Session \u0026gt; Set Working Directory \u0026gt; To Source File Location.\n   ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"4767315339e8f5535fcf141238416047","permalink":"https://edp693e.theoreticalphysed.com/lesson/basevisuals/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/lesson/basevisuals/","section":"lesson","summary":"Anything SPSS Can Do, R Can Do Better Getting Prepped Set your working directory Your working directory is simply where your script will look for anything it needs like external data sets.","tags":null,"title":"Base Visuals in R","type":"lesson"},{"authors":null,"categories":null,"content":"   This is me This is what I am This is where I come from This is what I research This is how you can contact me This is Sparta   This is me     This is what I am Professor of Educational Psychology and coordinator of the Program Evaluation Certificate at WVU.\n This is where I come from  PhD in Program Evaluation from Western Michigan University. MS in Mathematical Sciences from Michigan Technological University. BS in Mathematics from West Virginia Wesleyan College.   This is what I research  Transference of Foundational Evaluation Concepts Social Modeling using Machine Learning Applications of Predictive Hierarchical Social Networks  which are just fancy ways of saying\n How people learn basic concepts in evaluation Programming a type of artificial intelligence and then training it to do some of my work for me1 Figuring out how things are related to each other and then making judgments2  You can check out more about what I do here    ORCID   ResearcherID (via ublons)   GitHub   ResearchGate  This is how you can contact me    Abhik.Roy   @DrTheoreticalPE  This is Sparta     No its not Skynet. Computers are stupid.↩︎\n Which is a very evaluation like thing to do!↩︎\n   ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"779259905d42fe327a85b980891c96bc","permalink":"https://edp693e.theoreticalphysed.com/professor/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/professor/","section":"","summary":"This is me This is what I am This is where I come from This is what I research This is how you can contact me This is Sparta   This is me     This is what I am Professor of Educational Psychology and coordinator of the Program Evaluation Certificate at WVU.","tags":null,"title":"Professor","type":"page"},{"authors":null,"categories":null,"content":"   Table of Contents     Readings  Go     This page contains the readings for the topic which should be the first place you go to.    Lesson  Go     Here are interactive lessons, slides, and/or walkthroughs that helps with any content.    Example  Go     Extra items that are picked or created to help you understand the current material exist on this page.    Assignment  Go     Instructions for all student related tasks including information about the tasks and deliverables are provided in this location.    Due  Go     This page contains instructions on what to submit by on a weekly basis.      Note: Assignments are due by Wednesday at 11:59 PM unless otherwise noted.  Weekly Overview   January 21, 2021 Friends Don\u0026rsquo;t Let Friends Use Pie Chart        January 28, 2021 Base R is a Thing        February 4, 2021 ggplotting         February 11, 2021 Tidy Themes            February 18, 2021 Making Copies          ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"3e223d7ba58b0122b42458e4cf52e04c","permalink":"https://edp693e.theoreticalphysed.com/schedule/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/schedule/","section":"","summary":"Table of Contents     Readings  Go     This page contains the readings for the topic which should be the first place you go to.","tags":null,"title":"Schedule","type":"page"},{"authors":null,"categories":null,"content":"   Course objectives FAQ  Is the course content difficult? Is R difficult? What if I find a mistake?  Course materials  Texts Note: Online help  Assignments and Grades  Your hours Class conduct and expectations Learning and knowledge during a pandemic  Course policies COVID-19 Statement  Psychological and Psychiatric Services CARE Team Lauren’s Promise Academic Integrity Inclusivity Statement Incomplete Grades Sale of Course Materials Student Evaluation of Instruction (SEI) University Attendance Policy Course Netiquette Response Time Technical Requirements Technical Support    Instructor  Dr. Abhik Roy  Allen Hall 504O  Abhik.Roy@mail.wvu.edu  @DrTheoreticalPE  Schedule an appointment   Course details  Forever (for the next 15 weeks)  January 19 - May 8  You pick!  Online  Slack   Contacting me Slack is the best way to get in contact with me. Response times are typically much quicker than the standard 24-48 hours given to emails. Please remember that life is still chaotic at this time!\n  Course objectives Students will be expected to develop the following knowledge, skills, and abilities, including but not limited to:\nDefining and understanding the purpose of visualization.\n Delineating between various types and classifications of visualization techniques.\n Demonstrating how to locate and utilize publicly available data sets.\n Explaining the history of data visualization.\n Outlining methods and techniques for establishing and evaluating reliability and validity of data sets.\n Obtaining an understanding of ethical, social, political, and cultural issues confronted by data scientists.\n Presenting and reporting findings to a diverse audience.\n Understanding how to construct data visualizations that present ideas effectively while being visually appealing and functional.\n utilizing evaluative criteria to assess proper outlets of free data.\n   FAQ Is the course content difficult? You’ve probably heard an answer like this before: At times some of the material can be dense. Well that isn’t much of a response. Difficulty is not the issue here since as humans with differing educational background, we will have strengths in some areas more than others. Instead the question is can you identify areas that need strengthened and communicate them? If you can, then you have a good shot at succeeding in this class.\n Is R difficult? Learning R can be especially challenging at first—it’s akin to learning a new language like Spanish or even mathematics. Even experienced R users get frustrated…and so much so that some of us have swear jars. However as silly as it sounds one of the best feelings is to overcome a roadblock. With that said, if you find yourself getting irritated, try the following: take a break, go let some frustration out, sleep, discuss with a peer, etc. If you are at your limit, take a few breaths and contact me!\n What if I find a mistake? Tell me! I strive to be error free but like everyone else, make silly mistakes. This includes grammar and spelling errors as well!\n  Course materials There are four optional texts and two software packages necessary for this course. With that said, you will receive some supplementary materials in the course as well.\nTexts Optional Reference We’ll rely on the texts below. All are available through the WVU library WVU library or in an online capacity:\n Wickham, H., Navarro, D. \u0026amp; Pedersen, T.L. (2021). ggplot2: Elegant Graphics for Data Analysis (2nd and 3rd eds.). Springer.  Digital editions (free!) Hardcover edition (not free) - ISBN: 9783319242750  Wickham, H. (2021). Mastering Shiny (1st ed.). O’Reilly Media.  Digital edition (free!) Hardcover edition (not free) - ISBN: 9781492047384  Wickham, H. (2021). R for Data Science (1st ed.). O’Reilly Media.  Digital edition (web) (free!) Digital edition (WVU libraries) (free!) Hardcover edition (not free) - ISBN: 9781491910399  Sleeper, R. (2021). Innovative Tableau: 100 More Tips, Tutorials, and Strategies (1st ed.). O’Reilly Media.  Digital edition (free!) Hardcover edition (not free) - ISBN: 9781492075653   There will occasionally be additional articles and videos to read and watch. When this happens, links to these other resources will be included on the content page for that session.\n R and RStudio You will do all of your analysis with the open source (and free!) programming language R. You will use RStudio as the main program to access R. Think of R as an engine and RStudio as a car dashboard — R handles all the calculations produces the actual statistics and graphical output, while RStudio provides a nice interface for running R code. Please note that\nyou do not need to have any programming experience to use R\n R is free, but it can sometimes be a task to install and configure. To make life easier, you can opt to use the free RStudio.cloud service, which lets you run a full instance of RStudio in your web browser. This is recommended for those of you who do not want to install programs right now but please note that you will most likely have to in the near future.\nThe service is convenient, but please keep in mind that it can be slow and is not designed to handle large data sets or more complicated analysis and graphics. You also cannot customize much with RStudio.cloud. Over the course of the term, you’ll want to get around to installing R, RStudio, and other R packages on your computer and wean yourself off of RStudio.cloud.\nYou can find instructions for installing R, RStudio, and all the tidyverse packages here.\n  Note: Online help Data science and statistical programming can be difficult. Computers are stupid and its always the tiny errors in your coding can result in tons of headache. People working in any syntax based software package at any level experience this!\nBut there are multiple resources online to help.\n First you will have access to Data Camp which allows you to relieve professional training that otherwise costs a lot of money. Is it perfect and flashy? Nope but it is interactive and if you pay attention, then R’s initial steep learning curve won’t feel like an uphill battle.\n Second two of the most important are StackOverflow (a Q\u0026amp;A site with hundreds of thousands of answers to all sorts of programming questions) and RStudio Community (a forum specifically designed for people using RStudio and the tidyverse (i.e. you)). I freely admit that StackOverflow has saved me multiple hours of frustration. Just note if you have a syntax or process issue, both sites require you to produce a minimally reproducible example.\n Third using Twitter you can post R-related questions and content with #rstats. The community there is exceptionally generous and helpful.\n Fourth searching for help with R on Google (or another indexed search site) can sometimes be tricky because the program name is,for a lack of a better explanation, a single letter.\n Fifth we have a class chatroom at Slack where you can poise a question. I will monitor Slack regularly and will respond quickly. (This is a rare instances where I keep notifications on so please utilize it!) Ask questions about the readings, exercises, and mini projects. You’ll likely have similar questions as your peers, and you’ll likely be able to answer other peoples’ questions too.\n Sixth and lastly you can send items by Slack or email me with questions about content, R or whatever (after giving a graduate student effort of course). Please include the subject header EDP 693e “the title of your email” where the title of your email is given without the quotes. Know that I will not just give you the answer, but am happy to push you in the right direction. If you do email me, please include the following:\n A brief description of the problem and what you have done thus far including the line number of the issue (if applicable). A copy of your data set (if applicable). A copy of your script or Rmarkdown document with comments throughout so I know what you’ve tried historically leading up to the issue.   I have a mail filter that will automatically bring your email to a top priority status.^ [In this new normal, I receive an overwhelming number of emails per day and may miss yours if the header is not formatted properly.]\nYou should absolutely expect to struggle at times, but there is no better and more satisfying feeling than figuring things out for yourself! In the long run, you’re more likely to remember things you’ve figured out rather than those you’ve been shown or told.\n  Assignments and Grades You can find descriptions for all the assignments on the assignments page.\n   Assignment Points Percent    In Class Tasks 100 5%  Out of Class Tasks 200 10%  Data Camp Assessments 200 10%  R Project 200 10%  R Presentation 100 5%  Tableau Project 200 10%  Tableau Presentation 100 5%  Final Project Narrative 400 20%  Final Project Presentation 100 5%  Course Survey 100 5%  Extra Tasks 300 15%  Total 2000 —        Grade Range    A 90–100%  B 80%-89%  C 70–79%  D 60–69%  F \u0026lt; 60%     Your hours Please watch this video:\n Your hours (formerly known as office hours) are set times dedicated to you the student!1). This means that I will be in my office at home waiting for you to come by talk to me remotely with whatever questions you have. This is the best and easiest way to find me and the best chance for discussing class material and concerns.\nBecause of the pandemic, we cannot meet in person. I can meet you online via Zoom. You can request a meeting through the calendar, e-mail or Slack.\n Class conduct and expectations Here are the rules, expectations, and policies that I came up with or stole from other professors:\n Late work: Barring the three main course tasks, past due deliverables will only be accepted up to 48 hours after the initial time and due date. For each full day an assignment is late, 10% of the final grade will be deducted. All submissions must be made via eCampus. There are no exceptions to this policy. Please note that I will not accept coursework by email or any other means.\n Participation: Please ensure that you are engaged and participate in class. Engagement is mostly defined by you—if that means commenting and answering questions, neat; if it means sitting quietly and being focused, also neat; but if it means being being disrespectful or flaking off, not so neat.\n Justifications: On any submission, you must justify any assertion. I don’t know what you know so its your job to provide all of the necessary evidence to convince me that you do know what you say you know. While you’ve probably heard this multiple times over your life, think of it this way: if someone tells you that not only is the Earth flat, the core is actually made out of tiramisu and moscato, the first question you should be asking is what’s your evidence? possibly followed by is the core delicious?.\n Rubrics: While there are valid reasons for the utilization of a rubric in undergraduate classes, at the graduate level, I do not (often) provide nor use a such an item to guide or evaluate your submission due to four primary concerns:\nWhen writing anything in academia that is pivotal (a thesis, dissertation, journal article, report, etc.), a rubric isn’t often provided. If you write within the limitations as defined in a rubric, then creativity may be stifled (i.e. writing to the rubric rather than constructing a product from the ground up). Feedback can only be given along the criteria listed within a rubric which limits your learning as a student and constrains me as the instructor. Unless you are in a very specific area, the real world does not use rubrics!   Technology use: Use phones, computers, etc. responsibly. We’re all adults2.\n My philosophy:\nJust assume that all submissions are formal and must be submitted with the appropriate use of language, grammar, syntax, etc. and follow standard APA 7th edition formatting guidelines where applicable. People who are easily offended by content, believe their work to be flawless or are generally unable to handle criticism should consider looking at another course. If you want rainbows and ponies, consider another class. If you care about data, fieldwork and learning a highly marketable practice, you’ve come to the right place. There is a great deal of content in this course and you will likely struggle with some at times. Given that, there is also something to be said about the satisfaction a person gets when figuring something out, but nowhere is it written that has to be on your own. You may find that a nudge here or there elicits the same feeling so please reach out for help.    Learning and knowledge during a pandemic When course objectives are written explicitly and clearly, they provide the information you need to figure out what a student should be able to do by the end of a given term. In fact, professors often test your proficiency in an area through multiple assessments such as exams, papers, presentations, etc where you are essentially asked to show us what you have learned. However learning is not the same as knowledge .\nTo save you from a long philosophical narrative on epistemology, in a nutshell we humans aren’t that good at evaluating a person’s knowledge mainly because its not a well-defined concept. With that said, we believe one indicator of knowledge is in a person’s ability to successfully explain a high level concept in such a way that the lay person can understand it. Every so often, consider asking yourself this:\nCan I describe whatever using language so that anyone could understand it?\n On top of what’s noted above and I’m not sure how to articulate this any better - life sucks right now! It is likely by now you know people who have been hospitalized or passed away, lost their jobs, and/or tested positive for COVID-19. Additionally stresses in life are up. Given this, here is my promise to you:\nIf you keep an open line, show initiative, and let me know ahead of time if something is going not according to plan3, I will do everything I can to help you learn everything you were hoping to learn from this class!\n   Course policies Its pretty simple: Be nice. Be honest. Don’t cheat. Stay in touch. Be a good human.\n We will also follow WVU’s Code of Conduct.\nThis syllabus reflects a plan for the term but things change and plans change. so deviations may become necessary as we move along during the term. Note that I reserve the right to alter or amend this syllabus and will send notifications if course tasks are affected.\n COVID-19 Statement WVU is committed to maintaining a safe learning environment for all students, faculty, and staff. Should campus operations change because of health concerns related to the COVID-19 pandemic, it is possible that this course will move to a fully online delivery format. If that occurs, students will be advised of technical and/or equipment requirements, including remote proctoring software.\nIn a face-to-face environment, our commitment to safety requires students, staff, and instructors to observe the social distancing and personal protective equipment (PPE) guidelines set by the University at all times. While in class, students will sit in assigned seats when applicable and wear the required PPE. Should a student forget to bring the required PPE, PPE will be available in the building for students to acquire. Students who fail to comply will be dismissed from the classroom for the class period and may be referred to the Office of Student Conduct for further sanctions.\nIf a student becomes sick or is required to quarantine during the semester, they should notify the instructor. The student should work with the instructor to develop a plan to receive the necessary course content, activities, and assessments to complete the course learning outcomes.\nPsychological and Psychiatric Services Life at WVU can be complicated and challenging, especially during a pandemic! You might feel overwhelmed, experience anxiety or depression, or struggle with relationships or family responsibilities. Psychological and Psychiatric Services provides free, confidential support for students who are struggling with mental health and emotional challenges. The office is staffed by professional counselors and psychiatrists who are attuned to the needs of all types of college and professional students. Please do not hesitate to contact them for assistance—getting help is a smart and courageous thing to do.\n CARE Team If you or anyone you know may be at-risk such as those listed here, please make a CARE referral. You may do so directly at the main WVU CARE TEAM site.\n Lauren’s Promise I will listen and believe you if someone is threatening you.\n Lauren McCluskey, a 21-year-old honors student athlete, was murdered on October 22, 2018 by a man she briefly dated on the University of Utah campus. We must all take action to ensure that this never happens again.\nIf you are in immediate danger, call 911 or the Campus Police at 304-293-3136.\nIf you are experiencing sexual assault, domestic violence, or stalking, please report it to me and I will connect you to resources or call/text a private Title IX On-Call Line 304-906-9930.\nAny form of sexual harassment or violence will not be excused or tolerated at West Virginia University. WVU has instituted procedures to respond to violations of these laws and standards, programs aimed at the prevention of such conduct, and intervention on behalf of the victims.\n Academic Integrity The integrity of the classes offered by any academic institution solidifies the foundation of its mission and cannot be sacrificed to expediency, ignorance, or blatant fraud. Therefore, I will enforce rigorous standards of academic integrity in all aspects and assignments of this course. For the detailed policy of West Virginia University regarding the definitions of acts considered to fall under academic dishonesty and possible ensuing sanctions, please see the West Virginia University Academic Catalog at http://catalog.wvu.edu/undergraduate/coursecreditstermsclassification/#academicintegritytext. Should you have any questions about possibly improper research citations or references, or any other activity that may be interpreted as an attempt at academic dishonesty, please see me before the assignment is due to discuss the matter.\n Inclusivity Statement The West Virginia University community is committed to creating and fostering a positive learning and working environment based on open communication, mutual respect, and inclusion.\nIf you are a person with a disability and anticipate needing any type of accommodation in order to participate in this class, please advise me and make appropriate arrangements with the Office of Accessibility Services (304-293-6700).\nFor more information on West Virginia University’s Diversity, Equity, and Inclusion initiatives, please see http://diversity.wvu.edu.\n Incomplete Grades Students who want to be considered for an Incomplete must apply to their instructor prior to the end of the term. If the instructor agrees, the instructor and the student must negotiate the conditions under which the grade of I will be changed to a letter grade and sign a contract. The date to submit the incomplete work should not be set beyond the last day of class of the following semester. If the student does not complete the terms of contract, then the instructor should submit a grade of F. All incomplete contracts must be filed with the department and Dean’s Office. See the policy at [Students who want to be considered for an Incomplete must apply to their instructor prior to the end of the term. If the instructor agrees, the instructor and the student must negotiate the conditions under which the grade of I will be changed to a letter grade and sign a contract. The date to submit the incomplete work should not be set beyond the last day of class of the following semester. If the student does not complete the terms of contract, then the instructor should submit a grade of F. All incomplete contracts must be filed with the department and Dean’s Office. See the policy at http://catalog.wvu.edu/undergraduate/enrollmentandregistration/#gradestext.\n Sale of Course Materials All course materials, including lectures, class notes, quizzes, exams, handouts, presentations, and other materials provided to students for this course are protected under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. Please review the sharing and editing restrictions prior to distributing or amending any material on this site. As such, the unauthorized purchase or sale of these materials may result in disciplinary sanctions under the Campus Student Code. Basically you can share what you like but don’t try to make a buck.\n Student Evaluation of Instruction (SEI) Effective teaching is a primary mission of West Virginia University. Student evaluation of instruction provides the university and the instructor with feedback about your experiences in the course for review and course improvement. Your participation in the evaluation of course instruction is both strongly encouraged and highly valued. Results are strictly confidential, anonymous, and not available to the instructor until after final grades are released by Admissions and Records. Information about how you can complete this evaluation will be provided later.\n University Attendance Policy At West Virginia University, class attendance contributes significantly to academic success. Students who attend classes regularly tend to earn higher grades and have higher passing rates in courses. Excessive absences may jeopardize students’ grades or even their ability to continue in their courses. There is a strong correlation between regular class attendance and academic success.\n Course Netiquette The basic premise is that the etiquette expected of students in the online environment is the same as that expected in a classroom. Common courtesy is the guiding rule of Internet communications. Be prepared to communicate effectively when taking an online course. Following these simple netiquette rules in your online class or education environment will ensure your success:\n Include a professional salutation. In this case, “Hello Dr. Roy” or “Dear Dr. Roy” is appropriate. Include a proper ending such as “Thank you” or “With regards.” Then type in your full name. Never type in ALL CAPS, because it reads as if you ARE SHOUTING AT PEOPLE. Act as professionally, via your writing, as you would in a face to face classroom. Refrain from inappropriate language and derogatory or personal attacks. Do not dominate any discussion. Give other students the opportunity to join in the discussion. Disagree with ideas but avoid challenges that may be interpreted as a personal attack. Check that you are replying to the specific person you intend, and not to the entire class. Never give your password to another person. Respect the virtual classroom. Never forward in-class communications or posts by others outside of this virtual space. Never spam your classmates. If you quote someone’s previous post, only quote enough to make your point.  Be aware of the University’s Academic Integrity and Dishonesty Policy http://catalog.wvu.edu/undergraduate/coursecreditstermsclassification/#academicintegritytext. You can review the rules, regulations, and procedures concerning student conduct and discipline for the main campus of West Virginia University, at http://campuslife.wvu.edu/r/download/1802350.\n Response Time I generally respond to Slack queries in the same day while responses to emails and discussion posts are within 48 hours, except during holidays. Often, I will reply much more quickly but you should not count on a immediate. Please plan accordingly so that you don’t miss deadlines! I generally return assignments within one to two weeks after a final submission date.\n Technical Requirements Students need to have access to a computer for word processing, e-mail and access to eCampus. Access to the Internet is necessary for completion of this course. Run the Browser Check. This tool will check that you are using a supported Internet browser and have a valid Java version installed. The required technical skills to participate in this course are:\nNavigate the web Use email with attachments Create and submit files in commonly used word processing program formats Copy and paste Download and install software Consult software tutorials and other online sources as a method of learning software features Use syntax when necessary   Technical Support Technical support regarding your use of eCampus is available by contacting 304-293-4444 (telephone), 1-877-327-9260 (toll free number), itshelp@mail.wvu.edu (email), and/or http://it.wvu.edu (website).\n\nThis work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License.\n   There is some misunderstanding about what office hours actually are! For some reason that is not clear, particular graduate students have noted in my course evaluations that they believe these to be the times I should not be disturbed. This is not just a local issue!, which is the exact opposite of what they are for!↩︎\n Most of the time.↩︎\n I realize sometimes this just isn’t possible so contact me as soon as you can.↩︎\n   ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"e4d5a4a79239f08c6ad0d7cbf1be756c","permalink":"https://edp693e.theoreticalphysed.com/syllabus/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/syllabus/","section":"","summary":"Course objectives FAQ  Is the course content difficult? Is R difficult? What if I find a mistake?  Course materials  Texts Note: Online help  Assignments and Grades  Your hours Class conduct and expectations Learning and knowledge during a pandemic  Course policies COVID-19 Statement  Psychological and Psychiatric Services CARE Team Lauren’s Promise Academic Integrity Inclusivity Statement Incomplete Grades Sale of Course Materials Student Evaluation of Instruction (SEI) University Attendance Policy Course Netiquette Response Time Technical Requirements Technical Support    Instructor  Dr.","tags":null,"title":"Syllabus","type":"page"}]